{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#SOS_token = 0\n",
    "EOS_token = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.token2index = {\"#\":0}\n",
    "        self.token2count = {}\n",
    "        self.index2token = {0:\"#\"}\n",
    "        self.n_tokens = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for token in list(sentence):\n",
    "            self.addtoken(token)\n",
    "\n",
    "    def addtoken(self, token):\n",
    "        if token not in self.token2index:\n",
    "            self.token2index[token] = self.n_tokens\n",
    "            self.token2count[token] = 1\n",
    "            self.index2token[self.n_tokens] = token\n",
    "            self.n_tokens += 1\n",
    "        else:\n",
    "            self.token2count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(list(p[1])) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "    \n",
    "def prepareData(input_data_path, num_samples=10000):\n",
    "    with  open(input_data_path, 'r', encoding='utf-8') as f:\n",
    "        input_lines = f.read().split('\\n')  # 行ごとのリストに\n",
    "    print(\"Counting tokens:\")\n",
    "    data = Data()\n",
    "    target_lines = []\n",
    "    for line in input_lines:\n",
    "        input_tokens = list(line)\n",
    "        target_tokens = input_tokens[1:]\n",
    "        target_tokens.append(\"#\")\n",
    "        target_lines.append(\"\".join(target_tokens))\n",
    "        data.addSentence(line)\n",
    "    min_samples = min(num_samples, min(len(input_lines)-1, len(target_lines)-1))\n",
    "    pairs = [[i,t]for (i,t) in zip(input_lines[:min_samples],target_lines[:min_samples])]\n",
    "    pairs.append(input_lines)\n",
    "    pairs.append(target_lines)\n",
    "    pairs = filterPairs(pairs)\n",
    "\n",
    "    print(\"Counted tokens:\")\n",
    "    print('data:{}'.format(data.n_tokens))\n",
    "    return data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting tokens:\n",
      "Counted tokens:\n",
      "data:4164\n",
      "train:157364\n",
      "val:39341\n",
      "['「玉竜」はチャボリュウノヒゲと呼ばれ、ガーデニングの寄せ植え材料としても人気があります。', '玉竜」はチャボリュウノヒゲと呼ばれ、ガーデニングの寄せ植え材料としても人気があります。#']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_data_path = \"./data/text/mai2000a_token.txt\"\n",
    "#input_data_path = \"./data/text/mai2000a_normal.txt\"\n",
    "data, pairs = prepareData(input_data_path, 30000000)\n",
    "train_pairs, val_pairs = train_test_split(pairs, train_size=0.8)\n",
    "print(\"train:\"+ str(len(train_pairs)))\n",
    "print(\"val:\"+ str(len(val_pairs)))\n",
    "print(random.choice(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, sentence):\n",
    "    return [data.token2index[token] for token in list(sentence)]\n",
    "\n",
    "def tensorFromSentence(data, sentence):\n",
    "    indexes = indexesFromSentence(data, sentence)\n",
    "    #indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(data, pair[0])\n",
    "    target_tensor = tensorFromSentence(data, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeds = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.initHidden()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeds(input)\n",
    "        lstm_out, hidden = self.lstm(embeds.view(len(input), 1, -1), hidden)\n",
    "        output = self.linear(lstm_out.view(len(input), -1))\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        #self.hidden = hidden\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(BDLSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeds = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, input_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.initHidden()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeds(input)\n",
    "        lstm_out, hidden = self.lstm(embeds.view(len(input), 1, -1), hidden)\n",
    "        output = self.linear(lstm_out.view(len(input), -1))\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, model, optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    model.train()\n",
    "    hidden = model.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_length):\n",
    "        output, hidden = model(input_tensor[i], hidden)\n",
    "        loss += criterion(output, target_tensor[i])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_tensor, target_tensor, model, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden()\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        loss = 0\n",
    "        for i in range(input_length):\n",
    "            output, hidden = model(input_tensor[i], hidden)\n",
    "            loss += criterion(output, target_tensor[i]) \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(model, epochs=1, print_every=10000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_train_losses = []\n",
    "    plot_val_losses = []\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    plot_val_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    train_length = len(train_pairs)\n",
    "    val_length = len(val_pairs)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs)) for i in range(train_length)]\n",
    "    validation_pairs = [tensorsFromPair(random.choice(val_pairs)) for i in range(val_length)]\n",
    "    for epoch in range(epochs):\n",
    "        #Train\n",
    "        for j, train_pair in enumerate(training_pairs):\n",
    "            i = j+1\n",
    "            input_tensor = train_pair[0]\n",
    "            target_tensor = train_pair[1]\n",
    "            loss = train(input_tensor, target_tensor, model, optimizer, criterion)\n",
    "            print_train_loss_total += loss\n",
    "            plot_train_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_train_loss_total / print_every\n",
    "                print_train_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, i / train_length),\n",
    "                                             i, i / train_length * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_train_loss_total / plot_every\n",
    "                plot_train_losses.append(plot_loss_avg)\n",
    "                plot_train_loss_total = 0\n",
    "        \n",
    "        #Validation        \n",
    "        for j, val_pair in enumerate(validation_pairs):\n",
    "            i = j+1\n",
    "            input_tensor = train_pair[0]\n",
    "            target_tensor = train_pair[1]\n",
    "            loss = train(input_tensor, target_tensor, model, optimizer, criterion)\n",
    "            print_val_loss_total += loss\n",
    "            plot_val_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_val_loss_total / print_every\n",
    "                print_val_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, i / val_length),\n",
    "                                             i, i / val_length * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_val_loss_total / plot_every\n",
    "                plot_val_losses.append(plot_loss_avg)\n",
    "                plot_val_loss_total = 0\n",
    "            \n",
    "\n",
    "    showPlot(plot_train_losses, \"./results/\"+str(epochs)+\"_train.png\")\n",
    "    showPlot(plot_val_losses, \"./results/\"+str(epochs)+\"val.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def showPlot(points, figure_path):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.savefig(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, sentence, max_length=MAX_LENGTH):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(data, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        hidden = model.initHidden()\n",
    "        outputs = []\n",
    "        for i in range(input_length):\n",
    "            output, hidden = model(input_tensor[i], hidden)\n",
    "            outputs.append(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(model, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        outputs = evaluate(model, pair[0])\n",
    "        input_tokens = list(pair[0])\n",
    "        for j, output in enumerate(outputs):\n",
    "            if len(input_tokens) <= j: \n",
    "                break\n",
    "            topv_list, topi_list = output[0].topk(5)\n",
    "            print(input_tokens[j] + \":\")\n",
    "            output_tokens = []\n",
    "            for index in topi_list:\n",
    "                output_tokens.append(data.index2token[index.item()])\n",
    "                \n",
    "            print(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 20s (- 365m 42s) (1000 0%) 5.8933\n",
      "3m 58s (- 309m 1s) (2000 1%) 5.2214\n",
      "5m 33s (- 285m 56s) (3000 1%) 5.0051\n",
      "7m 10s (- 274m 58s) (4000 2%) 4.9006\n",
      "8m 49s (- 268m 43s) (5000 3%) 4.7509\n",
      "10m 26s (- 263m 27s) (6000 3%) 4.6628\n",
      "12m 6s (- 260m 13s) (7000 4%) 4.5875\n",
      "13m 44s (- 256m 42s) (8000 5%) 4.5572\n",
      "15m 24s (- 253m 59s) (9000 5%) 4.5110\n",
      "17m 1s (- 250m 56s) (10000 6%) 4.4830\n",
      "18m 40s (- 248m 26s) (11000 6%) 4.4565\n",
      "20m 18s (- 246m 0s) (12000 7%) 4.4325\n",
      "21m 58s (- 244m 4s) (13000 8%) 4.3691\n",
      "23m 34s (- 241m 28s) (14000 8%) 4.2926\n",
      "25m 13s (- 239m 20s) (15000 9%) 4.3114\n",
      "26m 52s (- 237m 25s) (16000 10%) 4.2955\n",
      "28m 32s (- 235m 40s) (17000 10%) 4.2663\n",
      "30m 11s (- 233m 47s) (18000 11%) 4.2507\n",
      "31m 50s (- 231m 51s) (19000 12%) 4.2392\n",
      "33m 28s (- 229m 55s) (20000 12%) 4.2203\n",
      "35m 6s (- 227m 55s) (21000 13%) 4.1611\n",
      "36m 41s (- 225m 48s) (22000 13%) 4.1733\n",
      "38m 18s (- 223m 47s) (23000 14%) 4.1355\n",
      "39m 55s (- 221m 53s) (24000 15%) 4.1417\n",
      "41m 31s (- 219m 49s) (25000 15%) 4.0963\n",
      "43m 7s (- 217m 55s) (26000 16%) 4.1340\n",
      "44m 42s (- 215m 52s) (27000 17%) 4.0847\n",
      "46m 19s (- 214m 2s) (28000 17%) 4.0715\n",
      "47m 54s (- 212m 5s) (29000 18%) 4.0454\n",
      "49m 33s (- 210m 23s) (30000 19%) 4.0248\n",
      "51m 9s (- 208m 33s) (31000 19%) 4.0474\n",
      "52m 43s (- 206m 35s) (32000 20%) 4.0395\n",
      "54m 18s (- 204m 38s) (33000 20%) 3.9987\n",
      "55m 54s (- 202m 49s) (34000 21%) 4.0033\n",
      "57m 28s (- 200m 57s) (35000 22%) 4.0012\n",
      "59m 3s (- 199m 5s) (36000 22%) 3.9909\n",
      "60m 43s (- 197m 32s) (37000 23%) 3.9780\n",
      "62m 19s (- 195m 46s) (38000 24%) 3.9473\n",
      "63m 57s (- 194m 5s) (39000 24%) 3.9690\n",
      "65m 36s (- 192m 29s) (40000 25%) 3.9674\n",
      "67m 14s (- 190m 49s) (41000 26%) 3.9455\n",
      "68m 51s (- 189m 7s) (42000 26%) 3.9983\n",
      "70m 26s (- 187m 21s) (43000 27%) 3.9169\n",
      "72m 4s (- 185m 41s) (44000 27%) 3.9511\n",
      "73m 41s (- 183m 59s) (45000 28%) 3.9572\n",
      "75m 17s (- 182m 17s) (46000 29%) 3.9370\n",
      "76m 56s (- 180m 39s) (47000 29%) 3.9546\n",
      "78m 31s (- 178m 55s) (48000 30%) 3.9287\n",
      "80m 8s (- 177m 13s) (49000 31%) 3.9083\n",
      "81m 46s (- 175m 35s) (50000 31%) 3.9532\n",
      "83m 22s (- 173m 53s) (51000 32%) 3.9354\n",
      "84m 58s (- 172m 9s) (52000 33%) 3.8687\n",
      "86m 35s (- 170m 30s) (53000 33%) 3.8920\n",
      "88m 13s (- 168m 51s) (54000 34%) 3.9156\n",
      "89m 47s (- 167m 7s) (55000 34%) 3.9084\n",
      "91m 23s (- 165m 25s) (56000 35%) 3.9211\n",
      "93m 0s (- 163m 45s) (57000 36%) 3.8854\n",
      "94m 36s (- 162m 4s) (58000 36%) 3.9059\n",
      "96m 12s (- 160m 23s) (59000 37%) 3.8651\n",
      "97m 48s (- 158m 43s) (60000 38%) 3.8750\n",
      "99m 25s (- 157m 3s) (61000 38%) 3.8540\n",
      "101m 2s (- 155m 25s) (62000 39%) 3.8325\n",
      "102m 40s (- 153m 47s) (63000 40%) 3.8869\n",
      "104m 18s (- 152m 9s) (64000 40%) 3.8585\n",
      "105m 54s (- 150m 29s) (65000 41%) 3.8430\n",
      "107m 32s (- 148m 51s) (66000 41%) 3.8841\n",
      "109m 8s (- 147m 12s) (67000 42%) 3.8490\n",
      "110m 45s (- 145m 33s) (68000 43%) 3.8653\n",
      "112m 23s (- 143m 56s) (69000 43%) 3.8339\n",
      "113m 58s (- 142m 14s) (70000 44%) 3.8203\n",
      "115m 33s (- 140m 34s) (71000 45%) 3.8010\n",
      "117m 11s (- 138m 56s) (72000 45%) 3.8343\n",
      "118m 44s (- 137m 14s) (73000 46%) 3.7947\n",
      "120m 20s (- 135m 33s) (74000 47%) 3.8063\n",
      "121m 54s (- 133m 53s) (75000 47%) 3.8230\n",
      "123m 29s (- 132m 12s) (76000 48%) 3.8173\n",
      "125m 7s (- 130m 34s) (77000 48%) 3.7964\n",
      "126m 42s (- 128m 55s) (78000 49%) 3.8032\n",
      "128m 16s (- 127m 14s) (79000 50%) 3.8438\n",
      "129m 51s (- 125m 34s) (80000 50%) 3.7994\n",
      "131m 26s (- 123m 55s) (81000 51%) 3.8101\n",
      "133m 2s (- 122m 16s) (82000 52%) 3.7881\n",
      "134m 37s (- 120m 36s) (83000 52%) 3.8235\n",
      "136m 12s (- 118m 57s) (84000 53%) 3.7632\n",
      "137m 46s (- 117m 17s) (85000 54%) 3.7899\n",
      "139m 20s (- 115m 38s) (86000 54%) 3.7787\n",
      "140m 57s (- 114m 0s) (87000 55%) 3.7621\n",
      "142m 32s (- 112m 21s) (88000 55%) 3.7752\n",
      "144m 6s (- 110m 41s) (89000 56%) 3.7500\n",
      "145m 40s (- 109m 1s) (90000 57%) 3.7709\n",
      "147m 16s (- 107m 24s) (91000 57%) 3.7807\n",
      "148m 52s (- 105m 46s) (92000 58%) 3.7446\n",
      "150m 28s (- 104m 8s) (93000 59%) 3.7379\n",
      "152m 4s (- 102m 30s) (94000 59%) 3.7684\n",
      "153m 39s (- 100m 52s) (95000 60%) 3.7838\n",
      "155m 14s (- 99m 14s) (96000 61%) 3.7378\n",
      "156m 48s (- 97m 34s) (97000 61%) 3.7436\n",
      "158m 24s (- 95m 57s) (98000 62%) 3.7386\n",
      "160m 0s (- 94m 19s) (99000 62%) 3.7209\n",
      "161m 34s (- 92m 41s) (100000 63%) 3.7156\n",
      "163m 11s (- 91m 4s) (101000 64%) 3.7814\n",
      "164m 47s (- 89m 26s) (102000 64%) 3.7421\n",
      "166m 21s (- 87m 48s) (103000 65%) 3.7556\n",
      "167m 56s (- 86m 10s) (104000 66%) 3.7494\n",
      "169m 29s (- 84m 31s) (105000 66%) 3.7397\n",
      "171m 5s (- 82m 54s) (106000 67%) 3.7454\n",
      "172m 40s (- 81m 16s) (107000 67%) 3.7358\n",
      "174m 17s (- 79m 39s) (108000 68%) 3.7569\n",
      "175m 50s (- 78m 1s) (109000 69%) 3.6731\n",
      "177m 25s (- 76m 23s) (110000 69%) 3.7032\n",
      "178m 59s (- 74m 45s) (111000 70%) 3.7294\n",
      "180m 35s (- 73m 8s) (112000 71%) 3.7126\n",
      "182m 9s (- 71m 31s) (113000 71%) 3.6969\n",
      "183m 47s (- 69m 54s) (114000 72%) 3.7389\n",
      "185m 23s (- 68m 17s) (115000 73%) 3.7365\n",
      "186m 59s (- 66m 40s) (116000 73%) 3.7520\n",
      "188m 33s (- 65m 3s) (117000 74%) 3.6571\n",
      "190m 7s (- 63m 25s) (118000 74%) 3.6834\n",
      "191m 42s (- 61m 48s) (119000 75%) 3.6491\n",
      "193m 16s (- 60m 10s) (120000 76%) 3.6994\n",
      "194m 49s (- 58m 33s) (121000 76%) 3.6779\n",
      "196m 23s (- 56m 55s) (122000 77%) 3.6592\n",
      "197m 57s (- 55m 18s) (123000 78%) 3.6944\n",
      "199m 33s (- 53m 41s) (124000 78%) 3.6728\n",
      "201m 9s (- 52m 4s) (125000 79%) 3.7253\n",
      "202m 43s (- 50m 27s) (126000 80%) 3.7285\n",
      "204m 19s (- 48m 50s) (127000 80%) 3.7204\n",
      "205m 54s (- 47m 14s) (128000 81%) 3.7094\n",
      "207m 28s (- 45m 37s) (129000 81%) 3.6929\n",
      "209m 4s (- 44m 0s) (130000 82%) 3.6865\n",
      "210m 39s (- 42m 23s) (131000 83%) 3.7080\n",
      "212m 13s (- 40m 46s) (132000 83%) 3.6763\n",
      "213m 47s (- 39m 9s) (133000 84%) 3.6749\n",
      "215m 21s (- 37m 32s) (134000 85%) 3.7178\n",
      "216m 54s (- 35m 56s) (135000 85%) 3.6806\n",
      "218m 28s (- 34m 19s) (136000 86%) 3.6856\n",
      "220m 4s (- 32m 42s) (137000 87%) 3.6515\n",
      "221m 40s (- 31m 6s) (138000 87%) 3.6738\n",
      "223m 16s (- 29m 29s) (139000 88%) 3.7136\n",
      "224m 50s (- 27m 53s) (140000 88%) 3.6797\n",
      "226m 25s (- 26m 16s) (141000 89%) 3.6555\n",
      "228m 1s (- 24m 40s) (142000 90%) 3.6859\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 33 is out of bounds for dimension 0 with size 33",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-aa29b66df83d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBDLSTMPredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrainEpochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-32fee9d3295e>\u001b[0m in \u001b[0;36mtrainEpochs\u001b[1;34m(model, epochs, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtarget_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mprint_train_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mplot_train_loss_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-2b23382b26bc>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(input_tensor, target_tensor, model, optimizer, criterion, max_length)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 33 is out of bounds for dimension 0 with size 33"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embedding_dim = 256\n",
    "epochs = 1\n",
    "model = BDLSTMPredictor(data.n_tokens, embedding_dim, hidden_size).to(device)\n",
    "trainEpochs(model, epochs, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluateRandomly(model, 10)\n",
    "\n",
    "outputs = evaluate(model, \"だが「市場の論理」万能のグローバル化はどうか。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./weights/token_level_bd_\"+str(epochs)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
