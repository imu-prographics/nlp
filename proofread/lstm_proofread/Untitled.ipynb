{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1ce0f800130>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = 17\n",
    "emb = 16\n",
    "hid = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = nn.Embedding(inp, emb)\n",
    "lstm = nn.LSTM(emb, hid)\n",
    "linear = nn.Linear(hid, inp)\n",
    "dropout = nn.Dropout(0.1)\n",
    "softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeds = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.initHidden()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeds(input)\n",
    "        lstm_out, hidden = self.lstm(embeds.view(len(input), 1, -1), hidden)\n",
    "        output = self.linear(lstm_out.view(len(input), -1))\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BDLSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(BDLSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeds = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, input_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.initHidden()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeds(input)\n",
    "        lstm_out, hidden = self.lstm(embeds.view(len(input), 1, -1), hidden)\n",
    "        cbow = self.make_cbow(lstm_out, hidden)\n",
    "        output = self.linear(cbow)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def make_cbow(self, lstm_out, hidden):\n",
    "        lstm_out = lstm_out.squeeze()\n",
    "        forward, reverse = torch.chunk(lstm_out,2,dim=1)\n",
    "        output = []\n",
    "        for n in range(1, len(forward)-1):\n",
    "            tmp = torch.cat([forward[n-1,:], reverse[n+1,:]], dim=0)\n",
    "            output.append(tmp)\n",
    "        output = torch.stack(output, dim=0)\n",
    "        return output\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return (autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(2, 1, self.hidden_dim)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "inputs = [torch.tensor([1,2,1,2,1,3,0,4,0,5,1,3,0,4,0,5,1], device=device) for _ in range(100)]\n",
    "targets = [torch.tensor([2,1,2,1,3,0,4,0,5,1,3,0,4,0,5,1,6], device=device) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 17])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lstm = LSTMPredictor(inp, emb, hid).to(device)\n",
    "bilstm = BDLSTMPredictor(inp, emb, hid).to(device)\n",
    "opt_lstm = optim.SGD(lstm.parameters(), lr=0.01)\n",
    "opt_bilstm = optim.SGD(bilstm.parameters(), lr=0.01)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "'''\n",
    "for i, t in zip(inputs, targets):\n",
    "    hidden = lstm.initHidden()\n",
    "    out, hidden = lstm(i, hidden)\n",
    "    loss = criterion(out, t)\n",
    "    loss.backward()\n",
    "    opt_lstm.step()\n",
    "'''\n",
    "for i, t in zip(inputs, targets):\n",
    "    hidden = bilstm.initHidden()\n",
    "    out, hidden = bilstm(i, hidden)\n",
    "    t = t[1:-1]\n",
    "    loss = criterion(out, t)\n",
    "    loss.backward()\n",
    "    opt_bilstm.step()\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 17])\n",
      "tensor(1, device='cuda:0') tensor([1], device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor([2], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([1], device='cuda:0')\n",
      "tensor(3, device='cuda:0') tensor([3], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([0], device='cuda:0')\n",
      "tensor(4, device='cuda:0') tensor([4], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([0], device='cuda:0')\n",
      "tensor(5, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([1], device='cuda:0')\n",
      "tensor(3, device='cuda:0') tensor([3], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([0], device='cuda:0')\n",
      "tensor(4, device='cuda:0') tensor([4], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([0], device='cuda:0')\n",
      "tensor(5, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bilstm.eval()\n",
    "with torch.no_grad():\n",
    "    hidden = bilstm.initHidden()\n",
    "    out, hidden = bilstm(inputs[0], hidden)\n",
    "    print(out.shape)\n",
    "    #print(out)\n",
    "    topv, topi = out.topk(1)\n",
    "    for n,i in enumerate(topi):\n",
    "        print(targets[0][n+1], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17, 17])\n",
      "tensor(2, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(2, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(3, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(4, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(5, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(3, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(4, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(0, device='cuda:0') tensor([16], device='cuda:0')\n",
      "tensor(5, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(1, device='cuda:0') tensor([5], device='cuda:0')\n",
      "tensor(6, device='cuda:0') tensor([16], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "lstm.eval()\n",
    "with torch.no_grad():\n",
    "    hidden = lstm.initHidden()\n",
    "    out, hidden = lstm(inputs[0], hidden)\n",
    "    print(out.shape)\n",
    "    #print(out)\n",
    "    topv, topi = out.topk(1)\n",
    "    for n,i in enumerate(topi):\n",
    "        print(targets[0][n], i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emba = nn.Embedding(inp, emb).to(device)\n",
    "lma = nn.LSTM(emb, hid).to(device)\n",
    "lina = nn.Linear(hid, inp).to(device)\n",
    "dropa = nn.Dropout(0.1).to(device)\n",
    "softa = nn.LogSoftmax(dim=1).to(device)\n",
    "hida = (autograd.Variable(torch.zeros(1, 1, hid)).cuda(),\n",
    "            autograd.Variable(torch.zeros(1, 1, hid)).cuda())\n",
    "\n",
    "embb = nn.Embedding(inp, emb).to(device)\n",
    "lmb = nn.LSTM(emb, hid, bidirectional=True).to(device)\n",
    "linb = nn.Linear(hid * 2, inp).to(device)\n",
    "dropb = nn.Dropout(0.1).to(device)\n",
    "softb = nn.LogSoftmax(dim=1).to(device)\n",
    "hidb = (autograd.Variable(torch.zeros(2, 1, hid)).cuda(),\n",
    "            autograd.Variable(torch.zeros(2, 1, hid)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_out = emba(inputs[0])\n",
    "lstm_out, hidden = lma(a_out.view(len(inputs[0]), 1, -1), hida)\n",
    "print('lstm:',lstm_out.shape, hidden[0].shape)\n",
    "a_out = lina(a_out.view(len(inputs[0]), -1))\n",
    "print('linear:', a_out.shape)\n",
    "a_out = dropa(a_out)\n",
    "a_out = softa(a_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilstm: torch.Size([17, 1, 32]) torch.Size([2, 1, 16])\n",
      "torch.Size([17, 32])\n"
     ]
    }
   ],
   "source": [
    "b_out = embb(inputs[0])\n",
    "b_out, b_hidden = lmb(b_out.view(len(inputs[0]), 1, -1), hidb)\n",
    "print('bilstm:', b_out.shape, b_hidden[0].shape)\n",
    "print(b_out.view(len(inputs[0]), -1).shape)\n",
    "#b_out = linb(b_out.view(len(inputs[0]), -1))\n",
    "#print('linear:', b_out.shape)\n",
    "#b_out = dropb(b_out)\n",
    "#b_out = softb(b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq: torch.Size([17, 32])\n",
      "chunk: torch.Size([17, 16])\n",
      "out: torch.Size([15, 32])\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-37-db926d2b42dc>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-db926d2b42dc>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    return output\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "lstm_out = b_out.squeeze()\n",
    "#17,32\n",
    "print('sq:', lstm_out.shape)\n",
    "forward, reverse = torch.chunk(lstm_out,2,dim=1)\n",
    "print('chunk:',forward.shape)\n",
    "#output = torch.zeros(len(lstm_out)-2, hidden).to(device)\n",
    "# 15,16\n",
    "output = []\n",
    "for n in range(1, len(forward)-1):\n",
    "\n",
    "    tmp = torch.cat([forward[n-1,:], reverse[n+1,:]], dim=0)\n",
    "\n",
    "    output.append(tmp)\n",
    "output = torch.stack(output, dim=0)\n",
    "print('out:',output.shape)\n",
    "#out:17-2, 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
