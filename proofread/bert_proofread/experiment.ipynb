{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "必要ModuleをImport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "from utils import GELU, PositionwiseFeedForward, LayerNorm, SublayerConnection, LayerNorm\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "read_dir = './data/merged_bert/'\n",
    "output_dir = './output/merged_bert/'\n",
    "processed_train_txt = read_dir + 'train_X.txt'\n",
    "processed_valid_txt = read_dir + 'valid_X.txt'\n",
    "processed_test_txt = read_dir + 'test_X.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attentionセルを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Scaled Dot Product Attention\n",
    "    \"\"\"\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(query.size(-1))\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        return torch.matmul(p_attn, value), p_attn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Head Attentionを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2) for l, x in zip(self.linear_layers, (query, key, value))]\n",
    "\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "\n",
    "        return self.output_linear(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformerを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTクラスを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, hidden=768, n_layers=12, attn_heads=12, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_heads = attn_heads\n",
    "        self.feed_forward_hidden = hidden * 4\n",
    "        # embedding for BERT\n",
    "        self.embedding = BERTEmbedding(vocab_size=vocab_size, embed_size=hidden, dropout=dropout)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList([TransformerBlock(hidden, attn_heads, hidden * 4, dropout) for _ in range(n_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # xの中で0以上は1, 0未満は0として, maskテンソルを作る\n",
    "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer.forward(x, mask)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERTのEmbedding層を定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embed_size=512):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)).float().exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class BERTEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
    "        self.position = PositionalEmbedding(d_model=self.token.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "    #def forward(self, sequence, segment_label):\n",
    "    def forward(self, sequence):\n",
    "        x = self.token(sequence) + self.position(sequence)\n",
    "        return self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習用にマスク予測の層を追加する<br>\n",
    "Next Sentence Prediction用のクラスは削除してある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTLM(nn.Module):\n",
    "    def __init__(self, bert: BERT, vocab_size):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.mask_lm = MaskedLanguageModel(self.bert.hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return self.mask_lm(x)\n",
    "\n",
    "class MaskedLanguageModel(nn.Module):\n",
    "    def __init__(self, hidden, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTESD(nn.Module):\n",
    "    def __init__(self, bert: BERT):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.pr = ErrorSentenceDetectionHead(self.bert.hidden)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return self.pr(x)\n",
    "\n",
    "class ErrorSentenceDetectionHead(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTHybridESD(nn.Module):\n",
    "    def __init__(self, epd):\n",
    "        super().__init__()\n",
    "        self.epd = epd\n",
    "        self.esd = ErrorSentenceDetectionHead(9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.epd(x)\n",
    "        return self.esd(x)\n",
    "\n",
    "class ErrorSentenceDetectionHead(nn.Module):\n",
    "    def __init__(self, hidden):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden, 2)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTEPD(nn.Module):\n",
    "    def __init__(self, bert: BERT, head):\n",
    "        super().__init__()\n",
    "        self.bert = bert\n",
    "        self.epd = ErrorPositionDetectionHead(self.bert.hidden, head)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bert(x)\n",
    "        return self.epd(x)\n",
    "\n",
    "class ErrorPositionDetectionHead(nn.Module):\n",
    "    def __init__(self, hidden, head):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(hidden, head)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT用のVocabを生成するクラスを定義する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "class TorchVocab(object):\n",
    "    \"\"\"\n",
    "    :property freqs: collections.Counter, コーパス中の単語の出現頻度を保持するオブジェクト\n",
    "    :property stoi: collections.defaultdict, string → id の対応を示す辞書\n",
    "    :property itos: collections.defaultdict, id → string の対応を示す辞書\n",
    "    \"\"\"\n",
    "    def __init__(self, counter, max_size=None, min_freq=1, specials=['<pad>', '<oov>'],\n",
    "                 vectors=None, unk_init=None, vectors_cache=None):\n",
    "        \"\"\"\n",
    "        :param coutenr: collections.Counter, データ中に含まれる単語の頻度を計測するためのcounter\n",
    "        :param max_size: int, vocabularyの最大のサイズ. Noneの場合は最大値なし. defaultはNone\n",
    "        :param min_freq: int, vocabulary中の単語の最低出現頻度. この数以下の出現回数の単語はvocabularyに加えられない.\n",
    "        :param specials: list of str, vocabularyにあらかじめ登録するtoken\n",
    "        :param vecors: list of vectors, 事前学習済みのベクトル. ex)Vocab.load_vectors\n",
    "        \"\"\"\n",
    "        self.freqs = counter\n",
    "        counter = counter.copy()\n",
    "        min_freq = max(min_freq, 1)\n",
    "\n",
    "        self.itos = list(specials)\n",
    "        # special tokensの出現頻度はvocabulary作成の際にカウントされない\n",
    "        for tok in specials:\n",
    "            del counter[tok]\n",
    "\n",
    "        max_size = None if max_size is None else max_size + len(self.itos)\n",
    "\n",
    "        # まず頻度でソートし、次に文字順で並び替える\n",
    "        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        # 出現頻度がmin_freq未満のものはvocabに加えない\n",
    "        for word, freq in words_and_frequencies:\n",
    "            if freq < min_freq or len(self.itos) == max_size:\n",
    "                break\n",
    "            self.itos.append(word)\n",
    "\n",
    "        # dictのk,vをいれかえてstoiを作成する\n",
    "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
    "\n",
    "        self.vectors = None\n",
    "        if vectors is not None:\n",
    "            self.load_vectors(vectors, unk_init=unk_init, cache=vectors_cache)\n",
    "        else:\n",
    "            assert unk_init is None and vectors_cache is None\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if self.freqs != other.freqs:\n",
    "            return False\n",
    "        if self.stoi != other.stoi:\n",
    "            return False\n",
    "        if self.itos != other.itos:\n",
    "            return False\n",
    "        if self.vectors != other.vectors:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def vocab_rerank(self):\n",
    "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
    "\n",
    "    def extend(self, v, sort=False):\n",
    "        words = sorted(v.itos) if sort else v.itos\n",
    "        for w in words:\n",
    "            if w not in self.stoi:\n",
    "                self.itos.append(w)\n",
    "                self.stoi[w] = len(self.itos) - 1\n",
    "\n",
    "\n",
    "class Vocab(TorchVocab):\n",
    "    def __init__(self, counter, max_size=None, min_freq=1):\n",
    "        self.pad_index = 0\n",
    "        self.unk_index = 1\n",
    "        self.eos_index = 2\n",
    "        self.sos_index = 3\n",
    "        self.mask_index = 4\n",
    "        super().__init__(counter, specials=[\"<pad>\", \"<unk>\", \"<eos>\", \"<sos>\", \"<mask>\"], max_size=max_size, min_freq=min_freq)\n",
    "\n",
    "    # override用\n",
    "    def to_seq(self, sentece, seq_len, with_eos=False, with_sos=False) -> list:\n",
    "        pass\n",
    "\n",
    "    # override用\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'Vocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def save_vocab(self, vocab_path):\n",
    "        with open(vocab_path, \"wb\") as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "\n",
    "# テキストファイルからvocabを作成する\n",
    "class WordVocab(Vocab):\n",
    "    def __init__(self, texts, max_size=None, min_freq=1):\n",
    "        print(\"Building Vocab\")\n",
    "        counter = Counter()\n",
    "        for line in texts:\n",
    "            if isinstance(line, list):\n",
    "                words = line\n",
    "            else:\n",
    "                words = line.replace(\"\\n\", \"\").replace(\"\\t\", \"\").split()\n",
    "\n",
    "            for word in words:\n",
    "                counter[word] += 1\n",
    "        super().__init__(counter, max_size=max_size, min_freq=min_freq)\n",
    "\n",
    "    def to_seq(self, sentence, seq_len=None, with_eos=False, with_sos=False, with_len=False):\n",
    "        if isinstance(sentence, str):\n",
    "            sentence = sentence.split()\n",
    "\n",
    "        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n",
    "\n",
    "        if with_eos:\n",
    "            seq += [self.eos_index]  # this would be index 1\n",
    "        if with_sos:\n",
    "            seq = [self.sos_index] + seq\n",
    "\n",
    "        origin_seq_len = len(seq)\n",
    "\n",
    "        if seq_len is None:\n",
    "            pass\n",
    "        elif len(seq) <= seq_len:\n",
    "            seq += [self.pad_index for _ in range(seq_len - len(seq))]\n",
    "        else:\n",
    "            seq = seq[:seq_len]\n",
    "\n",
    "        return (seq, origin_seq_len) if with_len else seq\n",
    "\n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        words = [self.itos[idx]\n",
    "                 if idx < len(self.itos)\n",
    "                 else \"<%d>\" % idx\n",
    "                 for idx in seq\n",
    "                 if not with_pad or idx != self.pad_index]\n",
    "\n",
    "        return \" \".join(words) if join else words\n",
    "\n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
    "        with open(vocab_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "\n",
    "def build(corpus_path, output_path, vocab_size=None, encoding='utf-8', min_freq=1):\n",
    "    with open(corpus_path, \"r\", encoding=encoding) as f:\n",
    "        vocab = WordVocab(f, max_size=vocab_size, min_freq=min_freq)\n",
    "\n",
    "    print(\"VOCAB SIZE:\", len(vocab))\n",
    "    vocab.save_vocab(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloaderを定義する.<br>\n",
    "ここで文章中の単語をMASKする処理を行う<br>\n",
    "Windowsでの並列化処理のために外部ファイル(dataset.py)で定義する  \n",
    "MACやLinuxならこのipynbに直接定義しても良いはず"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainerクラスを定義する.  \n",
    "Masked Language Model : 文章中の一部の単語をマスクして,予測を行うタスク.  \n",
    "- `save_bert`はbert本体のみを保存する\n",
    "- `save_pretrain`は事前学習用のHeadも含んだ全体を保存する\n",
    "- `load_bert`と`load_pretrain`も同様"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "dt_now = str(datetime.datetime.now()).replace(' ', '')\n",
    "dt_now = dt_now.replace(':','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "class ESDTrainer:\n",
    "    def __init__(self, bert: BERT, train_dataloader: DataLoader, \n",
    "                 valid_dataloader: DataLoader = None,\n",
    "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01,\n",
    "                 with_cuda: bool = True, log_freq: int = 10):\n",
    "        # GPU環境において、GPUを指定しているかのフラグ\n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
    "\n",
    "        self.bert = bert\n",
    "        self.model = BERTESD(bert).to(self.device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "        self.valid_data = valid_dataloader\n",
    "\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "        # masked_token予測のためのLoss関数を設定\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.train_accs = []\n",
    "        self.valid_accs = []\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def valid(self, epoch):\n",
    "        self.iteration(epoch, self.valid_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        str_code = \"train\" if train else \"valid\"\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=\"EP_%s:%d\" % (str_code, epoch), total=len(data_loader), bar_format=\"{l_bar}{r_bar}\")\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "\n",
    "        for i, data in data_iter:\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "            pr_output = self.model.forward(data[\"bert_input\"])\n",
    "            pr_loss = self.criterion(pr_output, data[\"label\"])\n",
    "            loss = pr_loss\n",
    "            # training時のみ,backwardとoptimizer更新を行う\n",
    "            if train:\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "            \n",
    "            correct = pr_output.argmax(dim=-1).eq(data[\"label\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"label\"].nelement()\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "\n",
    "        print(\"EP%d_%s, avg_loss=\" % (epoch, str_code), avg_loss / len(data_iter),  \"total_acc=\", total_correct * 100.0 / total_element)\n",
    "        if train:\n",
    "            self.train_losses.append(avg_loss / len(data_iter))\n",
    "            self.train_accs.append(total_correct * 100.0 / total_element)\n",
    "        else:\n",
    "            self.valid_losses.append(avg_loss / len(data_iter))\n",
    "            self.valid_accs.append(total_correct * 100.0 / total_element)\n",
    "        \n",
    "    def save_bert(self, epoch, file_path=output_dir + \"bert_model\"):\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(self.bert.state_dict(), output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def save_pretrain(self, epoch, file_path=output_dir + \"mlm_model\"):\n",
    "        state = {\n",
    "            'epoch' : epoch,\n",
    "            'state_dict' : self.model.module.state_dict(),\n",
    "            'optimizer' : self.optim.state_dict()\n",
    "        }\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(state, output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    " \n",
    "    def load_bert(self, file_path):\n",
    "        self.bert.state_dict(torch.load(file_path))\n",
    "        \n",
    "    def load_pretrain(self, file_path):\n",
    "        state = torch.load(file_path)\n",
    "        #state = self.fix_model_state_dict(state)\n",
    "        self.model.module.load_state_dict(state['state_dict'])\n",
    "        self.optim.load_state_dict(state['optimizer'])\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridESDTrainer:\n",
    "    def __init__(self, bert: BERT,train_dataloader: DataLoader, \n",
    "                 valid_dataloader: DataLoader = None,\n",
    "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01,\n",
    "                 with_cuda: bool = True, log_freq: int = 10, head = 9):\n",
    "        # GPU環境において、GPUを指定しているかのフラグ\n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
    "\n",
    "        self.bert = bert\n",
    "        self.epd = BERTEPD(bert, head)\n",
    "        self.model = BERTHybridESD(self.epd).to(self.device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "        self.valid_data = valid_dataloader\n",
    "\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "        # masked_token予測のためのLoss関数を設定\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.train_accs = []\n",
    "        self.valid_accs = []\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def valid(self, epoch):\n",
    "        self.iteration(epoch, self.valid_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        str_code = \"train\" if train else \"valid\"\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=\"EP_%s:%d\" % (str_code, epoch), total=len(data_loader), bar_format=\"{l_bar}{r_bar}\")\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "\n",
    "        for i, data in data_iter:\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "            pr_output = self.model.forward(data[\"bert_input\"])\n",
    "            pr_loss = self.criterion(pr_output, data[\"label\"])\n",
    "            loss = pr_loss\n",
    "            # training時のみ,backwardとoptimizer更新を行う\n",
    "            if train:\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "            \n",
    "            correct = pr_output.argmax(dim=-1).eq(data[\"label\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"label\"].nelement()\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "\n",
    "        print(\"EP%d_%s, avg_loss=\" % (epoch, str_code), avg_loss / len(data_iter),  \"total_acc=\", total_correct * 100.0 / total_element)\n",
    "        if train:\n",
    "            self.train_losses.append(avg_loss / len(data_iter))\n",
    "            self.train_accs.append(total_correct * 100.0 / total_element)\n",
    "        else:\n",
    "            self.valid_losses.append(avg_loss / len(data_iter))\n",
    "            self.valid_accs.append(total_correct * 100.0 / total_element)\n",
    "        \n",
    "    def save_bert(self, epoch, file_path=output_dir + \"bert_model\"):\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(self.bert.state_dict(), output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def save_pretrain(self, epoch, file_path=output_dir + \"mlm_model\"):\n",
    "        state = {\n",
    "            'epoch' : epoch,\n",
    "            'state_dict' : self.model.module.state_dict(),\n",
    "            'optimizer' : self.optim.state_dict()\n",
    "        }\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(state, output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    " \n",
    "    def load_bert(self, file_path):\n",
    "        self.bert.state_dict(torch.load(file_path))\n",
    "    \n",
    "    def load_epd(self, file_path):\n",
    "        state = torch.load(file_path)\n",
    "        self.epd.load_state_dict(state['state_dict'])\n",
    "    \n",
    "    def load_pretrain(self, file_path):\n",
    "        state = torch.load(file_path)\n",
    "        #state = self.fix_model_state_dict(state)\n",
    "        self.model.module.load_state_dict(state['state_dict'])\n",
    "        self.optim.load_state_dict(state['optimizer'])\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EPDTrainer:\n",
    "    def __init__(self, bert: BERT, train_dataloader: DataLoader, \n",
    "                 valid_dataloader: DataLoader = None,\n",
    "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01,\n",
    "                 with_cuda: bool = True, log_freq: int = 10, head = 2):\n",
    "        # GPU環境において、GPUを指定しているかのフラグ\n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
    "\n",
    "        self.bert = bert\n",
    "        self.model = BERTEPD(bert, head).to(self.device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "        self.valid_data = valid_dataloader\n",
    "\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "        # masked_token予測のためのLoss関数を設定\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.train_accs = []\n",
    "        self.valid_accs = []\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def valid(self, epoch):\n",
    "        self.iteration(epoch, self.valid_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        str_code = \"train\" if train else \"valid\"\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=\"EP_%s:%d\" % (str_code, epoch), total=len(data_loader), bar_format=\"{l_bar}{r_bar}\")\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "\n",
    "        for i, data in data_iter:\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "            pr_output = self.model.forward(data[\"bert_input\"])\n",
    "            pr_loss = self.criterion(pr_output.transpose(1, 2), data[\"token_label\"])\n",
    "            loss = pr_loss\n",
    "            # training時のみ,backwardとoptimizer更新を行う\n",
    "            if train:\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "            \n",
    "            correct = pr_output.argmax(dim=-1).eq(data[\"token_label\"]).sum().item()\n",
    "\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "            total_correct += correct\n",
    "            total_element += data[\"token_label\"].nelement() * 128\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "\n",
    "        print(\"EP%d_%s, avg_loss=\" % (epoch, str_code), avg_loss / len(data_iter),  \"total_acc=\", total_correct * 100.0 / total_element)\n",
    "        if train:\n",
    "            self.train_losses.append(avg_loss / len(data_iter))\n",
    "            self.train_accs.append(total_correct * 100.0 / total_element)\n",
    "        else:\n",
    "            self.valid_losses.append(avg_loss / len(data_iter))\n",
    "            self.valid_accs.append(total_correct * 100.0 / total_element)\n",
    "        \n",
    "    def save_bert(self, epoch, file_path=output_dir + \"bert_model\"):\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(self.bert.state_dict(), output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def save_pretrain(self, epoch, file_path=output_dir + \"mlm_model\"):\n",
    "        state = {\n",
    "            'epoch' : epoch,\n",
    "            'state_dict' : self.model.module.state_dict(),\n",
    "            'optimizer' : self.optim.state_dict()\n",
    "        }\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(state, output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    " \n",
    "    def load_bert(self, file_path):\n",
    "        self.bert.state_dict(torch.load(file_path))\n",
    "        \n",
    "    def load_pretrain(self, file_path):\n",
    "        state = torch.load(file_path)\n",
    "        self.model.module.load_state_dict(state['state_dict'])\n",
    "        self.optim.load_state_dict(state['optimizer'])\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLMTrainer:\n",
    "    def __init__(self, bert: BERT, vocab_size: int,\n",
    "                 train_dataloader: DataLoader, valid_dataloader: DataLoader = None,\n",
    "                 lr: float = 1e-4, betas=(0.9, 0.999), weight_decay: float = 0.01,\n",
    "                 with_cuda: bool = True, log_freq: int = 10):\n",
    "        # GPU環境において、GPUを指定しているかのフラグ\n",
    "        cuda_condition = torch.cuda.is_available() and with_cuda\n",
    "        self.device = torch.device(\"cuda:0\" if cuda_condition else \"cpu\")\n",
    "        self.bert = bert\n",
    "        self.model = BERTLM(bert, vocab_size).to(self.device)\n",
    "\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Using %d GPUS for BERT\" % torch.cuda.device_count())\n",
    "            self.model = nn.DataParallel(self.model)\n",
    "\n",
    "        self.train_data = train_dataloader\n",
    "        self.valid_data = valid_dataloader\n",
    "\n",
    "        self.optim = Adam(self.model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "\n",
    "        # masked_token予測のためのLoss関数を設定\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.log_freq = log_freq\n",
    "        print(\"Total Parameters:\", sum([p.nelement() for p in self.model.parameters()]))\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        self.train_accs = []\n",
    "        self.valid_accs = []\n",
    "\n",
    "    def train(self, epoch):\n",
    "        self.iteration(epoch, self.train_data)\n",
    "\n",
    "    def valid(self, epoch):\n",
    "        self.iteration(epoch, self.valid_data, train=False)\n",
    "\n",
    "    def iteration(self, epoch, data_loader, train=True):\n",
    "        \"\"\"\n",
    "        :param epoch: 現在のepoch\n",
    "        :param data_loader: torch.utils.data.DataLoader\n",
    "        :param train: trainかtestかのbool値\n",
    "        \"\"\"\n",
    "        str_code = \"train\" if train else \"valid\"\n",
    "        data_iter = tqdm.tqdm(enumerate(data_loader), desc=\"EP_%s:%d\" % (str_code, epoch), total=len(data_loader), bar_format=\"{l_bar}{r_bar}\")\n",
    "        avg_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_element = 0\n",
    "\n",
    "        for i, data in data_iter:\n",
    "            # 0. batch_dataはGPU or CPUに載せる\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "            # 1. forward the next_sentence_prediction and masked_lm model\n",
    "            mask_lm_output = self.model.forward(data[\"bert_input\"])\n",
    "            # 2-2. NLLLoss(negative log likelihood) : predicting masked token word\n",
    "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data[\"bert_label\"])\n",
    "            # 2-3. next_lossとmask_lossの合計をlossとする\n",
    "            loss = mask_loss\n",
    "            # 3. training時のみ,backwardとoptimizer更新を行う\n",
    "            if train:\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "\n",
    "            correct = mask_lm_output.argmax(dim=-1).eq(data[\"bert_label\"]).sum().item()\n",
    "            avg_loss += loss.item()\n",
    "            total_element += data[\"bert_label\"].nelement() * 128\n",
    "            total_correct += correct\n",
    "            post_fix = {\n",
    "                \"epoch\": epoch,\n",
    "                \"iter\": i,\n",
    "                \"avg_loss\": avg_loss / (i + 1),\n",
    "                \"avg_acc\": total_correct / total_element * 100,\n",
    "                \"loss\": loss.item()\n",
    "            }\n",
    "\n",
    "            if i % self.log_freq == 0:\n",
    "                data_iter.write(str(post_fix))\n",
    "            \n",
    "        if train:\n",
    "            self.train_losses.append(avg_loss / len(data_iter))\n",
    "            self.train_accs.append(total_correct * 100.0 / total_element)\n",
    "        else:\n",
    "            self.valid_losses.append(avg_loss / len(data_iter))\n",
    "            self.valid_accs.append(total_correct * 100.0 / total_element)\n",
    "\n",
    "        print(\"EP%d_%s, avg_loss=\" % (epoch, str_code), avg_loss / len(data_iter))\n",
    "\n",
    "        \n",
    "    def save_bert(self, epoch, file_path=output_dir + \"bert\"):\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(self.bert.state_dict(), output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    "    \n",
    "    def save_pretrain(self, epoch, file_path=output_dir + \"mlm\"):\n",
    "        state = {\n",
    "            'epoch' : epoch,\n",
    "            'state_dict' : self.model.module.state_dict(),\n",
    "            'optimizer' : self.optim.state_dict(),\n",
    "            'train_loss' : self.train_losses,\n",
    "            'valid_loss' : self.valid_losses\n",
    "        }\n",
    "        output_path = file_path + \".ep%d\" % epoch\n",
    "        torch.save(state, output_path)\n",
    "        self.bert.to(self.device)\n",
    "        print(\"EP:%d Model Saved on:\" % epoch, output_path)\n",
    "        return output_path\n",
    " \n",
    "    def load_bert(self, file_path):\n",
    "        self.bert.state_dict(torch.load(file_path))\n",
    "        \n",
    "    def load_pretrain(self, file_path):\n",
    "        state = torch.load(file_path)\n",
    "        self.model.module.load_state_dict(state['state_dict'])\n",
    "        self.optim.load_state_dict(state['optimizer'])\n",
    "        self.train_losses = state['train_loss']\n",
    "        self.valid_losses = state['valid_loss']\n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def showPlot(points):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.show()\n",
    "    \n",
    "def savePlot(points, figure_path):\n",
    "    plt.switch_backend('Agg')\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.savefig(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練用パラメタを定義する\n",
    "vocab_path= read_dir + 'vocab.txt'\n",
    "\n",
    "hidden=256 #768\n",
    "layers=2 #12\n",
    "attn_heads=4 #12\n",
    "seq_len=128\n",
    "\n",
    "batch_size=128\n",
    "num_workers=0\n",
    "with_cuda=True\n",
    "log_freq=100\n",
    "corpus_lines=None\n",
    "\n",
    "lr=1e-3\n",
    "adam_weight_decay=0.00\n",
    "adam_beta1=0.9\n",
    "adam_beta2=0.999\n",
    "\n",
    "dropout=0.0\n",
    "\n",
    "min_freq=7\n",
    "\n",
    "label_path=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_path=processed_train_txt\n",
    "#build(corpus_path, vocab_path, min_freq=min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Vocab ./data/merged_bert/vocab.txt\n",
      "Loading Train Dataset ./data/merged_bert/train_X.txt\n",
      "Loading Valid Dataset ./data/merged_bert/valid_X.txt\n",
      "Creating Dataloader\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Loading Vocab\", vocab_path)\n",
    "vocab = WordVocab.load_vocab(vocab_path)\n",
    "\n",
    "from dataset import MixDataset\n",
    "print(\"Loading Train Dataset\", processed_train_txt)\n",
    "train_dataset = MixDataset(processed_train_txt, vocab, seq_len=seq_len, label_path=label_path, corpus_lines=corpus_lines)\n",
    "\n",
    "print(\"Loading Valid Dataset\", processed_valid_txt)\n",
    "valid_dataset = MixDataset(processed_valid_txt, vocab, seq_len=seq_len, label_path=label_path) if processed_valid_txt is not None else None\n",
    "\n",
    "print(\"Creating Dataloader\")\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers) if processed_valid_txt is not None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building BERT model\n",
      "Using 2 GPUS for BERT\n",
      "Total Parameters: 2761481\n",
      "Using 2 GPUS for BERT\n",
      "Total Parameters: 2761501\n",
      "Using 2 GPUS for BERT\n",
      "Total Parameters: 5522944\n"
     ]
    }
   ],
   "source": [
    "print(\"Building BERT model\")\n",
    "epd_bert = BERT(len(vocab), hidden=hidden, n_layers=layers, attn_heads=attn_heads, dropout=dropout)\n",
    "epd_trainer = EPDTrainer(epd_bert, train_dataloader=train_data_loader, valid_dataloader=valid_data_loader,\n",
    "                 lr=lr, betas=(adam_beta1, adam_beta2), weight_decay=adam_weight_decay,\n",
    "                 with_cuda=with_cuda, log_freq=log_freq, head=9)\n",
    "\n",
    "esd_bert = BERT(len(vocab), hidden=hidden, n_layers=layers, attn_heads=attn_heads, dropout=dropout)\n",
    "esd_trainer = HybridESDTrainer(esd_bert, train_dataloader=train_data_loader, valid_dataloader=valid_data_loader,\n",
    "                                  lr=lr, betas=(adam_beta1, adam_beta2), weight_decay=adam_weight_decay,\n",
    "                                  with_cuda=with_cuda, log_freq=log_freq, head=9)\n",
    "\n",
    "layers=4 #12\n",
    "attn_heads=8 #12\n",
    "mlm_bert = BERT(len(vocab), hidden=hidden, n_layers=layers, attn_heads=attn_heads, dropout=dropout)\n",
    "mlm_trainer = MLMTrainer(mlm_bert, len(vocab), train_dataloader=train_data_loader, valid_dataloader=valid_data_loader,\n",
    "                  lr=lr, betas=(adam_beta1, adam_beta2), weight_decay=adam_weight_decay,\n",
    "                  with_cuda=with_cuda, log_freq=log_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "esd_model_path = output_dir + 'mix/esd/small/small.ep15'\n",
    "epd_model_path = output_dir + 'mix/epd/small/small.ep34'\n",
    "mlm_model_path = output_dir + 'mlm/mid/.ep16'\n",
    "_ = epd_trainer.load_pretrain(epd_model_path)\n",
    "\n",
    "_ = esd_trainer.load_pretrain(esd_model_path)\n",
    "\n",
    "\n",
    "_ = mlm_trainer.load_pretrain(mlm_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset = MixDataset(processed_test_txt, vocab, seq_len=seq_len, label_path=label_path, is_train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=num_workers, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "野中広務官房長官と同会議の樋口広太郎議長が１９日、首相官邸で会談して決めた。\n",
      "野中広務官房長官と同会議の樋口広太郎議長や１９日、首相官邸で会談して決めっ。\n",
      "1 1\n",
      "野中広務官房長官と同会議の樋口広太郎議長<mask>１９日、首相官邸で会談して決め<mask>。\n",
      "9\n",
      "40\n",
      "0 :野\n",
      "0 :中\n",
      "0 :広\n",
      "0 :務\n",
      "0 :官\n",
      "0 :房\n",
      "0 :長\n",
      "0 :官\n",
      "0 :と\n",
      "0 :同\n",
      "0 :会\n",
      "0 :議\n",
      "0 :の\n",
      "0 :樋\n",
      "0 :口\n",
      "0 :広\n",
      "0 :太\n",
      "0 :郎\n",
      "0 :議\n",
      "3 :長\n",
      "0 :<mask> :誤: ['は', 'が', 'も']\n",
      "0 :１\n",
      "0 :９\n",
      "0 :日\n",
      "0 :、\n",
      "0 :首\n",
      "0 :相\n",
      "0 :官\n",
      "0 :邸\n",
      "0 :で\n",
      "0 :会\n",
      "0 :談\n",
      "0 :し\n",
      "0 :て\n",
      "0 :決\n",
      "3 :め\n",
      "0 :<mask> :誤: ['た', 'る', 'て']\n",
      "0 :。\n",
      "文部省の現職幹部は明かす。\n",
      "文部省の現職幹部は明かす。\n",
      "0 1\n",
      "文部省の現職幹部は明かす。\n",
      "9\n",
      "15\n",
      "0 :文\n",
      "0 :部\n",
      "0 :省\n",
      "0 :の\n",
      "0 :現\n",
      "0 :職\n",
      "0 :幹\n",
      "0 :部\n",
      "0 :は\n",
      "0 :明\n",
      "0 :か\n",
      "0 :す\n",
      "0 :。\n",
      "ドナーとなり得る患者が発生した場合、同センターではこの原則を家族に説明する。\n",
      "ドナーとなり得る患者が発生した場合、同センターではこの原則を家族に説明する。\n",
      "0 0\n",
      "一方、人権、台湾問題では双方が原則的立場を主張し、協議は平行線に終わった。クリントン大統領は「政治的意見を表明しようとした人々を逮捕するなどダライ・ラマとの対話が進んでいないことも遺憾だ」と述べた。\n",
      "一方、人権、台湾問題ででは双方原則的立場を主張、協議は平行線に終わった。クリントン大統領は「政治的意見をを表明しｙうとしした人々を逮捕するながダライ・ラマとの対話進んでいないことも遺憾だ」と述べべた。\n",
      "1 1\n",
      "一方、人権、台湾問題では双方<mask><mask>原則的立場を主張、協議は平行線に終わった。クリントン大統領は「政治的意見を表明し<mask>うとした人々を逮捕するながダライ・ラマとの対話<mask><mask>進んでいないことも遺憾だ」と述べた。\n",
      "9\n",
      "102\n",
      "0 :一\n",
      "0 :方\n",
      "0 :、\n",
      "0 :人\n",
      "0 :権\n",
      "0 :、\n",
      "0 :台\n",
      "0 :湾\n",
      "0 :問\n",
      "0 :題\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :は\n",
      "0 :双\n",
      "2 :方\n",
      "-1 :<mask> :脱: ['と', 'が', 'に']\n",
      "-1 :<mask> :脱: ['も', 'の', 'は']\n",
      "0 :原\n",
      "0 :則\n",
      "0 :的\n",
      "0 :立\n",
      "0 :場\n",
      "0 :を\n",
      "0 :主\n",
      "0 :張\n",
      "0 :、\n",
      "0 :協\n",
      "0 :議\n",
      "0 :は\n",
      "0 :平\n",
      "0 :行\n",
      "0 :線\n",
      "0 :に\n",
      "0 :終\n",
      "0 :わ\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :。\n",
      "0 :ク\n",
      "0 :リ\n",
      "0 :ン\n",
      "0 :ト\n",
      "0 :ン\n",
      "0 :大\n",
      "0 :統\n",
      "0 :領\n",
      "0 :は\n",
      "0 :「\n",
      "0 :政\n",
      "0 :治\n",
      "0 :的\n",
      "0 :意\n",
      "0 :見\n",
      "0 :を\n",
      "6 :<del>\n",
      "6 :表\n",
      "0 :明\n",
      "0 :し\n",
      "0 :<mask> :誤: ['よ', 'そ', 'た']\n",
      "3 :う\n",
      "0 :と\n",
      "0 :し\n",
      "0 :た\n",
      "6 :<del>\n",
      "6 :人\n",
      "0 :々\n",
      "0 :を\n",
      "0 :逮\n",
      "0 :捕\n",
      "0 :す\n",
      "0 :る\n",
      "0 :な\n",
      "0 :が\n",
      "0 :ダ\n",
      "0 :ラ\n",
      "0 :イ\n",
      "0 :・\n",
      "0 :ラ\n",
      "0 :マ\n",
      "0 :と\n",
      "0 :の\n",
      "0 :対\n",
      "0 :話\n",
      "0 :<mask> :脱: ['に', 'ま', 'し']\n",
      "2 :<mask> :脱: ['は', 'か', 'も']\n",
      "-1 :進\n",
      "-1 :ん\n",
      "0 :で\n",
      "0 :い\n",
      "0 :な\n",
      "0 :い\n",
      "0 :こ\n",
      "0 :と\n",
      "0 :も\n",
      "0 :遺\n",
      "0 :憾\n",
      "0 :だ\n",
      "0 :」\n",
      "0 :と\n",
      "0 :述\n",
      "0 :べ\n",
      "0 :た\n",
      "0 :。\n",
      "神奈川県庁に勤め、組合運動をやっていた３０代半ば、言葉遊びの詩を作り始めた。\n",
      "神奈川県庁に勤め、組合運動やてた３０代半ば、言葉遊び詩を作りり始めめた。\n",
      "1 1\n",
      "神奈川県庁に勤め、組合運動<mask>て<mask><mask>た３０代半ば、言葉遊び詩を作り始めた。\n",
      "9\n",
      "38\n",
      "0 :神\n",
      "0 :奈\n",
      "0 :川\n",
      "0 :県\n",
      "0 :庁\n",
      "0 :に\n",
      "0 :勤\n",
      "0 :め\n",
      "0 :、\n",
      "0 :組\n",
      "0 :合\n",
      "0 :運\n",
      "3 :動\n",
      "2 :<mask> :誤: ['し', 'を', 'で']\n",
      "-1 :て\n",
      "-1 :<mask> :脱: ['い', 'あ', 'お']\n",
      "0 :<mask> :脱: ['っ', 'れ', 'い']\n",
      "0 :た\n",
      "0 :３\n",
      "0 :０\n",
      "0 :代\n",
      "0 :半\n",
      "0 :ば\n",
      "0 :、\n",
      "0 :言\n",
      "0 :葉\n",
      "0 :遊\n",
      "0 :び\n",
      "0 :詩\n",
      "0 :を\n",
      "0 :作\n",
      "6 :<del>\n",
      "6 :り\n",
      "0 :始\n",
      "0 :め\n",
      "6 :<del>\n",
      "6 :た\n",
      "0 :。\n",
      "１位は圧倒的に「日本の雑誌やテレビドラマを理解したい」だった。\n",
      "１位圧倒的に「日本の雑誌ややテレビドラマを理解しｔい」だった。\n",
      "1 1\n",
      "１位<mask><mask>圧倒的に「日本の雑誌やテレビドラマを理解し<mask>い」だった。\n",
      "9\n",
      "34\n",
      "2 :１\n",
      "-1 :位\n",
      "-1 :<mask> :脱: ['に', 'か', 'で']\n",
      "0 :<mask> :脱: ['は', 'ら', 'も']\n",
      "0 :圧\n",
      "0 :倒\n",
      "0 :的\n",
      "0 :に\n",
      "0 :「\n",
      "0 :日\n",
      "0 :本\n",
      "0 :の\n",
      "0 :雑\n",
      "0 :誌\n",
      "6 :<del>\n",
      "6 :や\n",
      "0 :テ\n",
      "0 :レ\n",
      "0 :ビ\n",
      "0 :ド\n",
      "0 :ラ\n",
      "0 :マ\n",
      "0 :を\n",
      "0 :理\n",
      "0 :解\n",
      "0 :し\n",
      "3 :<mask> :誤: ['た', 'な', 'て']\n",
      "0 :い\n",
      "0 :」\n",
      "0 :だ\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :。\n",
      "大阪・劇場飛天の八月公演はミュージカル「ラ・マンチャの男」。\n",
      "大阪・劇場飛天の八月公演はミュージカル「ラ・マンチャの男」。\n",
      "0 0\n",
      "紛争を抱える両国には偶発戦争の危険性もある。\n",
      "紛争を抱えるる両国にｈ偶発戦争の危険性もある。\n",
      "1 1\n",
      "紛争を抱える両国に<mask>偶発戦争の危険性もある。\n",
      "9\n",
      "24\n",
      "0 :紛\n",
      "0 :争\n",
      "0 :を\n",
      "0 :抱\n",
      "0 :え\n",
      "6 :<del>\n",
      "6 :る\n",
      "0 :両\n",
      "0 :国\n",
      "0 :に\n",
      "3 :<mask> :誤: ['は', 'も', 'の']\n",
      "0 :偶\n",
      "0 :発\n",
      "0 :戦\n",
      "0 :争\n",
      "0 :の\n",
      "0 :危\n",
      "0 :険\n",
      "0 :性\n",
      "0 :も\n",
      "0 :あ\n",
      "0 :る\n",
      "0 :。\n",
      "今年３月に地元の新聞で紹介されたところ、５カ月で７００件を超す希望が寄せられた。「同じ思いの人がこんなにいたのか」と驚いたという。「ナプキンや紙おむつだとかぶれる」という尿漏れに悩む高齢者からの問い合わせも少なくないそうだ。\n",
      "今年３月に地元の新聞でで紹介されところろ、５カ月で７００件を超す希望が寄せらた。「同じじ思いいの人ｇこんｎにいのか」と驚いたｔいう。「ナプキンや紙おむｔだとかれる」というう尿漏れに悩む高齢者からの問い合わせも少なくないうだ。\n",
      "1 1\n",
      "今年３月に地元の新聞で紹介されところ、５カ月で７００件を超す希望が寄せら<mask><mask>た。「同じ思いの人<mask>こん<mask>にいのか」と驚いた<mask>いう。「ナプキンや紙おむ<mask>だとかれる」という尿漏れに悩む高齢者からの問い合わせも少なくないだ。\n",
      "9\n",
      "110\n",
      "0 :今\n",
      "0 :年\n",
      "0 :３\n",
      "0 :月\n",
      "0 :に\n",
      "0 :地\n",
      "0 :元\n",
      "0 :の\n",
      "0 :新\n",
      "0 :聞\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :紹\n",
      "0 :介\n",
      "0 :さ\n",
      "0 :れ\n",
      "0 :と\n",
      "0 :こ\n",
      "0 :ろ\n",
      "6 :<del>\n",
      "6 :、\n",
      "0 :５\n",
      "0 :カ\n",
      "0 :月\n",
      "0 :で\n",
      "0 :７\n",
      "0 :０\n",
      "0 :０\n",
      "0 :件\n",
      "0 :を\n",
      "0 :超\n",
      "0 :す\n",
      "0 :希\n",
      "0 :望\n",
      "0 :が\n",
      "0 :寄\n",
      "0 :せ\n",
      "0 :ら\n",
      "2 :<mask> :脱: ['れ', 'さ', 'ま']\n",
      "-1 :<mask> :脱: ['い', 'っ', 'れ']\n",
      "-1 :た\n",
      "0 :。\n",
      "0 :「\n",
      "0 :同\n",
      "0 :じ\n",
      "0 :思\n",
      "6 :<del>\n",
      "6 :い\n",
      "0 :の\n",
      "0 :人\n",
      "6 :<del>\n",
      "6 :<mask> :誤: ['が', 'は', 'も']\n",
      "0 :こ\n",
      "0 :ん\n",
      "3 :<mask> :誤: ['な', 'ど', 'ご']\n",
      "0 :に\n",
      "0 :い\n",
      "3 :の\n",
      "0 :か\n",
      "0 :」\n",
      "0 :と\n",
      "0 :驚\n",
      "0 :い\n",
      "0 :た\n",
      "0 :<mask> :誤: ['と', 'だ', 'こ']\n",
      "0 :い\n",
      "0 :う\n",
      "3 :。\n",
      "0 :「\n",
      "0 :ナ\n",
      "0 :プ\n",
      "0 :キ\n",
      "0 :ン\n",
      "0 :や\n",
      "0 :紙\n",
      "0 :お\n",
      "0 :む\n",
      "0 :<mask> :誤: ['つ', 'し', 'け']\n",
      "0 :だ\n",
      "0 :と\n",
      "3 :か\n",
      "0 :れ\n",
      "0 :る\n",
      "0 :」\n",
      "0 :と\n",
      "0 :い\n",
      "0 :う\n",
      "0 :尿\n",
      "0 :漏\n",
      "0 :れ\n",
      "6 :<del>\n",
      "6 :に\n",
      "0 :悩\n",
      "0 :む\n",
      "0 :高\n",
      "0 :齢\n",
      "0 :者\n",
      "0 :か\n",
      "0 :ら\n",
      "0 :の\n",
      "0 :問\n",
      "0 :い\n",
      "0 :合\n",
      "0 :わ\n",
      "0 :せ\n",
      "0 :も\n",
      "0 :少\n",
      "0 :な\n",
      "0 :く\n",
      "0 :な\n",
      "0 :い\n",
      "0 :だ\n",
      "0 :。\n",
      "リクルート事件、消費税導入と宇野宗佑首相の女性スキャンダルが重なった揚げ句の惨敗。\n",
      "リクルート事件、消費税導入ｔ宇野宗佑首相の女性スキャンダルが重なごた揚げ句の惨敗。\n",
      "1 1\n",
      "リクルート事件、消費税導入<mask>宇野宗佑首相の女性スキャンダルが重な<mask>た揚げ句の惨敗。\n",
      "9\n",
      "43\n",
      "0 :リ\n",
      "0 :ク\n",
      "0 :ル\n",
      "0 :ー\n",
      "0 :ト\n",
      "0 :事\n",
      "0 :件\n",
      "0 :、\n",
      "0 :消\n",
      "0 :費\n",
      "0 :税\n",
      "0 :導\n",
      "3 :入\n",
      "0 :<mask> :誤: ['の', 'で', 'と']\n",
      "0 :宇\n",
      "0 :野\n",
      "0 :宗\n",
      "0 :佑\n",
      "0 :首\n",
      "0 :相\n",
      "0 :の\n",
      "0 :女\n",
      "0 :性\n",
      "0 :ス\n",
      "0 :キ\n",
      "0 :ャ\n",
      "0 :ン\n",
      "0 :ダ\n",
      "0 :ル\n",
      "0 :が\n",
      "0 :重\n",
      "3 :な\n",
      "0 :<mask> :誤: ['っ', 'え', 'い']\n",
      "0 :た\n",
      "0 :揚\n",
      "0 :げ\n",
      "0 :句\n",
      "0 :の\n",
      "0 :惨\n",
      "0 :敗\n",
      "0 :。\n",
      "日本の警察が「強姦」と呼ぶのはこれらの「必須要件」を満たす場合に限られる。\n",
      "日本の警察「強姦」とと呼ぶのはこれらの「必須要件」を満たす場合て限らられる。\n",
      "1 1\n",
      "日本の警察<mask><mask>「強姦」と呼ぶのはこれらの「必須要件」を満たす場合<mask>限られる。\n",
      "9\n",
      "40\n",
      "0 :日\n",
      "0 :本\n",
      "0 :の\n",
      "2 :警\n",
      "-1 :察\n",
      "-1 :<mask> :脱: ['で', 'か', 'へ']\n",
      "0 :<mask> :脱: ['は', 'ら', 'も']\n",
      "0 :「\n",
      "0 :強\n",
      "0 :姦\n",
      "0 :」\n",
      "6 :<del>\n",
      "6 :と\n",
      "0 :呼\n",
      "0 :ぶ\n",
      "0 :の\n",
      "0 :は\n",
      "0 :こ\n",
      "0 :れ\n",
      "0 :ら\n",
      "0 :の\n",
      "0 :「\n",
      "0 :必\n",
      "0 :須\n",
      "0 :要\n",
      "0 :件\n",
      "0 :」\n",
      "0 :を\n",
      "0 :満\n",
      "0 :た\n",
      "0 :す\n",
      "0 :場\n",
      "0 :合\n",
      "3 :<mask> :誤: ['は', 'に', 'も']\n",
      "0 :限\n",
      "0 :ら\n",
      "6 :<del>\n",
      "6 :れ\n",
      "0 :る\n",
      "0 :。\n",
      "一方、同市内ではベランダの窓ガラスが割られたり、合いかぎを使うなどの手口のマンション荒らしが１００件以上もあり、府警は関連を調べる。\n",
      "一方、同市内ではベランダの窓ガラスが割られたり、合いかぎを使うなどの手口のマンション荒らしが１００件以上もあり、府警は関連を調べる。\n",
      "0 0\n",
      "しかし、不登校などの現象を、学校や大人が悪いから、と肯定しているだけではだめだ。なぜ自分は学校に行きたくないのかを、子供にきちんと文章で書かせる。行かないことに積極的な意味が見つけられれば、それがエネルギーになる可能性がある。綴方教育が生き残る道もそこにあるだろう」\n",
      "しかし、不登校ななどの現象を、学校や大人が悪いへら、と肯定しているだけけでではだめだ。なぜ自分は学校に行たくくないのかを、子供にきちんとと文章で書ｋせ。行かないこｔに積極的な意味が見つけられれば、そがエネルギーなるる可能性があるる。綴方教育がが生き残る\n",
      "1 1\n",
      "しかし、不登校などの現象を、学校や大人が悪い<mask>ら、と肯定しているだけではだめだ。なぜ自分は学校に行<mask>たくないのかを、子供にきちんと文章で書<mask>せ<mask>。行かないこ<mask>に積極的な意味が見つけられれば、そ<mask><mask>がエネルギー<mask>なる可能性がある。綴方教育が生き残る\n",
      "9\n",
      "125\n",
      "0 :し\n",
      "0 :か\n",
      "0 :し\n",
      "0 :、\n",
      "0 :不\n",
      "0 :登\n",
      "0 :校\n",
      "6 :<del>\n",
      "6 :な\n",
      "0 :ど\n",
      "0 :の\n",
      "0 :現\n",
      "0 :象\n",
      "0 :を\n",
      "0 :、\n",
      "0 :学\n",
      "0 :校\n",
      "0 :や\n",
      "0 :大\n",
      "0 :人\n",
      "0 :が\n",
      "0 :悪\n",
      "0 :い\n",
      "3 :<mask> :誤: ['か', 'く', 'た']\n",
      "0 :ら\n",
      "0 :、\n",
      "0 :と\n",
      "0 :肯\n",
      "0 :定\n",
      "0 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :だ\n",
      "0 :け\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :は\n",
      "6 :<del>\n",
      "6 :だ\n",
      "0 :め\n",
      "0 :だ\n",
      "0 :。\n",
      "0 :な\n",
      "0 :ぜ\n",
      "0 :自\n",
      "0 :分\n",
      "0 :は\n",
      "0 :学\n",
      "0 :校\n",
      "0 :に\n",
      "0 :行\n",
      "0 :<mask> :脱: ['き', 'い', 'け']\n",
      "1 :た\n",
      "-1 :く\n",
      "0 :な\n",
      "0 :い\n",
      "6 :<del>\n",
      "6 :の\n",
      "0 :か\n",
      "0 :を\n",
      "0 :、\n",
      "0 :子\n",
      "0 :供\n",
      "0 :に\n",
      "0 :き\n",
      "0 :ち\n",
      "0 :ん\n",
      "0 :と\n",
      "0 :文\n",
      "0 :章\n",
      "0 :で\n",
      "6 :<del>\n",
      "6 :書\n",
      "0 :<mask> :誤: ['か', 'こ', 'き']\n",
      "0 :せ\n",
      "0 :<mask> :脱: ['る', 'ん', 'た']\n",
      "0 :。\n",
      "3 :行\n",
      "1 :か\n",
      "-1 :な\n",
      "0 :い\n",
      "0 :こ\n",
      "0 :<mask> :誤: ['と', 'う', 'こ']\n",
      "0 :に\n",
      "0 :積\n",
      "0 :極\n",
      "3 :的\n",
      "0 :な\n",
      "0 :意\n",
      "0 :味\n",
      "0 :が\n",
      "0 :見\n",
      "0 :つ\n",
      "0 :け\n",
      "0 :ら\n",
      "0 :れ\n",
      "0 :れ\n",
      "0 :ば\n",
      "0 :、\n",
      "0 :そ\n",
      "0 :<mask> :脱: ['れ', 'の', 'ん']\n",
      "0 :<mask> :脱: ['ら', 'か', 'だ']\n",
      "0 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :教\n",
      "0 :育\n",
      "0 :の\n",
      "0 :性\n",
      "0 :質\n",
      "0 :上\n",
      "0 :、\n",
      "0 :学\n",
      "0 :校\n",
      "0 :内\n",
      "0 :で\n",
      "0 :あ\n",
      "0 :る\n",
      "0 :種\n",
      "0 :の\n",
      "0 :強\n",
      "0 :制\n",
      "0 :が\n",
      "0 :が\n",
      "0 :働\n",
      "0 :く\n",
      "6 :<del>\n",
      "6 :の\n",
      "0 :は\n",
      "0 :当\n",
      "0 :然\n",
      "0 :で\n",
      "0 :あ\n",
      "0 :り\n",
      "0 :、\n",
      "0 :入\n",
      "0 :学\n",
      "0 :式\n",
      "0 :や\n",
      "6 :<del>\n",
      "6 :卒\n",
      "0 :業\n",
      "0 :式\n",
      "0 :児\n",
      "0 :童\n",
      "0 :・\n",
      "0 :生\n",
      "0 :徒\n",
      "0 :全\n",
      "0 :員\n",
      "0 :に\n",
      "0 :国\n",
      "0 :歌\n",
      "0 :を\n",
      "0 :斉\n",
      "0 :唱\n",
      "0 :さ\n",
      "0 :<mask> :誤: ['せ', 'れ', 'る']\n",
      "3 :<mask> :誤: ['て', 'に', 'か']\n",
      "3 :も\n",
      "0 :問\n",
      "0 :題\n",
      "0 :は\n",
      "0 :は\n",
      "0 :な\n",
      "2 :<mask> :脱: ['い', 'な', 'っ']\n",
      "-1 :<mask> :脱: ['か', 'た', 'い']\n",
      "-1 :。\n",
      "0 :ど\n",
      "0 :う\n",
      "1 :<mask> :脱: ['し', 'み', 'っ']\n",
      "-1 :て\n",
      "0 :も\n",
      "0 :国\n",
      "0 :歌\n",
      "0 :を\n",
      "0 :斉\n",
      "0 :唱\n",
      "0 :し\n",
      "0 :た\n",
      "6 :<del>\n",
      "6 :く\n",
      "0 :け\n",
      "0 :い\n",
      "0 :生\n",
      "0 :徒\n",
      "0 :<mask> :誤: ['の', 'が', 'は']\n",
      "0 :力\n",
      "3 :ず\n",
      "0 :く\n",
      "0 :で\n",
      "0 :歌\n",
      "0 :わ\n",
      "0 :た\n",
      "0 :<mask> :脱: ['り', 'く', 'れ']\n",
      "1 :、\n",
      "-1 :国\n",
      "0 :歌\n",
      "0 :を\n",
      "0 :斉\n",
      "0 :唱\n",
      "0 :し\n",
      "0 :な\n",
      "0 :い\n",
      "0 :か\n",
      "0 :ら\n",
      "0 :と\n",
      "0 :い\n",
      "0 :<mask> :誤: ['っ', 'う', 'わ']\n",
      "0 :<mask> :誤: ['た', 'て', 'れ']\n",
      "3 :停\n",
      "3 :学\n",
      "0 :・\n",
      "0 :退\n",
      "0 :学\n",
      "0 :処\n",
      "0 :分\n",
      "0 :を\n",
      "0 :課\n",
      "0 :す\n",
      "0 :と\n",
      "0 :い\n",
      "6 :<del>\n",
      "6 :う\n",
      "0 :こ\n",
      "0 :と\n",
      "6 :<del>\n",
      "6 :が\n",
      "0 :あ\n",
      "0 :れ\n",
      "0 :ば\n",
      "6 :<del>\n",
      "6 :当\n",
      "0 :然\n",
      "自宅ではバラを栽培。\n",
      "自宅でｈバラを栽培。\n",
      "1 1\n",
      "自宅で<mask>バラを栽培。\n",
      "9\n",
      "12\n",
      "0 :自\n",
      "0 :宅\n",
      "3 :で\n",
      "0 :<mask> :誤: ['は', 'も', 'の']\n",
      "0 :バ\n",
      "0 :ラ\n",
      "0 :を\n",
      "0 :栽\n",
      "0 :培\n",
      "0 :。\n",
      "ギリシャはＥＭＵ参加希望国のうち唯一、参加基準を達成できず、２００１年の参加を目指している。\n",
      "ギリシャｈＥＭＵ参加希望国のううち唯一、参加基準を達成ｄきず、２００１年の参加目指している。\n",
      "1 1\n",
      "ギリシャ<mask>ＥＭＵ参加希望国のうち唯一、参加基準を達成<mask>きず、２００１年の参加<mask><mask>目指している。\n",
      "9\n",
      "49\n",
      "0 :ギ\n",
      "0 :リ\n",
      "0 :シ\n",
      "3 :ャ\n",
      "0 :<mask> :誤: ['は', 'の', 'が']\n",
      "0 :Ｅ\n",
      "0 :Ｍ\n",
      "0 :Ｕ\n",
      "0 :参\n",
      "0 :加\n",
      "0 :希\n",
      "0 :望\n",
      "0 :国\n",
      "0 :の\n",
      "6 :<del>\n",
      "6 :う\n",
      "0 :ち\n",
      "0 :唯\n",
      "0 :一\n",
      "0 :、\n",
      "0 :参\n",
      "0 :加\n",
      "0 :基\n",
      "0 :準\n",
      "0 :を\n",
      "0 :達\n",
      "0 :成\n",
      "3 :<mask> :誤: ['で', 'い', 'さ']\n",
      "0 :き\n",
      "0 :ず\n",
      "0 :、\n",
      "0 :２\n",
      "0 :０\n",
      "0 :０\n",
      "0 :１\n",
      "0 :年\n",
      "0 :の\n",
      "0 :参\n",
      "2 :加\n",
      "-1 :<mask> :脱: ['し', 'ま', 'で']\n",
      "-1 :<mask> :脱: ['を', 'も', 'で']\n",
      "0 :目\n",
      "0 :指\n",
      "0 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :。\n",
      "また、関節炎を起こさせたマウスに３週間、体重１キロ当たり４グラムのアガロオリゴ糖を与えると関節炎の発症が抑制され、明らかな治療効果があったという。\n",
      "また、関節炎を起こさせたマウスに３週間、体重１キロ当たり４グラムのアガロオリゴ糖を与えると関節炎の発症が抑制され、明らかな治療効果があったという。\n",
      "0 0\n",
      "大分空港ケ岳の山中に墜落しているのが発見された。\n",
      "大分空港ケ岳の山中に墜落ししているるのが発見された。\n",
      "1 1\n",
      "大分空港ケ岳の山中に墜落しているのが発見された。\n",
      "9\n",
      "26\n",
      "0 :大\n",
      "0 :分\n",
      "0 :空\n",
      "0 :港\n",
      "0 :ケ\n",
      "0 :岳\n",
      "0 :の\n",
      "0 :山\n",
      "0 :中\n",
      "0 :に\n",
      "0 :墜\n",
      "0 :落\n",
      "6 :<del>\n",
      "6 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "6 :<del>\n",
      "6 :の\n",
      "0 :が\n",
      "0 :発\n",
      "0 :見\n",
      "0 :さ\n",
      "0 :れ\n",
      "0 :た\n",
      "0 :。\n",
      "東京都文京区本郷の区民センターで開かれた遺族の会の第２３回総会の冒頭、井手渉は隼君事件に触れ、「検察は事件を不起訴にしてしまうと、刑事訴訟法を盾に遺族にさえ捜査情報を開示しない。交通事故の不起訴率が８０％以上に拡大し、検察の『省力化』の目標は達成されたが、逆に遺族の知る権利と被害者の人権は無視され続けてきた。刑訴法１条の『事件の真相を明らかにする』という精神からして、本末転倒ではないか」と批判した。井手会長は「隼君事件の署名活動に協力し、両親を支援したい」と訴え、了承された。隼君の両親は入会していないため出席していなかったが、約１３０人の遺族は次々に署名した。\n",
      "東京都文京区本郷ど区民センターで開かれの遺族の会の第２３回総会冒頭、井手渉は隼君事件に触れ、「検察は事件を不起訴ににしててしままうと、刑事訴訟法を盾に遺族にさえ捜査情報開示ない。交通事故のの不起訴率が８０％以上に拡大、検察の『省力化』の目標ｈ達成ｓれが\n",
      "1 1\n",
      "東京都文京区本郷<mask>区民センターで開かれの遺族の会の第２３回総会冒頭、井手渉は隼君事件に触れ、「検察は事件を不起訴にしてしまうと、刑事訴訟法を盾に遺族にさえ捜査情報開示<mask>ない。交通事故の不起訴率が８０％以上に拡大、検察の『省力化』の目標<mask>達成<mask>れが\n",
      "9\n",
      "125\n",
      "0 :東\n",
      "0 :京\n",
      "0 :都\n",
      "0 :文\n",
      "0 :京\n",
      "0 :区\n",
      "0 :本\n",
      "3 :郷\n",
      "0 :<mask> :誤: ['の', 'と', 'が']\n",
      "0 :区\n",
      "0 :民\n",
      "0 :セ\n",
      "0 :ン\n",
      "0 :タ\n",
      "0 :ー\n",
      "0 :で\n",
      "0 :開\n",
      "0 :か\n",
      "0 :れ\n",
      "0 :の\n",
      "0 :遺\n",
      "0 :族\n",
      "0 :の\n",
      "0 :会\n",
      "0 :の\n",
      "0 :第\n",
      "0 :２\n",
      "0 :３\n",
      "0 :回\n",
      "0 :総\n",
      "0 :会\n",
      "0 :冒\n",
      "0 :頭\n",
      "0 :、\n",
      "0 :井\n",
      "0 :手\n",
      "0 :渉\n",
      "0 :は\n",
      "0 :隼\n",
      "0 :君\n",
      "0 :事\n",
      "0 :件\n",
      "0 :に\n",
      "0 :触\n",
      "0 :れ\n",
      "0 :、\n",
      "0 :「\n",
      "0 :検\n",
      "0 :察\n",
      "0 :は\n",
      "0 :事\n",
      "0 :件\n",
      "0 :を\n",
      "0 :不\n",
      "0 :起\n",
      "0 :訴\n",
      "6 :<del>\n",
      "6 :に\n",
      "0 :し\n",
      "0 :て\n",
      "6 :<del>\n",
      "6 :し\n",
      "0 :ま\n",
      "0 :う\n",
      "6 :<del>\n",
      "6 :と\n",
      "0 :、\n",
      "0 :刑\n",
      "0 :事\n",
      "0 :訴\n",
      "0 :訟\n",
      "0 :法\n",
      "0 :を\n",
      "0 :盾\n",
      "0 :に\n",
      "0 :遺\n",
      "0 :族\n",
      "0 :に\n",
      "0 :さ\n",
      "0 :え\n",
      "0 :捜\n",
      "0 :査\n",
      "0 :情\n",
      "0 :報\n",
      "0 :開\n",
      "0 :示\n",
      "0 :<mask> :脱: ['し', 'れ', 'は']\n",
      "1 :な\n",
      "-1 :い\n",
      "0 :。\n",
      "0 :交\n",
      "0 :通\n",
      "0 :事\n",
      "0 :故\n",
      "0 :の\n",
      "0 :不\n",
      "0 :起\n",
      "6 :<del>\n",
      "6 :訴\n",
      "0 :率\n",
      "0 :が\n",
      "0 :８\n",
      "0 :０\n",
      "0 :％\n",
      "0 :以\n",
      "0 :上\n",
      "0 :に\n",
      "0 :拡\n",
      "0 :大\n",
      "0 :、\n",
      "0 :検\n",
      "0 :察\n",
      "0 :の\n",
      "0 :『\n",
      "0 :省\n",
      "0 :力\n",
      "0 :化\n",
      "0 :』\n",
      "0 :の\n",
      "0 :目\n",
      "0 :標\n",
      "0 :<mask> :誤: ['の', 'は', 'が']\n",
      "0 :達\n",
      "0 :成\n",
      "3 :<mask> :誤: ['さ', 'す', 'し']\n",
      "0 :れ\n",
      "0 :が\n",
      "バブル崩壊で会社神話が崩れ、教育を取り巻く環境も変わった。\n",
      "バブル崩壊で会社神話が崩ろ、教育を取り巻く環境も変わった。\n",
      "1 1\n",
      "バブル崩壊で会社神話が崩<mask>、教育を取り巻く環境も変わった。\n",
      "9\n",
      "31\n",
      "0 :バ\n",
      "0 :ブ\n",
      "0 :ル\n",
      "0 :崩\n",
      "0 :壊\n",
      "0 :で\n",
      "0 :会\n",
      "0 :社\n",
      "0 :神\n",
      "0 :話\n",
      "0 :が\n",
      "3 :崩\n",
      "0 :<mask> :誤: ['れ', 'り', 'し']\n",
      "0 :、\n",
      "0 :教\n",
      "0 :育\n",
      "0 :を\n",
      "0 :取\n",
      "0 :り\n",
      "0 :巻\n",
      "0 :く\n",
      "0 :環\n",
      "0 :境\n",
      "0 :も\n",
      "0 :変\n",
      "0 :わ\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :。\n",
      "第一の点でいうなら、旧宗主国の英国が残した現実主義、合理主義の原理は、同首相の性格に有形、無形の影響を与えているように思われる。これは同族支配や私利私欲の汚名を浴びて倒れたスハルト氏との最大の相違点である。\n",
      "第一の点でいうなら、旧宗主国の英国が残した現実主義、合理主義の原理は、同首相の性格に有形、無形の影響を与えているように思われる。これは同族支配や私利私欲の汚名を浴びて倒れたスハルト氏との最大の相違点である。\n",
      "0 0\n",
      "同キャンペーンによると、これまでに各国の約６００の市民団体や労働組合が、ＭＡＩに反対を表明している。\n",
      "同キャンペーンよると、ここれままでに各国の約６００が市民団体や労働組合が、ＭＡＩに反対を表明しているる。\n",
      "1 1\n",
      "同キャンペーンよると、これまでに各国の約６００が市民団体や労働組合が、ＭＡＩに反対を表明している。\n",
      "9\n",
      "51\n",
      "0 :同\n",
      "0 :キ\n",
      "0 :ャ\n",
      "0 :ン\n",
      "0 :ペ\n",
      "0 :ー\n",
      "0 :ン\n",
      "0 :よ\n",
      "0 :る\n",
      "0 :と\n",
      "0 :、\n",
      "6 :<del>\n",
      "6 :こ\n",
      "0 :れ\n",
      "0 :ま\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :に\n",
      "0 :各\n",
      "0 :国\n",
      "0 :の\n",
      "0 :約\n",
      "0 :６\n",
      "0 :０\n",
      "0 :０\n",
      "0 :が\n",
      "0 :市\n",
      "0 :民\n",
      "0 :団\n",
      "0 :体\n",
      "0 :や\n",
      "0 :労\n",
      "0 :働\n",
      "0 :組\n",
      "0 :合\n",
      "0 :が\n",
      "0 :、\n",
      "0 :Ｍ\n",
      "0 :Ａ\n",
      "0 :Ｉ\n",
      "0 :に\n",
      "0 :反\n",
      "0 :対\n",
      "0 :を\n",
      "0 :表\n",
      "0 :明\n",
      "0 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :。\n",
      "最近の毎日新聞は元気があり面白い、と私は思っている。「時代の風」に代表される連載企画物、連載小説など楽しみにしているものが多い。\n",
      "最近の毎日新聞元気があり面白い、ｔ私は思っている。「時代の風」に代表れる連載企画物、連載小説な楽しぬにしているものが多いい。\n",
      "1 1\n",
      "最近の毎日新聞元気があり面白い、<mask>私は思っている。「時代の風」に代表れる連載企画物、連載小説な楽し<mask>にしているものが多い。\n",
      "9\n",
      "63\n",
      "0 :最\n",
      "0 :近\n",
      "0 :の\n",
      "0 :毎\n",
      "0 :日\n",
      "0 :新\n",
      "0 :聞\n",
      "0 :元\n",
      "0 :気\n",
      "0 :が\n",
      "0 :あ\n",
      "0 :り\n",
      "0 :面\n",
      "0 :白\n",
      "0 :い\n",
      "3 :、\n",
      "0 :<mask> :誤: ['と', 'な', 'を']\n",
      "0 :私\n",
      "0 :は\n",
      "0 :思\n",
      "0 :っ\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :。\n",
      "0 :「\n",
      "0 :時\n",
      "0 :代\n",
      "0 :の\n",
      "0 :風\n",
      "0 :」\n",
      "0 :に\n",
      "0 :代\n",
      "0 :表\n",
      "0 :れ\n",
      "0 :る\n",
      "0 :連\n",
      "0 :載\n",
      "0 :企\n",
      "0 :画\n",
      "0 :物\n",
      "0 :、\n",
      "0 :連\n",
      "0 :載\n",
      "0 :小\n",
      "0 :説\n",
      "0 :な\n",
      "0 :楽\n",
      "3 :し\n",
      "0 :<mask> :誤: ['み', 'さ', 'き']\n",
      "0 :に\n",
      "0 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :も\n",
      "0 :の\n",
      "0 :が\n",
      "0 :多\n",
      "6 :<del>\n",
      "6 :い\n",
      "0 :。\n",
      "出発したホテルに到着した。私もいってしまおう。自分で自分を褒めてあげたい……と。そして皆に助けられて完走できたのだ。すばらしい仲間たちよ、ありがとう。\n",
      "出発したホテル到着しぷ。私もっｓまおう。自分でで自分を褒めめてあげげたい……と。そして皆に助けられて完走できぜのだ。すばらししい仲間たちよ、ありがととう。\n",
      "1 1\n",
      "出発したホテル到着し<mask>。私もっ<mask>まおう。自分で自分を褒めてあげたい……と。そして皆に助けられて完走でき<mask>のだ。すばらしい仲間たち<mask><mask>よ、ありがとう。\n",
      "9\n",
      "76\n",
      "0 :出\n",
      "0 :発\n",
      "0 :し\n",
      "0 :た\n",
      "0 :ホ\n",
      "0 :テ\n",
      "0 :ル\n",
      "0 :到\n",
      "0 :着\n",
      "3 :し\n",
      "0 :<mask> :誤: ['た', 'て', 'よ']\n",
      "0 :。\n",
      "0 :私\n",
      "0 :も\n",
      "3 :っ\n",
      "0 :<mask> :誤: ['て', 'と', 'た']\n",
      "0 :ま\n",
      "0 :お\n",
      "0 :う\n",
      "0 :。\n",
      "0 :自\n",
      "0 :分\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :自\n",
      "0 :分\n",
      "0 :を\n",
      "0 :褒\n",
      "0 :め\n",
      "6 :<del>\n",
      "6 :て\n",
      "0 :あ\n",
      "0 :げ\n",
      "0 :た\n",
      "6 :<del>\n",
      "6 :い\n",
      "0 :…\n",
      "0 :…\n",
      "0 :と\n",
      "0 :。\n",
      "0 :そ\n",
      "0 :し\n",
      "0 :て\n",
      "0 :皆\n",
      "0 :に\n",
      "0 :助\n",
      "0 :け\n",
      "0 :ら\n",
      "0 :れ\n",
      "0 :て\n",
      "0 :完\n",
      "0 :走\n",
      "0 :で\n",
      "0 :き\n",
      "0 :<mask> :誤: ['た', 'る', 'ん']\n",
      "0 :の\n",
      "3 :だ\n",
      "0 :。\n",
      "0 :す\n",
      "0 :ば\n",
      "0 :ら\n",
      "0 :し\n",
      "0 :い\n",
      "0 :仲\n",
      "6 :<del>\n",
      "6 :間\n",
      "0 :た\n",
      "0 :ち\n",
      "0 :<mask> :脱: ['で', 'に', 'ゃ']\n",
      "0 :<mask> :脱: ['す', 'せ', 'し']\n",
      "2 :よ\n",
      "-1 :、\n",
      "-1 :あ\n",
      "0 :り\n",
      "0 :が\n",
      "0 :と"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :参\n",
      "0 :加\n",
      "0 :し\n",
      "0 :た\n",
      "0 :約\n",
      "0 :１\n",
      "0 :５\n",
      "0 :０\n",
      "0 :０\n",
      "0 :人\n",
      "0 :が\n",
      "0 :華\n",
      "0 :道\n",
      "0 :精\n",
      "0 :進\n",
      "0 :を\n",
      "6 :<del>\n",
      "6 :誓\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :。\n",
      "ほかに大正時代の流行歌や童謡なども。\n",
      "ほかに大正時代の流行歌で童謡なども。\n",
      "1 0\n",
      "広い敷地を一つの「家」と見立て、さまざまな趣向を凝らした七つのオープンスペースを設ける。\n",
      "広ぇ敷地を一つの「家」と見立て、さまざまな趣向をを凝らをた七ｔのオープンスペースをを設けるる。\n",
      "1 1\n",
      "広<mask>敷地を一つの「家」と見立て、さまざまな趣向を凝ら<mask>た七<mask>のオープンスペースを設ける。\n",
      "9\n",
      "46\n",
      "3 :広\n",
      "0 :<mask> :誤: ['い', 'く', 'の']\n",
      "0 :敷\n",
      "0 :地\n",
      "0 :を\n",
      "0 :一\n",
      "0 :つ\n",
      "0 :の\n",
      "0 :「\n",
      "0 :家\n",
      "0 :」\n",
      "0 :と\n",
      "0 :見\n",
      "0 :立\n",
      "0 :て\n",
      "0 :、\n",
      "0 :さ\n",
      "0 :ま\n",
      "0 :ざ\n",
      "0 :ま\n",
      "0 :な\n",
      "0 :趣\n",
      "0 :向\n",
      "6 :<del>\n",
      "6 :を\n",
      "0 :凝\n",
      "0 :ら\n",
      "3 :<mask> :誤: ['し', 'せ', 'す']\n",
      "0 :た\n",
      "0 :七\n",
      "3 :<mask> :誤: ['つ', 'て', 'め']\n",
      "0 :の\n",
      "0 :オ\n",
      "0 :ー\n",
      "0 :プ\n",
      "0 :ン\n",
      "0 :ス\n",
      "0 :ペ\n",
      "0 :ー\n",
      "0 :ス\n",
      "0 :を\n",
      "6 :<del>\n",
      "6 :設\n",
      "0 :け\n",
      "0 :る\n",
      "0 :。\n",
      "この映画は、すごい発明をしたジョー\n",
      "この映画は、すごい発明をしたジョー\n",
      "0 0\n",
      "意外だったのはアルバニア系代表団が３年間の暫定期間後に独立を問う住民投票実施に固執した点だ。\n",
      "意外だったたのアルバニア系代表団が３年間の暫定期間後に独立を問う住民投票実施に固執しした点だ。\n",
      "1 1\n",
      "意外だったのアルバニア系代表団が３年間の暫定期間後に独立を問う住民投票実施に固執した点だ。\n",
      "9\n",
      "47\n",
      "0 :意\n",
      "0 :外\n",
      "0 :だ\n",
      "0 :っ\n",
      "6 :<del>\n",
      "6 :た\n",
      "0 :の\n",
      "0 :ア\n",
      "0 :ル\n",
      "0 :バ\n",
      "0 :ニ\n",
      "0 :ア\n",
      "0 :系\n",
      "0 :代\n",
      "0 :表\n",
      "0 :団\n",
      "0 :が\n",
      "0 :３\n",
      "0 :年\n",
      "0 :間\n",
      "0 :の\n",
      "0 :暫\n",
      "0 :定\n",
      "0 :期\n",
      "0 :間\n",
      "0 :後\n",
      "0 :に\n",
      "0 :独\n",
      "0 :立\n",
      "0 :を\n",
      "0 :問\n",
      "0 :う\n",
      "0 :住\n",
      "0 :民\n",
      "0 :投\n",
      "0 :票\n",
      "0 :実\n",
      "0 :施\n",
      "0 :に\n",
      "0 :固\n",
      "0 :執\n",
      "0 :し\n",
      "6 :<del>\n",
      "6 :た\n",
      "0 :点\n",
      "0 :だ\n",
      "0 :。\n",
      "計算可能性とは販売量、価格、時間などが数量化、定量化され、製品や労働が規格化されることを意味する。\n",
      "計算可能性とは販売量、価格、時間などが数量化、定量化され、製品や労働がが規格化されることを意味する。\n",
      "1 1\n",
      "計算可能性とは販売量、価格、時間などが数量化、定量化され、製品や労働が規格化されることを意味する。\n",
      "9\n",
      "51\n",
      "0 :計\n",
      "0 :算\n",
      "0 :可\n",
      "0 :能\n",
      "0 :性\n",
      "0 :と\n",
      "0 :は\n",
      "0 :販\n",
      "0 :売\n",
      "0 :量\n",
      "0 :、\n",
      "0 :価\n",
      "0 :格\n",
      "0 :、\n",
      "0 :時\n",
      "0 :間\n",
      "0 :な\n",
      "0 :ど\n",
      "0 :が\n",
      "0 :数\n",
      "0 :量\n",
      "0 :化\n",
      "0 :、\n",
      "0 :定\n",
      "0 :量\n",
      "0 :化\n",
      "0 :さ\n",
      "0 :れ\n",
      "0 :、\n",
      "0 :製\n",
      "0 :品\n",
      "0 :や\n",
      "0 :労\n",
      "0 :働\n",
      "6 :<del>\n",
      "6 :が\n",
      "0 :規\n",
      "0 :格\n",
      "0 :化\n",
      "0 :さ\n",
      "0 :れ\n",
      "0 :る\n",
      "0 :こ\n",
      "0 :と\n",
      "0 :を\n",
      "0 :意\n",
      "0 :味\n",
      "0 :す\n",
      "0 :る\n",
      "0 :。\n",
      "人なつっこい平和な顔の３匹だ。\n",
      "人つっここい平和な顔の３匹だ。\n",
      "1 1\n",
      "人つっこい平和な顔の３匹だ。\n",
      "9\n",
      "16\n",
      "0 :人\n",
      "0 :つ\n",
      "0 :っ\n",
      "6 :<del>\n",
      "6 :こ\n",
      "0 :い\n",
      "0 :平\n",
      "0 :和\n",
      "0 :な\n",
      "0 :顔\n",
      "0 :の\n",
      "0 :３\n",
      "0 :匹\n",
      "0 :だ\n",
      "0 :。\n",
      "改造社の賀川豊彦「死線を越えて」はなんと百万部。\n",
      "改造社の賀川豊彦「死線を越えて」はなんと百万部。\n",
      "0 0\n",
      "現状では番組を発注した放送局側に著作権が帰属してしまい、作り手に権利がないことが多い。\n",
      "現状ででｈ番組を発注したた放送局側に著作権が帰属ししままい、作り手ｎ権利がないｋとが多い。\n",
      "1 1\n",
      "現状で<mask>番組を発注した放送局側に著作権が帰属しまい、作り手<mask>権利がない<mask>とが多い。\n",
      "9\n",
      "43\n",
      "0 :現\n",
      "0 :状\n",
      "6 :<del>\n",
      "6 :で\n",
      "3 :<mask> :誤: ['は', 'も', 'の']\n",
      "0 :番\n",
      "0 :組\n",
      "0 :を\n",
      "0 :発\n",
      "0 :注\n",
      "0 :し\n",
      "0 :た\n",
      "6 :<del>\n",
      "6 :放\n",
      "0 :送\n",
      "0 :局\n",
      "0 :側\n",
      "0 :に\n",
      "0 :著\n",
      "0 :作\n",
      "0 :権\n",
      "0 :が\n",
      "0 :帰\n",
      "0 :属\n",
      "0 :し\n",
      "0 :ま\n",
      "6 :<del>\n",
      "6 :い\n",
      "0 :、\n",
      "6 :<del>\n",
      "6 :作\n",
      "0 :り\n",
      "0 :手\n",
      "0 :<mask> :誤: ['の', 'に', 'は']\n",
      "0 :権\n",
      "0 :利\n",
      "3 :が\n",
      "0 :な\n",
      "0 :い\n",
      "0 :<mask> :誤: ['こ', 'も', 'ご']\n",
      "0 :と\n",
      "0 :が\n",
      "3 :多\n",
      "0 :い\n",
      "0 :。\n",
      "講師はＮＨＫ解説委員の村田幸子さん。\n",
      "講師はＮＨＫ解説委員の村田幸子さん。\n",
      "0 0\n",
      "北海道豊浦町のＪＲ室蘭線礼文浜トンネルで先月２８日、重さ２トンのコンクリート塊が落下、貨物列車が脱線した事故を例に挙げ、「今後、抜き取り調査を含めた検査を高い頻度で行ってデータをそろえることや、トンネルそのものを作り替えることもしないと、大惨事が起きる可能性がある。北海道の事故はそれを示している」と警告する。\n",
      "北海道豊浦町のＪＲ室蘭線礼文浜トンネルｄ先月２８日、重２トンのコンクリート塊が落下、貨物列車ｇ脱線した事故を例挙げ、「今後、抜き取りり調査を含めた検査を高いい頻度で行ぴデータをそえるこや、トンネルそののものを作ぎ替えることもしないとと、大惨事が起きる可\n",
      "1 1\n",
      "北海道豊浦町のＪＲ室蘭線礼文浜トンネル<mask>先月２８日、重２トンのコンクリート塊が落下、貨物列車<mask>脱線した事故を例挙げ、「今後、抜き取り調査を含めた検査を高い頻度で行<mask>データをそ<mask><mask>えるこ<mask>や、トンネルそのものを作ぎ替えることもしないと、大惨事が起きる可\n",
      "9\n",
      "127\n",
      "0 :北\n",
      "0 :海\n",
      "0 :道\n",
      "0 :豊\n",
      "0 :浦\n",
      "0 :町\n",
      "0 :の\n",
      "0 :Ｊ\n",
      "0 :Ｒ\n",
      "0 :室\n",
      "0 :蘭\n",
      "0 :線\n",
      "0 :礼\n",
      "0 :文\n",
      "0 :浜\n",
      "0 :ト\n",
      "0 :ン\n",
      "0 :ネ\n",
      "3 :ル\n",
      "0 :<mask> :誤: ['は', 'が', 'で']\n",
      "0 :先\n",
      "0 :月\n",
      "0 :２\n",
      "0 :８\n",
      "0 :日\n",
      "0 :、\n",
      "0 :重\n",
      "0 :２\n",
      "0 :ト\n",
      "0 :ン\n",
      "0 :の\n",
      "0 :コ\n",
      "0 :ン\n",
      "0 :ク\n",
      "0 :リ\n",
      "0 :ー\n",
      "0 :ト\n",
      "0 :塊\n",
      "0 :が\n",
      "0 :落\n",
      "0 :下\n",
      "0 :、\n",
      "0 :貨\n",
      "0 :物\n",
      "0 :列\n",
      "3 :車\n",
      "0 :<mask> :誤: ['が', 'で', 'を']\n",
      "0 :脱\n",
      "0 :線\n",
      "0 :し\n",
      "0 :た\n",
      "0 :事\n",
      "0 :故\n",
      "0 :を\n",
      "0 :例\n",
      "0 :挙\n",
      "0 :げ\n",
      "0 :、\n",
      "0 :「\n",
      "0 :今\n",
      "0 :後\n",
      "0 :、\n",
      "0 :抜\n",
      "0 :き\n",
      "0 :取\n",
      "6 :<del>\n",
      "6 :り\n",
      "0 :調\n",
      "0 :査\n",
      "0 :を\n",
      "0 :含\n",
      "0 :め\n",
      "0 :た\n",
      "0 :検\n",
      "0 :査\n",
      "0 :を\n",
      "0 :高\n",
      "0 :い\n",
      "6 :<del>\n",
      "6 :頻\n",
      "0 :度\n",
      "0 :で\n",
      "0 :行\n",
      "0 :<mask> :誤: ['う', 'く', 'き']\n",
      "3 :デ\n",
      "0 :ー\n",
      "0 :タ\n",
      "0 :を\n",
      "0 :そ\n",
      "2 :<mask> :脱: ['ぎ', 'う', 'そ']\n",
      "-1 :<mask> :脱: ['が', 'な', 'ら']\n",
      "-1 :え\n",
      "0 :る\n",
      "0 :こ\n",
      "1 :<mask> :脱: ['と', 'れ', 'う']\n",
      "-1 :や\n",
      "0 :、\n",
      "0 :ト\n",
      "0 :ン\n",
      "0 :ネ\n",
      "0 :ル\n",
      "0 :そ\n",
      "0 :の\n",
      "0 :も\n",
      "6 :<del>\n",
      "6 :の\n",
      "0 :を\n",
      "0 :作\n",
      "0 :ぎ\n",
      "0 :替\n",
      "0 :え\n",
      "0 :る\n",
      "0 :こ\n",
      "0 :と\n",
      "0 :も\n",
      "0 :し\n",
      "0 :な\n",
      "0 :い\n",
      "0 :と\n",
      "0 :、\n",
      "0 :大\n",
      "6 :<del>\n",
      "6 :惨\n",
      "0 :事\n",
      "0 :が\n",
      "0 :起\n",
      "0 :き\n",
      "0 :る\n",
      "0 :可\n",
      "現在、前売り中です。\n",
      "現在、前売り中です。\n",
      "0 0\n",
      "訴えによると、コネクティクスはプレステの機能制御用ソフトの一つである「ＢＩＯＳ」を無断で複製し、プレステ用に開発したゲームを米アップルコンピュータ製パソコンで楽しめるソフトを開発、著作権などソニーの知的所有権を侵害したという。\n",
      "訴えによると、コネクティクスやプレステの機能制御用ソフトの一けである「ＢＩＯＳ」無断で複製し、プレステ用に開発しごゲームを米アップルコンピュータ製パソコンでで楽しｍるソフトを開発、著作権などソニー知的所有権を侵害ｓたはいう。\n",
      "1 1\n",
      "訴えによると、コネクティクスやプレステの機能制御用ソフトの一けである「ＢＩＯＳ」無断で複製し、プレステ用に開発し<mask>ゲームを米アップルコンピュータ製パソコンで楽し<mask>るソフトを開発、著作権などソニー知的所有権を侵害<mask>た<mask>いう。\n",
      "9\n",
      "113\n",
      "0 :訴\n",
      "0 :え\n",
      "0 :に\n",
      "0 :よ\n",
      "0 :る\n",
      "0 :と\n",
      "0 :、\n",
      "0 :コ\n",
      "0 :ネ\n",
      "0 :ク\n",
      "0 :テ\n",
      "0 :ィ\n",
      "0 :ク\n",
      "0 :ス\n",
      "0 :や\n",
      "0 :プ\n",
      "0 :レ\n",
      "0 :ス\n",
      "0 :テ\n",
      "0 :の\n",
      "0 :機\n",
      "0 :能\n",
      "0 :制\n",
      "0 :御\n",
      "0 :用\n",
      "0 :ソ\n",
      "0 :フ\n",
      "0 :ト\n",
      "0 :の\n",
      "0 :一\n",
      "0 :け\n",
      "0 :で\n",
      "0 :あ\n",
      "0 :る\n",
      "0 :「\n",
      "0 :Ｂ\n",
      "0 :Ｉ\n",
      "0 :Ｏ\n",
      "0 :Ｓ\n",
      "0 :」\n",
      "0 :無\n",
      "0 :断\n",
      "0 :で\n",
      "0 :複\n",
      "0 :製\n",
      "0 :し\n",
      "0 :、\n",
      "0 :プ\n",
      "0 :レ\n",
      "0 :ス\n",
      "0 :テ\n",
      "0 :用\n",
      "0 :に\n",
      "0 :開\n",
      "0 :発\n",
      "3 :し\n",
      "0 :<mask> :誤: ['た', 'て', 'る']\n",
      "0 :ゲ\n",
      "0 :ー\n",
      "0 :ム\n",
      "0 :を\n",
      "0 :米\n",
      "0 :ア\n",
      "0 :ッ\n",
      "0 :プ\n",
      "0 :ル\n",
      "0 :コ\n",
      "0 :ン\n",
      "0 :ピ\n",
      "0 :ュ\n",
      "0 :ー\n",
      "0 :タ\n",
      "0 :製\n",
      "0 :パ\n",
      "0 :ソ\n",
      "0 :コ\n",
      "0 :ン\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :楽\n",
      "0 :し\n",
      "3 :<mask> :誤: ['め', 'げ', 'す']\n",
      "0 :る\n",
      "0 :ソ\n",
      "0 :フ\n",
      "0 :ト\n",
      "0 :を\n",
      "0 :開\n",
      "0 :発\n",
      "0 :、\n",
      "0 :著\n",
      "0 :作\n",
      "0 :権\n",
      "0 :な\n",
      "0 :ど\n",
      "0 :ソ\n",
      "0 :ニ\n",
      "0 :ー\n",
      "0 :知\n",
      "0 :的\n",
      "0 :所\n",
      "0 :有\n",
      "0 :権\n",
      "0 :を\n",
      "0 :侵\n",
      "0 :害\n",
      "3 :<mask> :誤: ['し', 'せ', 'す']\n",
      "0 :た\n",
      "3 :<mask> :誤: ['と', 'め', 'だ']\n",
      "0 :い\n",
      "0 :う\n",
      "0 :。\n",
      "同選手はスポルティング・リスボン、ベンフィカ、アトレチコ・マドリードなどポルトガル、スペインのチームを中心に活躍。\n",
      "同選手ははスポルティング・リスボン、ベンフィカ、アトレチコ・マドリードぃどポルトガル、スペインチームを中心に活躍。\n",
      "1 1\n",
      "同選手スポルティング・リスボン、ベンフィカ、アトレチコ・マドリード<mask>どポルトガル、スペインチームを中心に活躍。\n",
      "9\n",
      "57\n",
      "0 :同\n",
      "0 :選\n",
      "6 :<del>\n",
      "6 :手\n",
      "6 :<del>\n",
      "6 :ス\n",
      "0 :ポ\n",
      "0 :ル\n",
      "0 :テ\n",
      "0 :ィ\n",
      "0 :ン\n",
      "0 :グ\n",
      "0 :・\n",
      "0 :リ\n",
      "0 :ス\n",
      "0 :ボ\n",
      "0 :ン\n",
      "0 :、\n",
      "0 :ベ\n",
      "0 :ン\n",
      "0 :フ\n",
      "0 :ィ\n",
      "0 :カ\n",
      "0 :、\n",
      "0 :ア\n",
      "0 :ト\n",
      "0 :レ\n",
      "0 :チ\n",
      "0 :コ\n",
      "0 :・\n",
      "0 :マ\n",
      "0 :ド\n",
      "0 :リ\n",
      "0 :ー\n",
      "0 :ド\n",
      "0 :<mask> :誤: ['な', 'ほ', 'こ']\n",
      "3 :ど\n",
      "0 :ポ\n",
      "0 :ル\n",
      "0 :ト\n",
      "0 :ガ\n",
      "0 :ル\n",
      "0 :、\n",
      "0 :ス\n",
      "0 :ペ\n",
      "0 :イ\n",
      "0 :ン\n",
      "0 :チ\n",
      "0 :ー\n",
      "0 :ム\n",
      "0 :を\n",
      "0 :中\n",
      "0 :心\n",
      "0 :に\n",
      "0 :活\n",
      "0 :躍\n",
      "0 :。\n",
      "２４時間後に別の薬品をろ紙にたらして起きる化学反応で大気汚染の程度を判定する。\n",
      "２４時間後に別の薬品ををろ紙にたらしが起きる化学反応で大気汚染のの程度判定すむ。\n",
      "1 1\n",
      "２４時間後に別の薬品をろ紙に<mask><mask>たらしが起きる化学反応で大気汚染の程度判定す<mask>。\n",
      "9\n",
      "42\n",
      "0 :２\n",
      "0 :４\n",
      "0 :時\n",
      "0 :間\n",
      "0 :後\n",
      "0 :に\n",
      "0 :別\n",
      "0 :の\n",
      "0 :薬\n",
      "0 :品\n",
      "6 :<del>\n",
      "6 :を\n",
      "0 :ろ\n",
      "0 :紙\n",
      "2 :に\n",
      "-1 :<mask> :脱: ['つ', 'す', 'た']\n",
      "-1 :<mask> :脱: ['っ', 'い', 'け']\n",
      "0 :た\n",
      "0 :ら\n",
      "0 :し\n",
      "0 :が\n",
      "0 :起\n",
      "0 :き\n",
      "0 :る\n",
      "0 :化\n",
      "0 :学\n",
      "0 :反\n",
      "0 :応\n",
      "0 :で\n",
      "0 :大\n",
      "0 :気\n",
      "0 :汚\n",
      "0 :染\n",
      "0 :"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "た\n",
      "0 :あ\n",
      "0 :と\n",
      "0 :、\n",
      "0 :昭\n",
      "0 :和\n",
      "0 :２\n",
      "0 :９\n",
      "0 :年\n",
      "0 :氏\n",
      "0 :子\n",
      "0 :さ\n",
      "0 :ん\n",
      "0 :ち\n",
      "0 :の\n",
      "0 :要\n",
      "0 :望\n",
      "0 :で\n",
      "0 :現\n",
      "0 :在\n",
      "0 :の\n",
      "0 :形\n",
      "0 :に\n",
      "0 :<mask> :誤: ['な', 'あ', 'と']\n",
      "3 :り\n",
      "0 :ま\n",
      "0 :し\n",
      "6 :<del>\n",
      "6 :た\n",
      "0 :。\n",
      "0 :１\n",
      "6 :<del>\n",
      "6 :０\n",
      "0 :月\n",
      "0 :の\n",
      "0 :秋\n",
      "0 :祭\n",
      "0 :り\n",
      "0 :は\n",
      "0 :熱\n",
      "0 :心\n",
      "0 :に\n",
      "0 :や\n",
      "0 :っ\n",
      "0 :て\n",
      "0 :い\n",
      "0 :ま\n",
      "伊吹文明労相が２８日の会見で明らかにした。\n",
      "伊吹文明労相がが２８日の会見でで明らにした。\n",
      "1 1\n",
      "伊吹文明労相が２８日の会見で明ら<mask>にした。\n",
      "9\n",
      "23\n",
      "0 :伊\n",
      "0 :吹\n",
      "0 :文\n",
      "0 :明\n",
      "0 :労\n",
      "0 :相\n",
      "6 :<del>\n",
      "6 :が\n",
      "0 :２\n",
      "0 :８\n",
      "0 :日\n",
      "0 :の\n",
      "0 :会\n",
      "0 :見\n",
      "0 :で\n",
      "6 :<del>\n",
      "6 :明\n",
      "0 :ら\n",
      "1 :<mask> :脱: ['か', 'ぎ', 'み']\n",
      "-1 :に\n",
      "0 :し\n",
      "0 :た\n",
      "0 :。\n",
      "シャスのスウィサ内相はラジオで、新政権で内相ポストを狙う移民党を「シャスの内相を怖がっている。豚肉を売る店が閉められ、売春婦が入国できなくなるからだ」と非難した。\n",
      "シャスｎスウィサ内相はラジオ、新政権で内相ポストを狙うう移民党を「シャスの内相をを怖がっていいる。豚肉を売る店が閉められ、売春婦は入国できくなるからだ」と非難した。\n",
      "1 1\n",
      "シャス<mask>スウィサ内相はラジオ、新政権で内相ポストを狙う移民党を「シャスの内相を怖がっている。豚肉を売る店が閉められ、売春婦は入国でき<mask><mask>くなるからだ」と非難した。\n",
      "9\n",
      "83\n",
      "0 :シ\n",
      "0 :ャ\n",
      "3 :ス\n",
      "0 :<mask> :誤: ['の', 'と', 'や']\n",
      "0 :ス\n",
      "0 :ウ\n",
      "0 :ィ\n",
      "0 :サ\n",
      "0 :内\n",
      "0 :相\n",
      "0 :は\n",
      "0 :ラ\n",
      "0 :ジ\n",
      "0 :オ\n",
      "0 :、\n",
      "0 :新\n",
      "0 :政\n",
      "0 :権\n",
      "0 :で\n",
      "0 :内\n",
      "0 :相\n",
      "0 :ポ\n",
      "0 :ス\n",
      "0 :ト\n",
      "0 :を\n",
      "0 :狙\n",
      "6 :<del>\n",
      "6 :う\n",
      "0 :移\n",
      "0 :民\n",
      "0 :党\n",
      "0 :を\n",
      "0 :「\n",
      "0 :シ\n",
      "0 :ャ\n",
      "0 :ス\n",
      "0 :の\n",
      "0 :内\n",
      "0 :相\n",
      "0 :を\n",
      "6 :<del>\n",
      "6 :怖\n",
      "0 :が\n",
      "0 :っ\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "6 :<del>\n",
      "6 :。\n",
      "0 :豚\n",
      "0 :肉\n",
      "0 :を\n",
      "0 :売\n",
      "0 :る\n",
      "0 :店\n",
      "0 :が\n",
      "0 :閉\n",
      "0 :め\n",
      "0 :ら\n",
      "0 :れ\n",
      "0 :、\n",
      "0 :売\n",
      "0 :春\n",
      "0 :婦\n",
      "0 :は\n",
      "0 :入\n",
      "0 :国\n",
      "0 :で\n",
      "0 :き\n",
      "0 :<mask> :脱: ['や', 'に', 'が']\n",
      "2 :<mask> :脱: ['す', 'く', 'な']\n",
      "-1 :く\n",
      "-1 :な\n",
      "0 :る\n",
      "0 :か\n",
      "0 :ら\n",
      "0 :だ\n",
      "0 :」\n",
      "0 :と\n",
      "0 :非\n",
      "0 :難\n",
      "0 :し\n",
      "0 :た\n",
      "0 :。\n",
      "頭取の社内メールに対して、行員はどう受け止めているのだろうか。４０代の行員は、「ちゃんと働いてるやつは読み飛ばしてますよ。自己変革なんて言われる筋合いはないってね」。\n",
      "頭取の社内メールｎ対しｔ、行員はど受け止めているるのろうか。４０代の行員はは、「ちゃんとと働てるつは読み飛しておすよ。自己変革んてて言われぴ筋合いはなないってね」。\n",
      "1 1\n",
      "頭取の社内メール<mask>対し<mask>、行員はど受け止めているの<mask>ろうか。４０代の行員は、「ちゃんと働<mask>てるつは読み飛<mask>しておすよ。自己変革<mask>んて言われ<mask>筋合いはないってね」。\n",
      "9\n",
      "83\n",
      "0 :頭\n",
      "0 :取\n",
      "0 :の\n",
      "0 :社\n",
      "0 :内\n",
      "0 :メ\n",
      "0 :ー\n",
      "3 :ル\n",
      "0 :<mask> :誤: ['に', 'と', 'を']\n",
      "0 :対\n",
      "3 :し\n",
      "0 :<mask> :誤: ['て', 'た', 'か']\n",
      "0 :、\n",
      "0 :行\n",
      "0 :員\n",
      "0 :は\n",
      "0 :ど\n",
      "0 :受\n",
      "0 :け\n",
      "0 :止\n",
      "0 :め\n",
      "0 :て\n",
      "0 :い\n",
      "6 :<del>\n",
      "6 :る\n",
      "1 :の\n",
      "-1 :<mask> :脱: ['だ', 'や', 'で']\n",
      "0 :ろ\n",
      "0 :う\n",
      "0 :か\n",
      "0 :。\n",
      "0 :４\n",
      "0 :０\n",
      "0 :代\n",
      "0 :の\n",
      "0 :行\n",
      "0 :員\n",
      "0 :は\n",
      "6 :<del>\n",
      "6 :、\n",
      "0 :「\n",
      "0 :ち\n",
      "0 :ゃ\n",
      "0 :ん\n",
      "0 :と\n",
      "0 :働\n",
      "6 :<del>\n",
      "6 :<mask> :脱: ['い', 'け', 'き']\n",
      "1 :て\n",
      "-1 :る\n",
      "0 :つ\n",
      "0 :は\n",
      "0 :読\n",
      "0 :み\n",
      "0 :飛\n",
      "0 :<mask> :脱: ['ば', 'ま', 'く']\n",
      "1 :し\n",
      "-1 :て\n",
      "0 :お\n",
      "0 :す\n",
      "0 :よ\n",
      "0 :。\n",
      "0 :自\n",
      "0 :己\n",
      "0 :変\n",
      "0 :革\n",
      "0 :<mask> :脱: ['な', 'っ', 'さ']\n",
      "1 :ん\n",
      "-1 :て\n",
      "0 :言\n",
      "0 :わ\n",
      "6 :<del>\n",
      "6 :れ\n",
      "0 :<mask> :誤: ['る', 'た', 'て']\n",
      "0 :筋\n",
      "0 :合\n",
      "3 :い\n",
      "0 :は\n",
      "0 :な\n",
      "0 :い\n",
      "0 :っ\n",
      "0 :て\n",
      "6 :<del>\n",
      "6 :ね\n",
      "0 :」\n",
      "0 :。\n",
      "カラブラク村から３キロほど山間に入った政府軍の前線基地で、現地指揮官は３００メートルほど離れた小高い山の頂上を指さした。\n",
      "カラブラク村から３キロど山間入った政府軍の前線基地でで、現地指揮官は３００メートルほど離れｔ小高い山の頂上を指さた。\n",
      "1 1\n",
      "カラブラク村から３キロど山間入った政府軍の前線基地で、現地指揮官は３００メートルほど離れ<mask>小高い山の頂上を指さ<mask><mask>た。\n",
      "9\n",
      "61\n",
      "0 :カ\n",
      "0 :ラ\n",
      "0 :ブ\n",
      "0 :ラ\n",
      "0 :ク\n",
      "0 :村\n",
      "0 :か\n",
      "0 :ら\n",
      "0 :３\n",
      "0 :キ\n",
      "0 :ロ\n",
      "0 :ど\n",
      "0 :山\n",
      "0 :間\n",
      "0 :入\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :政\n",
      "0 :府\n",
      "0 :軍\n",
      "0 :の\n",
      "0 :前\n",
      "0 :線\n",
      "0 :基\n",
      "0 :地\n",
      "6 :<del>\n",
      "6 :で\n",
      "0 :、\n",
      "0 :現\n",
      "0 :地\n",
      "0 :指\n",
      "0 :揮\n",
      "0 :官\n",
      "0 :は\n",
      "0 :３\n",
      "0 :０\n",
      "0 :０\n",
      "0 :メ\n",
      "0 :ー\n",
      "0 :ト\n",
      "0 :ル\n",
      "0 :ほ\n",
      "0 :ど\n",
      "0 :離\n",
      "0 :れ\n",
      "3 :<mask> :誤: ['た', 'る', 'て']\n",
      "0 :小\n",
      "0 :高\n",
      "0 :い\n",
      "0 :山\n",
      "0 :の\n",
      "0 :頂\n",
      "0 :上\n",
      "0 :を\n",
      "0 :指\n",
      "2 :さ\n",
      "-1 :<mask> :脱: ['さ', 'し', 'な']\n",
      "-1 :<mask> :脱: ['っ', 'い', 'し']\n",
      "0 :た\n",
      "0 :。\n",
      "役割分担を置き去りにし、ふわりと解放された。\n",
      "役割分担を置き去りりにしし、ふわりと解放された。\n",
      "1 1\n",
      "役割分担を置き去りにし、ふ<mask><mask>わりと解放された。\n",
      "9\n",
      "26\n",
      "0 :役\n",
      "0 :割\n",
      "0 :分\n",
      "0 :担\n",
      "0 :を\n",
      "0 :置\n",
      "0 :き\n",
      "0 :去\n",
      "6 :<del>\n",
      "6 :り\n",
      "0 :に\n",
      "0 :し\n",
      "6 :<del>\n",
      "6 :、\n",
      "0 :ふ\n",
      "2 :<mask> :脱: ['り', 'さ', 'わ']\n",
      "-1 :<mask> :脱: ['ま', 'か', 'し']\n",
      "-1 :わ\n",
      "0 :り\n",
      "0 :と\n",
      "0 :解\n",
      "0 :放\n",
      "0 :さ\n",
      "0 :れ\n",
      "0 :た\n",
      "0 :。\n",
      "だが、昇格を確実にできる決勝進出を前に、準決勝で残り８秒で逆転負け。\n",
      "だが、昇格を確実ににでる決勝進出を前に、準決勝でで残い８秒で逆転負け。\n",
      "1 1\n",
      "だが、昇格を確実に<mask>る決勝進出を前に、準決勝で残い８秒で逆転負け。\n",
      "9\n",
      "35\n",
      "0 :だ\n",
      "0 :が\n",
      "0 :、\n",
      "0 :昇\n",
      "0 :格\n",
      "0 :を\n",
      "0 :確\n",
      "0 :実\n",
      "6 :<del>\n",
      "6 :に\n",
      "3 :<mask> :誤: ['す', 'い', 'し']\n",
      "0 :る\n",
      "0 :決\n",
      "0 :勝\n",
      "0 :進\n",
      "0 :出\n",
      "0 :を\n",
      "0 :前\n",
      "0 :に\n",
      "0 :、\n",
      "0 :準\n",
      "0 :決\n",
      "0 :勝\n",
      "0 :で\n",
      "6 :<del>\n",
      "6 :残\n",
      "0 :い\n",
      "0 :８\n",
      "0 :秒\n",
      "0 :で\n",
      "0 :逆\n",
      "0 :転\n",
      "0 :負\n",
      "0 :け\n",
      "0 :。\n",
      "結局、議論は平行線のまま終わった。\n",
      "結局、議論は平行線のまま終わった。\n",
      "0 1\n",
      "結局、議論は平行線のまま終わった。\n",
      "9\n",
      "19\n",
      "0 :結\n",
      "0 :局\n",
      "0 :、\n",
      "0 :議\n",
      "0 :論\n",
      "0 :は\n",
      "0 :平\n",
      "0 :行\n",
      "0 :線\n",
      "0 :の\n",
      "0 :ま\n",
      "0 :ま\n",
      "0 :終\n",
      "0 :わ\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :。\n",
      "亜大は６勝３敗となり、残り試合を全勝しても８勝３敗。\n",
      "亜大は６勝３敗となり、残り試合を全勝しても８勝３敗。\n",
      "0 0\n",
      "証券取引等監視委員会は今月２２日、ヤクルト本社など５社の幹部に約６億２０００万円のリベートを提供したなど８件の違反行為を指摘し、監督庁に対して行政処分を求める勧告をしていた。\n",
      "証券取引等監視委員会は今月２２日、ヤクルト本社などど５社の幹部に約６億２０００万円のリベートをを提供しど８件のの違反行為をを指摘し、監督庁にに対して行政処分求めるる勧告していた。\n",
      "1 1\n",
      "証券取引等監視委員会は今月２２日、ヤクルト本社など５社の幹部に約６億２０００万円のリベートを提供し<mask>８件の違反行為を指摘し、監督庁に対して行政処分<mask><mask>求める勧告していた。\n",
      "9\n",
      "87\n",
      "0 :証\n",
      "0 :券\n",
      "0 :取\n",
      "0 :引\n",
      "0 :等\n",
      "0 :監\n",
      "0 :視\n",
      "0 :委\n",
      "0 :員\n",
      "0 :会\n",
      "0 :は\n",
      "0 :今\n",
      "0 :月\n",
      "0 :２\n",
      "0 :２\n",
      "0 :日\n",
      "0 :、\n",
      "0 :ヤ\n",
      "0 :ク\n",
      "0 :ル\n",
      "0 :ト\n",
      "0 :本\n",
      "0 :社\n",
      "0 :な\n",
      "6 :<del>\n",
      "6 :ど\n",
      "0 :５\n",
      "0 :社\n",
      "0 :の\n",
      "0 :幹\n",
      "0 :部\n",
      "0 :に\n",
      "0 :約\n",
      "0 :６\n",
      "0 :億\n",
      "0 :２\n",
      "0 :０\n",
      "0 :０\n",
      "0 :０\n",
      "0 :万\n",
      "0 :円\n",
      "0 :の\n",
      "0 :リ\n",
      "0 :ベ\n",
      "0 :ー\n",
      "0 :ト\n",
      "0 :を\n",
      "6 :<del>\n",
      "6 :提\n",
      "0 :供\n",
      "0 :し\n",
      "0 :<mask> :誤: ['た', 'て', 'る']\n",
      "3 :８\n",
      "0 :件\n",
      "0 :の\n",
      "0 :違\n",
      "6 :<del>\n",
      "6 :反\n",
      "0 :行\n",
      "0 :為\n",
      "0 :を\n",
      "0 :指\n",
      "0 :摘\n",
      "6 :<del>\n",
      "6 :し\n",
      "0 :、\n",
      "0 :監\n",
      "0 :督\n",
      "0 :庁\n",
      "0 :に\n",
      "0 :対\n",
      "0 :し\n",
      "0 :て\n",
      "6 :<del>\n",
      "6 :行\n",
      "0 :政\n",
      "0 :処\n",
      "0 :分\n",
      "0 :<mask> :脱: ['ま', 'よ', 'に']\n",
      "0 :<mask> :脱: ['を', 'も', 'で']\n",
      "0 :求\n",
      "2 :め\n",
      "-1 :る\n",
      "-1 :勧\n",
      "0 :告\n",
      "0 :し\n",
      "0 :て\n",
      "6 :<del>\n",
      "6 :い\n",
      "0 :た\n",
      "0 :。\n",
      "日本だけではない。\n",
      "日本ぉけでははない。\n",
      "1 1\n",
      "日本<mask>けではない。\n",
      "9\n",
      "11\n",
      "0 :日\n",
      "3 :本\n",
      "0 :<mask> :誤: ['だ', 'わ', 'も']\n",
      "0 :け\n",
      "0 :で\n",
      "6 :<del>\n",
      "6 :は\n",
      "0 :な\n",
      "0 :い\n",
      "0 :。\n",
      "２９日午後１０時５５分ごろ、兵庫県尼崎市七松町２の市道で、自転車で帰宅途中の近くの無職女性が、ミニバイクの若い男に前かごの現金約７０万円入り手提げカバンをひったくられた。\n",
      "２９日午後１０時５５分やろ、兵庫県尼崎市七松町２の市道で、自転車で帰宅途中の近く無職女性が、ミニバイクの若い男に前かｇの現金約７０万円入ｒ手提げカバンをひったたくられたた。\n",
      "1 1\n",
      "２９日午後１０時５５分<mask>ろ、兵庫県尼崎市七松町２の市道で、自転車で帰宅途中の近く無職女性が、ミニバイクの若い男に前か<mask>の現金約７０万円入<mask>手提げカバンをひったくられた。\n",
      "9\n",
      "86\n",
      "0 :２\n",
      "0 :９\n",
      "0 :日\n",
      "0 :午\n",
      "0 :後\n",
      "0 :１\n",
      "0 :０\n",
      "0 :時\n",
      "0 :５\n",
      "0 :５\n",
      "3 :分\n",
      "0 :<mask> :誤: ['ご', 'こ', 'す']\n",
      "0 :ろ\n",
      "0 :、\n",
      "0 :兵\n",
      "0 :庫\n",
      "0 :県\n",
      "0 :尼\n",
      "0 :崎\n",
      "0 :市\n",
      "0 :七\n",
      "0 :松\n",
      "0 :町\n",
      "0 :２\n",
      "0 :の\n",
      "0 :市\n",
      "0 :道\n",
      "0 :で\n",
      "0 :、\n",
      "0 :自\n",
      "0 :転\n",
      "0 :車\n",
      "0 :で\n",
      "0 :帰\n",
      "0 :宅\n",
      "0 :途\n",
      "0 :中\n",
      "0 :の\n",
      "0 :近\n",
      "0 :く\n",
      "0 :無\n",
      "0 :職\n",
      "0 :女\n",
      "0 :性\n",
      "0 :が\n",
      "0 :、\n",
      "0 :ミ\n",
      "0 :ニ\n",
      "0 :バ\n",
      "0 :イ\n",
      "0 :ク\n",
      "0 :の\n",
      "0 :若\n",
      "0 :い\n",
      "0 :男\n",
      "0 :に\n",
      "0 :前\n",
      "3 :か\n",
      "0 :<mask> :誤: ['ら', 'ず', 'ご']\n",
      "0 :の\n",
      "0 :現\n",
      "0 :金\n",
      "0 :約\n",
      "0 :７\n",
      "0 :０\n",
      "0 :万\n",
      "0 :円\n",
      "3 :入\n",
      "0 :<mask> :誤: ['り', 'る', 'れ']\n",
      "0 :手\n",
      "0 :提\n",
      "0 :げ\n",
      "0 :カ\n",
      "0 :バ\n",
      "0 :ン\n",
      "0 :を\n",
      "0 :ひ"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " :事\n",
      "0 :の\n",
      "0 :合\n",
      "0 :間\n",
      "3 :を\n",
      "0 :<mask> :誤: ['も', 'や', 'と']\n",
      "0 :っ\n",
      "0 :て\n",
      "0 :体\n",
      "0 :力\n",
      "0 :維\n",
      "0 :持\n",
      "0 :に\n",
      "0 :努\n",
      "0 :め\n",
      "0 :、\n",
      "0 :戦\n",
      "0 :術\n",
      "0 :を\n",
      "0 :勉\n",
      "0 :強\n",
      "0 :し\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :。\n",
      "調べでは、金容疑者は１０日午前９時ごろ、大阪市中央区宗右衛門町の雑居ビル地下１階で、兵頭さんを殴ったりけったりして、キャッシュカードなどが入った財布を奪った疑い。兵頭さんは同日夜、意識不明で倒れているのを発見されたが、１２日に死亡した。\n",
      "調べは、金容疑者は１０日午前９時ご、大阪市中央区宗右衛門町の雑居ビル地下１階で、兵頭ささんを殴ったりりけったたりしｔ、キャッシュカードなどどが入った財布を奪っｔ疑い。兵頭さん同日夜、意識不明でで倒れてちるるのを発見されたが、１２日に死亡しｔ。\n",
      "1 1\n",
      "調べ<mask>は、金容疑者は１０日午前９時ご<mask><mask>、大阪市中央区宗右衛門町の雑居ビル地下１階で、兵頭さんを殴ったりけったりし<mask>、キャッシュカードなどが入った財布を奪っ<mask>疑い。兵頭さん<mask><mask>同日夜、意識不明で倒れて<mask>るのを発見されたが、１２日に死亡し<mask>。\n",
      "9\n",
      "122\n",
      "1 :調\n",
      "-1 :べ\n",
      "0 :<mask> :脱: ['で', 'に', 'ら']\n",
      "0 :は\n",
      "0 :、\n",
      "0 :金\n",
      "0 :容\n",
      "0 :疑\n",
      "0 :者\n",
      "0 :は\n",
      "0 :１\n",
      "0 :０\n",
      "0 :日\n",
      "0 :午\n",
      "0 :前\n",
      "0 :９\n",
      "2 :時\n",
      "-1 :ご\n",
      "-1 :<mask> :脱: ['ろ', 'ご', 'と']\n",
      "0 :<mask> :脱: ['に', 'ろ', 'で']\n",
      "0 :、\n",
      "0 :大\n",
      "0 :阪\n",
      "0 :市\n",
      "0 :中\n",
      "0 :央\n",
      "0 :区\n",
      "0 :宗\n",
      "0 :右\n",
      "0 :衛\n",
      "0 :門\n",
      "0 :町\n",
      "0 :の\n",
      "0 :雑\n",
      "0 :居\n",
      "0 :ビ\n",
      "0 :ル\n",
      "0 :地\n",
      "0 :下\n",
      "0 :１\n",
      "0 :階\n",
      "0 :で\n",
      "0 :、\n",
      "0 :兵\n",
      "0 :頭\n",
      "6 :<del>\n",
      "6 :さ\n",
      "0 :ん\n",
      "0 :を\n",
      "0 :殴\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :り\n",
      "6 :<del>\n",
      "6 :け\n",
      "0 :っ\n",
      "0 :た\n",
      "0 :り\n",
      "6 :<del>\n",
      "6 :し\n",
      "0 :<mask> :誤: ['て', 'た', 'く']\n",
      "0 :、\n",
      "3 :キ\n",
      "0 :ャ\n",
      "0 :ッ\n",
      "0 :シ\n",
      "0 :ュ\n",
      "0 :カ\n",
      "0 :ー\n",
      "0 :ド\n",
      "0 :な\n",
      "0 :ど\n",
      "0 :が\n",
      "0 :入\n",
      "6 :<del>\n",
      "6 :っ\n",
      "0 :た\n",
      "0 :財\n",
      "0 :布\n",
      "0 :を\n",
      "0 :奪\n",
      "0 :っ\n",
      "0 :<mask> :誤: ['た', 'て', 'の']\n",
      "0 :疑\n",
      "0 :い\n",
      "3 :。\n",
      "0 :兵\n",
      "0 :頭\n",
      "0 :さ\n",
      "0 :ん\n",
      "0 :<mask> :脱: ['か', 'ら', 'で']\n",
      "0 :<mask> :脱: ['は', 'も', 'が']\n",
      "2 :同\n",
      "-1 :日\n",
      "-1 :夜\n",
      "0 :、\n",
      "0 :意\n",
      "0 :識\n",
      "0 :不\n",
      "0 :明\n",
      "0 :で\n",
      "0 :倒\n",
      "0 :れ\n",
      "0 :て\n",
      "6 :<del>\n",
      "6 :<mask> :誤: ['い', 'あ', 'く']\n",
      "0 :る\n",
      "0 :の\n",
      "0 :を\n",
      "3 :発\n",
      "0 :見\n",
      "6 :<del>\n",
      "6 :さ\n",
      "0 :れ\n",
      "0 :た\n",
      "0 :が\n",
      "0 :、\n",
      "0 :１\n",
      "0 :２\n",
      "0 :日\n",
      "0 :に\n",
      "0 :死\n",
      "0 :亡\n",
      "0 :し\n",
      "0 :<mask> :誤: ['た', 'て', 'る']\n",
      "0 :。\n",
      "北九州市議会では、女性議員と２人でミニ会派を構成する森浩明市議。\n",
      "北九州市議会では、女性議員と２人でミニ会派を構成する森浩明市議。\n",
      "0 0\n",
      "コスト算出は環境庁のガイドラインやガス大手３社の協議で一定の基準ができているが、収益の算出方法は確たる基準がない。このため大ガスは、省エネ効果や環境問題への取り組みによる広告効果などを金額に換算する算定基準作りを進める。\n",
      "コスト算出は環境庁のガイドラインへガス大手３社の協議を一定の基準がでてるが、収益の算出方法は確たる基準がない。このため大ガスは、省エネ効果環境問題への取り組ｍもよる広告効果などを金額にに換算する算定基準作を進める。\n",
      "1 1\n",
      "コスト算出は環境庁のガイドライン<mask>ガス大手３社の協議を一定の基準がで<mask>るが、収益の算出方法は確たる基準がない。このため大ガスは、省エネ効果環境問題への取り組<mask><mask>よる広告効果などを金額に換算する算定基準作<mask>を進める。\n",
      "9\n",
      "109\n",
      "0 :コ\n",
      "0 :ス\n",
      "0 :ト\n",
      "0 :算\n",
      "0 :出\n",
      "0 :は\n",
      "0 :環\n",
      "0 :境\n",
      "0 :庁\n",
      "0 :の\n",
      "0 :ガ\n",
      "0 :イ\n",
      "0 :ド\n",
      "0 :ラ\n",
      "0 :イ\n",
      "3 :ン\n",
      "0 :<mask> :誤: ['と', 'や', 'の']\n",
      "0 :ガ\n",
      "0 :ス\n",
      "0 :大\n",
      "0 :手\n",
      "0 :３\n",
      "0 :社\n",
      "0 :の\n",
      "0 :協\n",
      "0 :議\n",
      "0 :を\n",
      "0 :一\n",
      "0 :定\n",
      "0 :の\n",
      "0 :基\n",
      "0 :準\n",
      "0 :が\n",
      "3 :で\n",
      "0 :<mask> :誤: ['き', 'あ', 'け']\n",
      "0 :る\n",
      "0 :が\n",
      "0 :、\n",
      "0 :収\n",
      "0 :益\n",
      "0 :の\n",
      "0 :算\n",
      "0 :出\n",
      "0 :方\n",
      "0 :法\n",
      "0 :は\n",
      "0 :確\n",
      "0 :た\n",
      "0 :る\n",
      "0 :基\n",
      "0 :準\n",
      "0 :が\n",
      "0 :な\n",
      "0 :い\n",
      "0 :。\n",
      "0 :こ\n",
      "0 :の\n",
      "0 :た\n",
      "0 :め\n",
      "0 :大\n",
      "0 :ガ\n",
      "0 :ス\n",
      "0 :は\n",
      "0 :、\n",
      "0 :省\n",
      "0 :エ\n",
      "0 :ネ\n",
      "0 :効\n",
      "0 :果\n",
      "0 :環\n",
      "0 :境\n",
      "0 :問\n",
      "0 :題\n",
      "0 :へ\n",
      "0 :の\n",
      "0 :取\n",
      "0 :り\n",
      "3 :組\n",
      "3 :<mask> :誤: ['み', 'む', 'ど']\n",
      "0 :<mask> :誤: ['に', 'と', 'を']\n",
      "0 :よ\n",
      "0 :る\n",
      "0 :広\n",
      "0 :告\n",
      "0 :効\n",
      "0 :果\n",
      "0 :な\n",
      "0 :ど\n",
      "0 :を\n",
      "0 :金\n",
      "0 :額\n",
      "6 :<del>\n",
      "6 :に\n",
      "0 :換\n",
      "0 :算\n",
      "0 :す\n",
      "0 :る\n",
      "0 :算\n",
      "0 :定\n",
      "0 :基\n",
      "0 :準\n",
      "1 :作\n",
      "-1 :<mask> :脱: ['り', 'ど', 'し']\n",
      "0 :を\n",
      "0 :進\n",
      "0 :め\n",
      "0 :る\n",
      "0 :。\n",
      "私は大学で教員免許関連の授業を受けていることもあり、本紙朝刊の連載記事「先生新教育の森」を興味深く読んでいる。\n",
      "私は大学で教員免許関連の授業を受てることもあゅ、本紙朝刊の連載記事「先生新教育の森」を興味深く読んでいる。\n",
      "1 1\n",
      "私は大学で教員免許関連の授業を受<mask>てることもあ<mask>、本紙朝刊の連載記事「先生新教育の森」を興味深く読んでいる。\n",
      "9\n",
      "56\n",
      "0 :私\n",
      "0 :は\n",
      "0 :大\n",
      "0 :学\n",
      "0 :で\n",
      "0 :教\n",
      "0 :員\n",
      "0 :免\n",
      "0 :許\n",
      "0 :関\n",
      "0 :連\n",
      "0 :の\n",
      "0 :授\n",
      "0 :業\n",
      "1 :を\n",
      "-1 :受\n",
      "0 :<mask> :脱: ['け', 'っ', 'い']\n",
      "0 :て\n",
      "0 :る\n",
      "0 :こ\n",
      "0 :と\n",
      "0 :も\n",
      "3 :あ\n",
      "0 :<mask> :誤: ['り', 'る', 'れ']\n",
      "0 :、\n",
      "0 :本\n",
      "0 :紙\n",
      "0 :朝\n",
      "0 :刊\n",
      "0 :の\n",
      "0 :連\n",
      "0 :載\n",
      "0 :記\n",
      "0 :事\n",
      "0 :「\n",
      "0 :先\n",
      "0 :生\n",
      "0 :新\n",
      "0 :教\n",
      "0 :育\n",
      "0 :の\n",
      "0 :森\n",
      "0 :」\n",
      "0 :を\n",
      "0 :興\n",
      "0 :味\n",
      "0 :深\n",
      "0 :く\n",
      "0 :読\n",
      "0 :ん\n",
      "0 :で\n",
      "0 :い\n",
      "0 :る\n",
      "0 :。\n",
      "もともとライカのレンズは、優れた描写力が売り物。加えてベトナム戦争中、報道カメラマンの故沢田教一氏が従軍取材に使用するなど、ボディーの丈夫さも世界屈指だ。そのかわり、自動露出・焦点の最新カメラと比べると、一部の機種はかなり使いにくく、フィルムの装てんさえ簡単にできないものも少なくない。\n",
      "もととライカのレンズは、優れた描写力が売ぞ物。加えてベトナム戦争中、報道カメラマンの故沢田教一氏ど従軍取材に使用するなど、ボディーの丈夫も世界屈指ｄ。そのかり、自動露出・焦点の最新カメラとと比べるると、一部を機種はかり使いいにくく、フィルムｎ装てさえ簡\n",
      "1 1\n",
      "もとライカのレンズは、優れた描写力が売<mask>物。加えてベトナム戦争中、報道カメラマンの故沢田教一氏<mask>従軍取材に使用するなど、ボディーの丈夫も世界屈指<mask>。そのかり、自動露出・焦点の最新カメラと比べると、一部を機種はかり使いにく、フィルム<mask>装てさえ簡\n",
      "9\n",
      "123\n",
      "0 :も\n",
      "6 :<del>\n",
      "6 :と\n",
      "0 :ラ\n",
      "0 :イ\n",
      "0 :カ\n",
      "0 :の\n",
      "0 :レ\n",
      "0 :ン\n",
      "0 :ズ\n",
      "0 :は\n",
      "0 :、\n",
      "0 :優\n",
      "0 :れ\n",
      "0 :た\n",
      "0 :描\n",
      "0 :写\n",
      "0 :力\n",
      "0 :が\n",
      "0 :売\n",
      "3 :<mask> :誤: ['り', 'れ', 'っ']\n",
      "0 :物\n",
      "0 :。\n",
      "0 :加\n",
      "0 :え\n",
      "0 :て\n",
      "0 :ベ\n",
      "0 :ト\n",
      "0 :ナ\n",
      "0 :ム\n",
      "0 :戦\n",
      "0 :争\n",
      "0 :中\n",
      "0 :、\n",
      "0 :報\n",
      "0 :道\n",
      "0 :カ\n",
      "0 :メ\n",
      "0 :ラ\n",
      "0 :マ\n",
      "0 :ン\n",
      "0 :の\n",
      "0 :故\n",
      "0 :沢\n",
      "0 :田\n",
      "0 :教\n",
      "0 :一\n",
      "0 :氏\n",
      "3 :<mask> :誤: ['が', 'の', 'を']\n",
      "0 :従\n",
      "0 :軍\n",
      "0 :取\n",
      "0 :材\n",
      "0 :に\n",
      "0 :使\n",
      "0 :用\n",
      "0 :す\n",
      "0 :る\n",
      "0 :な\n",
      "0 :ど\n",
      "0 :、\n",
      "0 :ボ\n",
      "0 :デ\n",
      "0 :ィ\n",
      "0 :ー\n",
      "0 :の\n",
      "0 :丈\n",
      "0 :夫\n",
      "0 :も\n",
      "0 :世\n",
      "0 :界\n",
      "0 :屈\n",
      "0 :指\n",
      "3 :<mask> :誤: ['だ', 'に', 'か']\n",
      "0 :。\n",
      "0 :そ\n",
      "0 :の\n",
      "0 :か\n",
      "0 :り\n",
      "0 :、\n",
      "0 :自\n",
      "0 :動\n",
      "0 :露\n",
      "0 :出\n",
      "0 :・\n",
      "0 :焦\n",
      "0 :点\n",
      "0 :の\n",
      "0 :最\n",
      "0 :新\n",
      "0 :カ\n",
      "0 :メ\n",
      "0 :ラ\n",
      "0 :と\n",
      "6 :<del>\n",
      "6 :比\n",
      "0 :べ\n",
      "0 :る\n",
      "0 :と\n",
      "6 :<del>\n",
      "6 :、\n",
      "0 :一\n",
      "0 :部\n",
      "0 :を\n",
      "0 :機\n",
      "0 :種\n",
      "0 :は\n",
      "0 :か\n",
      "0 :り\n",
      "0 :使\n",
      "0 :い\n",
      "0 :に\n",
      "0 :く\n",
      "6 :<del>\n",
      "6 :、\n",
      "0 :フ\n",
      "0 :ィ\n",
      "6 :<del>\n",
      "6 :ル\n",
      "0 :ム\n",
      "0 :<mask> :誤: ['と', 'を', 'な']\n",
      "0 :装\n",
      "0 :て\n",
      "0 :さ\n",
      "3 :え\n",
      "0 :簡\n",
      "首位の中日、ダイエーが優勝マジックを二つ減らした。\n",
      "首位に中日、ダイエーが優勝マジックをを二つ減ららた。\n",
      "1 1\n",
      "首位に中日、ダイエーが優勝マジックを二つ減ら<mask>た。\n",
      "9\n",
      "27\n",
      "0 :首\n",
      "0 :位\n",
      "0 :に\n",
      "0 :中\n",
      "0 :日\n",
      "0 :、\n",
      "0 :ダ\n",
      "0 :イ\n",
      "0 :エ\n",
      "0 :ー\n",
      "0 :が\n",
      "0 :優\n",
      "0 :勝\n",
      "0 :マ\n",
      "0 :ジ\n",
      "0 :ッ\n",
      "0 :ク\n",
      "6 :<del>\n",
      "6 :を\n",
      "0 :二\n",
      "0 :つ\n",
      "0 :減\n",
      "0 :ら\n",
      "7 :<del>\n",
      "7 :<mask> :脱: ['し', 'せ', 'げ']\n",
      "-1 :た\n",
      "0 :。\n",
      "東京都葛飾区・柴又帝釈天といえば、故渥美清さんが演じた「フーテンの寅さん」のお膝元。帝釈天の東側、「寅さん記念館」の裏手の江戸川河畔に、本流から直角に小枝を突き出したような「新八水路」がある。歌謡曲で有名になった「矢切の渡し」からわずか２００メートルほど下ったところである。\n",
      "東京都葛飾区・柴又帝釈天といえば、故渥美清さんが演じた「フーテンの寅さん」のお膝元。帝釈天の東側、「寅さん記念館」の裏手の江戸川河畔に、本流から直角に小枝を突き出したような「新八水路」がある。歌謡曲で有名になった「矢切の渡し」からわずか２００メートルほ\n",
      "0 0\n",
      "米政府の指導力の低下を指摘する声もあり、同代表の責任問題が浮上する可能性も出てきた。\n",
      "米政府の指導力の低下を指摘する声もあり、同代表の責任問題が浮上する可能性も出てきた。\n",
      "0 1\n",
      "米政府の指導力の低下を指摘する声もあり、同代表の責任問題が浮上する可能性も出てきた。\n",
      "9\n",
      "44\n",
      "0 :米\n",
      "0 :政\n",
      "0 :府\n",
      "0 :の\n",
      "0 :指\n",
      "0 :導\n",
      "0 :力\n",
      "0 :の\n",
      "0 :低\n",
      "0 :下\n",
      "0 :を\n",
      "0 :指\n",
      "0 :摘\n",
      "0 :す\n",
      "0 :る\n",
      "0 :声\n",
      "0 :も\n",
      "0 :あ\n",
      "0 :り\n",
      "0 :、\n",
      "0 :同\n",
      "0 :代\n",
      "0 :表\n",
      "0 :の\n",
      "0 :責\n",
      "0 :任\n",
      "0 :問\n",
      "0 :題\n",
      "0 :が\n",
      "0 :浮\n",
      "0 :上\n",
      "0 :す\n",
      "0 :る\n",
      "0 :可\n",
      "0 :能\n",
      "0 :性\n",
      "0 :も\n",
      "0 :出\n",
      "0 :て\n",
      "0 :き\n",
      "0 :た\n",
      "0 :。\n",
      "横綱の威厳は薄くなってはいても、まだ厳然とある。\n",
      "横綱ｎ威厳は薄くなっはいてても、まだ厳然とある。\n",
      "1 1\n",
      "横綱<mask>威厳は薄くなっはいても、まだ厳然とある。\n",
      "9\n",
      "25\n",
      "0 :横\n",
      "3 :綱\n",
      "0 :<mask> :誤: ['の', 'が', 'も']\n",
      "0 :威\n",
      "0 :厳\n",
      "0 :は\n",
      "0 :薄\n",
      "0 :く\n",
      "0 :な\n",
      "0 :っ\n",
      "0 :は\n",
      "0 :い\n",
      "6 :<del>\n",
      "6 :て\n",
      "0 :も\n",
      "0 :、\n",
      "0 :ま\n",
      "0 :だ\n",
      "0 :厳\n",
      "0 :然\n",
      "0 :と\n",
      "0 :あ\n",
      "0 :る\n",
      "0 :。\n",
      "安岡は、今年は走者を背負っても大崩れせず、防御率２・２５と安定感を増し、１人で３勝を挙げた。\n",
      "安岡は、今年は走者を背負っても大崩ｒせひ、防御率２・２５と安定感ｗ増し、１人でで３勝を挙げ。\n",
      "1 1\n",
      "安岡、今年は走者を背負っても大崩<mask>せ<mask>、防御率２・２５と安定感<mask>増し、１人で３勝を挙げ<mask><mask>。\n",
      "9\n",
      "48\n",
      "0 :安\n",
      "6 :<del>\n",
      "6 :岡\n",
      "0 :、\n",
      "0 :今\n",
      "0 :年\n",
      "0 :は\n",
      "0 :走\n",
      "0 :者\n",
      "0 :を\n",
      "0 :背\n",
      "0 :負\n",
      "0 :っ\n",
      "0 :て\n",
      "0 :も\n",
      "0 :大\n",
      "0 :崩\n",
      "3 :<mask> :誤: ['れ', 'し', 'さ']\n",
      "0 :せ\n",
      "3 :<mask> :誤: ['ず', 'ば', 'て']\n",
      "0 :、\n",
      "0 :防\n",
      "0 :御\n",
      "0 :率\n",
      "0 :２"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_all():\n",
    "    esd_trainer.model.eval()\n",
    "    epd_trainer.model.eval()\n",
    "    mlm_trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_line = []\n",
    "            text = batch['bert_input'][0]\n",
    "            original = batch['original'][0]\n",
    "            esd_output = esd_trainer.model(batch['bert_input'])\n",
    "            org_text = [vocab.itos[i] for i in original if i!=0]\n",
    "            print(\"\".join(org_text))\n",
    "            processed_text = [vocab.itos[i] for i in text if i!=0]\n",
    "            processed_text = processed_text[1:-1]\n",
    "            print(\"\".join(processed_text))\n",
    "            print(batch['label'].item(), esd_output.argmax(dim=-1).item())\n",
    "            \n",
    "            processed_index = [vocab.sos_index] +[vocab.stoi[i] for i in processed_text] + [vocab.eos_index]\n",
    "            processed_batch = torch.tensor(processed_index)\n",
    "            processed_batch = processed_batch.unsqueeze(0)\n",
    "            esd_output = esd_trainer.model(processed_batch)\n",
    "            #NG文だけ次のステップへ\n",
    "            if esd_output.argmax(dim=-1).item()==1:\n",
    "                epd_output = epd_trainer.model(processed_batch)[0]\n",
    "                predict_list = []\n",
    "                masked_list = []\n",
    "                masked_label = []\n",
    "                text = processed_batch[0]\n",
    "                for j in range(len(processed_batch[0])):\n",
    "                    predict = epd_output[j].argmax(dim=-1).item()\n",
    "                    if predict == 0:\n",
    "                        # 正しい場合\n",
    "                        masked_list.append(text[j])\n",
    "                        masked_label.append(-1)\n",
    "                        predict_list.append(0)\n",
    "                    elif predict == 1:\n",
    "                        # 脱字(1文字)\n",
    "                        masked_list.extend([text[j], vocab.mask_index])\n",
    "                        masked_label.extend([-1,-2])\n",
    "                        predict_list.extend([1,-1])\n",
    "                    elif predict == 2:\n",
    "                        # 脱字(2文字)\n",
    "                        masked_list.extend([text[j],vocab.mask_index, vocab.mask_index])\n",
    "                        masked_label.extend([-1,-2,-2])\n",
    "                        predict_list.extend([2,-1,-1])\n",
    "                    elif predict == 3:\n",
    "                        # 誤字\n",
    "                        masked_list.append(vocab.mask_index)\n",
    "                        masked_label.append(text[j])\n",
    "                        predict_list.append(3)\n",
    "                    elif predict == 4:\n",
    "                        # 誤字かつ脱字(1文字)\n",
    "                        masked_list.extend([vocab.mask_index, vocab.mask_index])\n",
    "                        masked_label.extend([text[j],-2])\n",
    "                        predict_list.extend([4,-1])\n",
    "                    elif predict == 5:\n",
    "                        # 誤字かつ脱字(2文字)\n",
    "                        masked_list.extend([vocab.mask_index, vocab.mask_index, vocab.mask_index])\n",
    "                        masked_label.extend([text[j],-2,-2])\n",
    "                        predict_list.extend([5,-1,-1])\n",
    "                    elif predict == 6:\n",
    "                        # 衍字\n",
    "                        predict_list.append(6)\n",
    "                    elif predict == 7:\n",
    "                        # 衍字かつ脱字(1文字)\n",
    "                        masked_list.append(vocab.mask_index)\n",
    "                        masked_label.append(-2)\n",
    "                        predict_list.extend([7,-1])\n",
    "                    elif predict == 8:\n",
    "                        # 衍字かつ脱字(2文字)\n",
    "                        masked_list.extend([vocab.mask_index, vocab.mask_index])\n",
    "                        masked_label.extend(-2,-2)\n",
    "                        predict_list.extend([8,-1,-1])\n",
    "                no_pad_text = [vocab.itos[i] for i in masked_list if i!=0]\n",
    "                no_pad_text = no_pad_text[1:-1]\n",
    "                print(\"\".join(no_pad_text))\n",
    "                masked_list = masked_list[:128]\n",
    "                masked_label = masked_label[:128]\n",
    "                predict_list = predict_list[1:129]\n",
    "                masked_text = [vocab.itos[i] for i in masked_list]\n",
    "                masked_batch = torch.tensor(masked_list)\n",
    "                masked_batch = masked_batch.unsqueeze(0)\n",
    "                mlm_output = mlm_trainer.model(masked_batch)\n",
    "                print(len(epd_output[0]))\n",
    "                print(len(masked_text))\n",
    "                enji_flag = False\n",
    "                for j in range(len(masked_text)):\n",
    "                    _, topi = mlm_output[0, j].topk(3)\n",
    "                    predict = [vocab.itos[index.item()] for index in topi]\n",
    "                    if masked_list[j] in [0,2,3]:\n",
    "                        continue\n",
    "\n",
    "                    if predict_list[j] in [6,7,8]:\n",
    "                        print(predict_list[j],\":<del>\")\n",
    "\n",
    "                    print(predict_list[j],\":\",end=\"\")\n",
    "                    if masked_label[j] == -1:\n",
    "                        print(masked_text[j])\n",
    "                    elif masked_label[j] == -2:\n",
    "                        print(masked_text[j],':脱:',predict)\n",
    "                    else:\n",
    "                        print(masked_text[j],':誤:',predict)\n",
    "\n",
    "test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "大分空港ケ岳の山中に墜落ているのが発見さた。\n",
      "大分空港ケ岳の山中に墜落<mask><mask>ているのが発見さ<mask><mask>た。\n",
      "9\n",
      "28\n",
      "0 :大\n",
      "0 :分\n",
      "0 :空\n",
      "0 :港\n",
      "0 :ケ\n",
      "0 :岳\n",
      "0 :の\n",
      "0 :山\n",
      "0 :中\n",
      "0 :に\n",
      "2 :墜\n",
      "-1 :落\n",
      "-1 :<mask> :脱: ['さ', 'を', 'と']\n",
      "0 :<mask> :脱: ['せ', 'し', 'み']\n",
      "0 :て\n",
      "0 :い\n",
      "0 :る\n",
      "0 :の\n",
      "0 :が\n",
      "0 :発\n",
      "2 :見\n",
      "-1 :さ\n",
      "-1 :<mask> :脱: ['れ', 'え', 'ま']\n",
      "0 :<mask> :脱: ['っ', 'れ', 'た']\n",
      "0 :た\n",
      "0 :。\n"
     ]
    }
   ],
   "source": [
    "def test_input(original_text ,processed_text):\n",
    "    esd_trainer.model.eval()\n",
    "    epd_trainer.model.eval()\n",
    "    mlm_trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_line = []\n",
    "        original = original_text\n",
    "        processed_index = [vocab.sos_index] +[vocab.stoi[i] for i in processed_text] + [vocab.eos_index]\n",
    "        processed_batch = torch.tensor(processed_index)\n",
    "        processed_batch = processed_batch.unsqueeze(0)\n",
    "        esd_output = esd_trainer.model(processed_batch)\n",
    "        print(original_text)\n",
    "        print(processed_text)\n",
    "        #NG文だけ次のステップへ\n",
    "        #if esd_output.argmax(dim=-1).item()==1:\n",
    "        epd_output = epd_trainer.model(processed_batch)[0]\n",
    "        predict_list = []\n",
    "        masked_list = []\n",
    "        masked_label = []\n",
    "        text = processed_batch[0]\n",
    "        for j in range(len(processed_batch[0])):\n",
    "            predict = epd_output[j].argmax(dim=-1).item()\n",
    "            if predict == 0:\n",
    "                # 正しい場合\n",
    "                masked_list.append(text[j])\n",
    "                masked_label.append(-1)\n",
    "                predict_list.append(0)\n",
    "            elif predict == 1:\n",
    "                # 脱字(1文字)\n",
    "                masked_list.extend([text[j], vocab.mask_index])\n",
    "                masked_label.extend([-1,-2])\n",
    "                predict_list.extend([1,-1])\n",
    "            elif predict == 2:\n",
    "                # 脱字(2文字)\n",
    "                masked_list.extend([text[j],vocab.mask_index, vocab.mask_index])\n",
    "                masked_label.extend([-1,-2,-2])\n",
    "                predict_list.extend([2,-1,-1])\n",
    "            elif predict == 3:\n",
    "                # 誤字\n",
    "                masked_list.append(vocab.mask_index)\n",
    "                masked_label.append(text[j])\n",
    "                predict_list.append(3)\n",
    "            elif predict == 4:\n",
    "                # 誤字かつ脱字(1文字)\n",
    "                masked_list.extend([vocab.mask_index, vocab.mask_index])\n",
    "                masked_label.extend([text[j],-2])\n",
    "                predict_list.extend([4,-1])\n",
    "            elif predict == 5:\n",
    "                # 誤字かつ脱字(2文字)\n",
    "                masked_list.extend([vocab.mask_index, vocab.mask_index, vocab.mask_index])\n",
    "                masked_label.extend([text[j],-2,-2])\n",
    "                predict_list.extend([5,-1,-1])\n",
    "            elif predict == 6:\n",
    "                # 衍字\n",
    "                predict_list.append(6)\n",
    "            elif predict == 7:\n",
    "                # 衍字かつ脱字(1文字)\n",
    "                masked_list.append(vocab.mask_index)\n",
    "                masked_label.append(-2)\n",
    "                predict_list.extend([7,-1])\n",
    "            elif predict == 8:\n",
    "                # 衍字かつ脱字(2文字)\n",
    "                masked_list.extend([vocab.mask_index, vocab.mask_index])\n",
    "                masked_label.extend(-2,-2)\n",
    "                predict_list.extend([8,-1,-1])\n",
    "        \n",
    "        no_pad_text = [vocab.itos[i] for i in masked_list if i!=0]\n",
    "        no_pad_text = no_pad_text[1:-1]\n",
    "        print(\"\".join(no_pad_text))\n",
    "        masked_list = masked_list[:128]\n",
    "        masked_label = masked_label[:128]\n",
    "        predict_list = predict_list[1:129]\n",
    "        masked_text = [vocab.itos[i] for i in masked_list]\n",
    "        masked_batch = torch.tensor(masked_list)\n",
    "        masked_batch = masked_batch.unsqueeze(0)\n",
    "        mlm_output = mlm_trainer.model(masked_batch)\n",
    "        print(len(epd_output[0]))\n",
    "        print(len(masked_text))\n",
    "        enji_flag = False\n",
    "        for j in range(len(masked_text)):\n",
    "            _, topi = mlm_output[0, j].topk(3)\n",
    "            predict = [vocab.itos[index.item()] for index in topi]\n",
    "            if masked_list[j] in [0,2,3]:\n",
    "                continue\n",
    "\n",
    "            if predict_list[j] in [6,7,8]:\n",
    "                print(predict_list[j],\":<del>\")\n",
    "                \n",
    "            print(predict_list[j],\":\",end=\"\")\n",
    "            if masked_label[j] == -1:\n",
    "                print(masked_text[j])\n",
    "            elif masked_label[j] == -2:\n",
    "                print(masked_text[j],':脱:',predict)\n",
    "            else:\n",
    "                print(masked_text[j],':誤:',predict)\n",
    "\n",
    "test_input(\"\",\"大分空港ケ岳の山中に墜落ているのが発見さた。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_esd():\n",
    "    esd_trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        true_positive = 0\n",
    "        true_negative = 0\n",
    "        false_positive = 0\n",
    "        false_negative = 0\n",
    "        for i, batch in enumerate(tqdm.tqdm(test_loader)):\n",
    "            if i==10000:\n",
    "                break\n",
    "            input_line = []\n",
    "            esd_output = esd_trainer.model(batch['bert_input'])\n",
    "            if batch['label'][0] == 1:\n",
    "                if esd_output.argmax(dim=-1).item() == 1:\n",
    "                    #NG文をNGと判定したとき\n",
    "                    true_positive += 1\n",
    "                    n_correct += 1\n",
    "                else:\n",
    "                    #NG文をOKと判定したとき\n",
    "                    false_negative += 1\n",
    "            else:\n",
    "                if esd_output.argmax(dim=-1).item() == 1:\n",
    "                    #OK文をNGと判定したとき\n",
    "                    false_positive += 1\n",
    "                else:\n",
    "                    #OK文をOKと判定したとき\n",
    "                    n_correct += 1\n",
    "                    true_negative += 1\n",
    "            print(\"検出率：\"+ str(n_correct/(i+1)))\n",
    "\n",
    "    with open(\"./esd.txt\",\"w\", encoding='utf-8') as f:\n",
    "        f.write(\"検出率：\"+ str(n_correct/i)+\"\\n\")\n",
    "        f.write(\"再現率：\"+ str(true_positive/(true_positive+false_negative))+\"\\n\")\n",
    "        f.write(\"適合率：\"+ str(true_positive/(true_positive+false_positive))+\"\\n\")\n",
    "        f.write(\"特異度：\"+ str(true_negative/(false_positive+true_negative))+\"\\n\")\n",
    "        f.write(\"F値：\"+ str(2*true_positive/(2*true_positive+false_negative+false_positive))+\"\\n\")\n",
    "\n",
    "test_esd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_epd():\n",
    "    epd_trainer.model.eval()\n",
    "    with torch.no_grad():\n",
    "        all_num = 0\n",
    "        n_correct = 0\n",
    "        p_correct = 0\n",
    "        true_positive = 0\n",
    "        true_negative = 0\n",
    "        false_positive = 0\n",
    "        false_negative = 0\n",
    "        for i, batch in enumerate(tqdm.tqdm(test_loader)):\n",
    "            if i==10000:\n",
    "                break\n",
    "            output = epd_trainer.model(batch['bert_input'])\n",
    "            for j in range(128):\n",
    "                all_num += 1\n",
    "                true =  batch[\"token_label\"][0,j].item()\n",
    "                predict = output[0,j].argmax(dim=-1).item()\n",
    "                if true != 0:\n",
    "                    if predict != 0:\n",
    "                        true_positive += 1\n",
    "                        n_correct += 1\n",
    "                        if predict == true:\n",
    "                            p_correct += 1\n",
    "                    else:\n",
    "                        false_negative += 1\n",
    "                else:\n",
    "                    if predict != 0:\n",
    "                        false_positive += 1\n",
    "                    else:\n",
    "                        true_negative += 1\n",
    "                        n_correct += 1\n",
    "            print(\"検出率：\", n_correct/all_num)\n",
    "            #print(\"完全検出率：\", p_correct/all_num)\n",
    "        print(\"再現率：\", true_positive/(true_positive+false_negative))\n",
    "        print(\"適合率：\", true_positive/(true_positive+false_positive))\n",
    "        print(\"特異度：\", true_negative/(false_positive+true_negative))\n",
    "        print(\"F値：\", 2*true_positive/(2*true_positive+false_negative+false_positive))\n",
    "    \n",
    "    with open(\"./epd.txt\",\"w\", encoding='utf-8') as f:\n",
    "        f.write(\"検出率：\"+ str(n_correct/all_num)+\"\\n\")\n",
    "        f.write(\"再現率：\"+ str(true_positive/(true_positive+false_negative))+\"\\n\")\n",
    "        f.write(\"適合率：\"+ str(true_positive/(true_positive+false_positive))+\"\\n\")\n",
    "        f.write(\"特異度：\"+ str(true_negative/(false_positive+true_negative))+\"\\n\")\n",
    "        f.write(\"F値：\"+ str(2*true_positive/(2*true_positive+false_negative+false_positive))+\"\\n\")\n",
    "test_epd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "待 ['あ', 'か', 'ん']\n",
      "て ['<pad>', 'ふ', 'ゆ']\n",
      "ど ['ぬ', 'に', 'は']\n",
      "も ['<pad>', 'に', 'く']\n",
      "結 ['<pad>', 'ぱ', 'は']\n",
      "果 ['ぽ', 'ぞ', 'ぐ']\n",
      "が ['ぞ', 'ぽ', 'ぐ']\n",
      "出 ['<pad>', 'は', 'ぱ']\n",
      "ｒ ['<pad>', 'に', 'く']\n",
      "こ ['ぬ', 'に', 'は']\n",
      "と ['<pad>', 'ふ', 'ゆ']\n",
      "は ['あ', 'か', 'ん']\n",
      "な ['ぞ', 'ぽ', 'ぐ']\n",
      "か ['あ', '<pad>', 'ぞ']\n",
      "っ ['<pad>', 'で', 'が']\n",
      "た ['ぬ', 'に', 'は']\n",
      "。 ['<pad>', 'ふ', 'お']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def test_mlm_proofread(original_text ,processed_text):\n",
    "    mlm_trainer.model.eval()\n",
    "    processed_list = [vocab.stoi[i] for i in processed_text]\n",
    "    error_list = []\n",
    "    for i in range(len(processed_list)):\n",
    "        masked_list = copy.copy(processed_list)\n",
    "        masked_list[i] = vocab.mask_index \n",
    "        masked_batch = torch.tensor(masked_list)\n",
    "        masked_batch = masked_batch.unsqueeze(0)\n",
    "        mlm_output = mlm_trainer.model(masked_batch)\n",
    "\n",
    "        _, topi = mlm_output[0, i].topk(3)\n",
    "        topi = [vocab.itos[j.item()] for j in topi]\n",
    "        print(processed_text[i],topi)\n",
    "        #if processed_list[i] in topi:\n",
    "        #    error_list.append(1)\n",
    "        # else:\n",
    "        #    error_list.append(0)\n",
    "    print(error_list)\n",
    "test_mlm_proofread(\"\",\"待てども結果が出ｒことはなかった。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def showPlot(points, figure_path):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.savefig(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showPlot(trainer.train_losses, \"./results/\"+str(epochs)+\"_train.png\")\n",
    "showPlot(trainer.valid_losses, \"./results/\"+str(epochs)+\"_valid.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
