{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#SOS_token = 0\n",
    "EOS_token = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.token2index = {\"#\":0}\n",
    "        self.token2count = {}\n",
    "        self.index2token = {0:\"#\"}\n",
    "        self.n_tokens = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for token in list(sentence):\n",
    "            self.addtoken(token)\n",
    "\n",
    "    def addtoken(self, token):\n",
    "        if token not in self.token2index:\n",
    "            self.token2index[token] = self.n_tokens\n",
    "            self.token2count[token] = 1\n",
    "            self.index2token[self.n_tokens] = token\n",
    "            self.n_tokens += 1\n",
    "        else:\n",
    "            self.token2count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(list(p[1])) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "    \n",
    "def prepareData(input_data_path, num_samples=10000):\n",
    "    with  open(input_data_path, 'r', encoding='utf-8') as f:\n",
    "        input_lines = f.read().split('\\n')  # 行ごとのリストに\n",
    "    print(\"Counting tokens:\")\n",
    "    data = Data()\n",
    "    target_lines = []\n",
    "    for line in input_lines:\n",
    "        input_tokens = list(line)\n",
    "        target_tokens = input_tokens[1:]\n",
    "        target_tokens.append(\"#\")\n",
    "        target_lines.append(\"\".join(target_tokens))\n",
    "        data.addSentence(line)\n",
    "    min_samples = min(num_samples, min(len(input_lines)-1, len(target_lines)-1))\n",
    "    pairs = [[i,t]for (i,t) in zip(input_lines[:min_samples],target_lines[:min_samples])]\n",
    "    pairs.append(input_lines)\n",
    "    pairs.append(target_lines)\n",
    "    pairs = filterPairs(pairs)\n",
    "\n",
    "    print(\"Counted tokens:\")\n",
    "    print('data:{}'.format(data.n_tokens))\n",
    "    return data, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting tokens:\n",
      "Counted tokens:\n",
      "data:4164\n",
      "train:157364\n",
      "val:39341\n",
      "['開けてみたらスカーフだった。', 'けてみたらスカーフだった。#']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_data_path = \"./data/text/mai2000a_token.txt\"\n",
    "#input_data_path = \"./data/text/mai2000a_normal.txt\"\n",
    "data, pairs = prepareData(input_data_path, 30000000)\n",
    "train_pairs, val_pairs = train_test_split(pairs, train_size=0.8)\n",
    "print(\"train:\"+ str(len(train_pairs)))\n",
    "print(\"val:\"+ str(len(val_pairs)))\n",
    "print(random.choice(train_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPredictor(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim):\n",
    "        super(LSTMPredictor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeds = nn.Embedding(input_dim, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim)\n",
    "        self.linear = nn.Linear(hidden_dim, input_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.hidden = self.initHidden()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeds(input)\n",
    "        lstm_out, hidden = self.lstm(\n",
    "            embeds.view(len(input), 1, -1), hidden)\n",
    "        output = self.linear(lstm_out.view(len(input), -1))\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        #self.hidden = hidden\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda(),\n",
    "                autograd.Variable(torch.zeros(1, 1, self.hidden_dim)).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(data, sentence):\n",
    "    return [data.token2index[token] for token in list(sentence)]\n",
    "\n",
    "def tensorFromSentence(data, sentence):\n",
    "    indexes = indexesFromSentence(data, sentence)\n",
    "    #indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(data, pair[0])\n",
    "    target_tensor = tensorFromSentence(data, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "def train(input_tensor, target_tensor, model, optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    model.train()\n",
    "    hidden = model.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    loss = 0\n",
    "\n",
    "    for i in range(input_length):\n",
    "        output, hidden = model(input_tensor[i], hidden)\n",
    "        loss += criterion(output, target_tensor[i])\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(input_tensor, target_tensor, model, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = model.initHidden()\n",
    "        input_length = input_tensor.size(0)\n",
    "        target_length = target_tensor.size(0)\n",
    "        loss = 0\n",
    "        for i in range(input_length):\n",
    "            output, hidden = model(input_tensor[i], hidden)\n",
    "            loss += criterion(output, target_tensor[i]) \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainEpochs(model, epochs=1, print_every=10000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_train_losses = []\n",
    "    plot_val_losses = []\n",
    "    print_train_loss_total = 0  # Reset every print_every\n",
    "    print_val_loss_total = 0  # Reset every print_every\n",
    "    plot_train_loss_total = 0  # Reset every plot_every\n",
    "    plot_val_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    train_length = len(train_pairs)\n",
    "    val_length = len(val_pairs)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs)) for i in range(train_length)]\n",
    "    validation_pairs = [tensorsFromPair(random.choice(val_pairs)) for i in range(val_length)]\n",
    "    for epoch in range(epochs):\n",
    "        #Train\n",
    "        for j, train_pair in enumerate(training_pairs):\n",
    "            i = j+1\n",
    "            input_tensor = train_pair[0]\n",
    "            target_tensor = train_pair[1]\n",
    "            loss = train(input_tensor, target_tensor, model, optimizer, criterion)\n",
    "            print_train_loss_total += loss\n",
    "            plot_train_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_train_loss_total / print_every\n",
    "                print_train_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, i / train_length),\n",
    "                                             i, i / train_length * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_train_loss_total / plot_every\n",
    "                plot_train_losses.append(plot_loss_avg)\n",
    "                plot_train_loss_total = 0\n",
    "        \n",
    "        #Validation        \n",
    "        for j, val_pair in enumerate(validation_pairs):\n",
    "            i = j+1\n",
    "            input_tensor = train_pair[0]\n",
    "            target_tensor = train_pair[1]\n",
    "            loss = train(input_tensor, target_tensor, model, optimizer, criterion)\n",
    "            print_val_loss_total += loss\n",
    "            plot_val_loss_total += loss\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                print_loss_avg = print_val_loss_total / print_every\n",
    "                print_val_loss_total = 0\n",
    "                print('%s (%d %d%%) %.4f' % (timeSince(start, i / val_length),\n",
    "                                             i, i / val_length * 100, print_loss_avg))\n",
    "\n",
    "            if i % plot_every == 0:\n",
    "                plot_loss_avg = plot_val_loss_total / plot_every\n",
    "                plot_val_losses.append(plot_loss_avg)\n",
    "                plot_val_loss_total = 0\n",
    "            \n",
    "\n",
    "    showPlot(plot_train_losses, \"./results/\"+str(epochs)+\"_train.png\")\n",
    "    showPlot(plot_val_losses, \"./results/\"+str(epochs)+\"val.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(train_pairs)) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()        \n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "        loss = train(input_tensor, target_tensor, model, optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses,\"./results/tken.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('Agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def showPlot(points, figure_path):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.savefig(figure_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, sentence, max_length=MAX_LENGTH):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(data, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        hidden = model.initHidden()\n",
    "        outputs = []\n",
    "        for i in range(input_length):\n",
    "            output, hidden = model(input_tensor[i], hidden)\n",
    "            outputs.append(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(model, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        outputs = evaluate(model, pair[0])\n",
    "        input_tokens = list(pair[0])\n",
    "        for j, output in enumerate(outputs):\n",
    "            if len(input_tokens) <= j: \n",
    "                break\n",
    "            topv_list, topi_list = output[0].topk(5)\n",
    "            print(input_tokens[j] + \":\")\n",
    "            output_tokens = []\n",
    "            for index in topi_list:\n",
    "                output_tokens.append(data.index2token[index.item()])\n",
    "                \n",
    "            print(output_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 55s (- 302m 15s) (1000 0%) 5.9021\n",
      "3m 11s (- 248m 23s) (2000 1%) 5.2466\n",
      "4m 26s (- 228m 31s) (3000 1%) 5.0736\n",
      "5m 42s (- 218m 47s) (4000 2%) 4.9456\n",
      "6m 59s (- 212m 56s) (5000 3%) 4.7669\n",
      "8m 15s (- 208m 14s) (6000 3%) 4.6753\n",
      "9m 29s (- 203m 58s) (7000 4%) 4.6225\n",
      "10m 43s (- 200m 20s) (8000 5%) 4.6305\n",
      "11m 59s (- 197m 37s) (9000 5%) 4.5603\n",
      "13m 14s (- 195m 7s) (10000 6%) 4.4826\n",
      "14m 30s (- 193m 5s) (11000 6%) 4.4625\n",
      "15m 46s (- 191m 2s) (12000 7%) 4.4132\n",
      "16m 59s (- 188m 41s) (13000 8%) 4.3533\n",
      "18m 15s (- 186m 59s) (14000 8%) 4.3829\n",
      "19m 30s (- 185m 13s) (15000 9%) 4.3520\n",
      "20m 45s (- 183m 23s) (16000 10%) 4.3275\n",
      "21m 59s (- 181m 37s) (17000 10%) 4.2995\n",
      "23m 17s (- 180m 17s) (18000 11%) 4.2776\n",
      "24m 34s (- 178m 55s) (19000 12%) 4.2653\n",
      "25m 49s (- 177m 24s) (20000 12%) 4.2286\n",
      "27m 5s (- 175m 56s) (21000 13%) 4.1974\n",
      "28m 20s (- 174m 24s) (22000 13%) 4.1662\n",
      "29m 39s (- 173m 14s) (23000 14%) 4.2110\n",
      "30m 56s (- 171m 54s) (24000 15%) 4.2083\n",
      "32m 11s (- 170m 24s) (25000 15%) 4.1685\n",
      "33m 27s (- 169m 5s) (26000 16%) 4.1555\n",
      "34m 43s (- 167m 40s) (27000 17%) 4.1692\n",
      "35m 59s (- 166m 18s) (28000 17%) 4.1145\n",
      "37m 15s (- 164m 55s) (29000 18%) 4.1495\n",
      "38m 31s (- 163m 33s) (30000 19%) 4.1068\n",
      "39m 46s (- 162m 7s) (31000 19%) 4.0976\n",
      "41m 1s (- 160m 44s) (32000 20%) 4.1021\n",
      "42m 16s (- 159m 18s) (33000 20%) 4.0898\n",
      "43m 30s (- 157m 52s) (34000 21%) 4.0670\n",
      "44m 46s (- 156m 33s) (35000 22%) 4.0530\n",
      "46m 0s (- 155m 6s) (36000 22%) 4.0888\n",
      "47m 16s (- 153m 48s) (37000 23%) 4.0742\n",
      "48m 32s (- 152m 28s) (38000 24%) 4.0700\n",
      "49m 47s (- 151m 7s) (39000 24%) 4.0324\n",
      "51m 3s (- 149m 48s) (40000 25%) 4.0517\n",
      "52m 20s (- 148m 33s) (41000 26%) 4.0596\n",
      "53m 35s (- 147m 12s) (42000 26%) 4.0139\n",
      "54m 51s (- 145m 55s) (43000 27%) 4.0375\n",
      "56m 8s (- 144m 39s) (44000 27%) 3.9957\n",
      "57m 26s (- 143m 24s) (45000 28%) 3.9863\n",
      "58m 42s (- 142m 7s) (46000 29%) 4.0080\n",
      "59m 59s (- 140m 51s) (47000 29%) 3.9922\n",
      "61m 14s (- 139m 32s) (48000 30%) 4.0027\n",
      "62m 32s (- 138m 18s) (49000 31%) 3.9967\n",
      "63m 48s (- 137m 1s) (50000 31%) 3.9724\n",
      "65m 5s (- 135m 44s) (51000 32%) 4.0074\n",
      "66m 20s (- 134m 25s) (52000 33%) 3.9389\n",
      "67m 36s (- 133m 8s) (53000 33%) 3.9710\n",
      "68m 52s (- 131m 49s) (54000 34%) 3.9891\n",
      "70m 6s (- 130m 29s) (55000 34%) 3.9253\n",
      "71m 20s (- 129m 8s) (56000 35%) 3.9523\n",
      "72m 37s (- 127m 52s) (57000 36%) 3.9278\n",
      "73m 51s (- 126m 32s) (58000 36%) 3.9317\n",
      "75m 7s (- 125m 14s) (59000 37%) 3.9380\n",
      "76m 23s (- 123m 58s) (60000 38%) 3.9526\n",
      "77m 39s (- 122m 40s) (61000 38%) 3.9305\n",
      "78m 53s (- 121m 20s) (62000 39%) 3.9502\n",
      "80m 8s (- 120m 2s) (63000 40%) 3.9545\n",
      "81m 24s (- 118m 45s) (64000 40%) 3.9359\n",
      "82m 40s (- 117m 28s) (65000 41%) 3.9581\n",
      "83m 54s (- 116m 9s) (66000 41%) 3.9032\n",
      "85m 10s (- 114m 51s) (67000 42%) 3.8887\n",
      "86m 24s (- 113m 32s) (68000 43%) 3.8752\n",
      "87m 39s (- 112m 14s) (69000 43%) 3.9123\n",
      "88m 55s (- 110m 58s) (70000 44%) 3.8745\n",
      "90m 10s (- 109m 40s) (71000 45%) 3.8700\n",
      "91m 27s (- 108m 25s) (72000 45%) 3.9008\n",
      "92m 43s (- 107m 9s) (73000 46%) 3.8800\n",
      "93m 57s (- 105m 50s) (74000 47%) 3.8415\n",
      "95m 11s (- 104m 32s) (75000 47%) 3.8729\n",
      "96m 27s (- 103m 16s) (76000 48%) 3.8749\n",
      "97m 45s (- 102m 1s) (77000 48%) 3.8637\n",
      "99m 2s (- 100m 46s) (78000 49%) 3.8707\n",
      "100m 15s (- 99m 27s) (79000 50%) 3.8587\n",
      "101m 31s (- 98m 10s) (80000 50%) 3.8607\n",
      "102m 45s (- 96m 52s) (81000 51%) 3.8545\n",
      "104m 1s (- 95m 36s) (82000 52%) 3.8790\n",
      "105m 17s (- 94m 20s) (83000 52%) 3.8714\n",
      "106m 32s (- 93m 3s) (84000 53%) 3.8993\n",
      "107m 48s (- 91m 46s) (85000 54%) 3.8575\n",
      "109m 3s (- 90m 29s) (86000 54%) 3.8207\n",
      "110m 16s (- 89m 11s) (87000 55%) 3.8161\n",
      "111m 31s (- 87m 54s) (88000 55%) 3.8534\n",
      "112m 47s (- 86m 38s) (89000 56%) 3.8662\n",
      "114m 2s (- 85m 21s) (90000 57%) 3.8469\n",
      "115m 17s (- 84m 5s) (91000 57%) 3.8370\n",
      "116m 34s (- 82m 49s) (92000 58%) 3.8348\n",
      "117m 49s (- 81m 32s) (93000 59%) 3.8450\n",
      "119m 4s (- 80m 16s) (94000 59%) 3.8143\n",
      "120m 21s (- 79m 0s) (95000 60%) 3.8207\n",
      "121m 36s (- 77m 43s) (96000 61%) 3.8583\n",
      "122m 50s (- 76m 26s) (97000 61%) 3.8672\n",
      "124m 5s (- 75m 10s) (98000 62%) 3.7943\n",
      "125m 22s (- 73m 54s) (99000 62%) 3.8422\n",
      "126m 37s (- 72m 38s) (100000 63%) 3.8325\n",
      "127m 52s (- 71m 21s) (101000 64%) 3.7797\n",
      "129m 6s (- 70m 4s) (102000 64%) 3.8405\n",
      "130m 24s (- 68m 49s) (103000 65%) 3.8022\n",
      "131m 39s (- 67m 33s) (104000 66%) 3.8370\n",
      "132m 55s (- 66m 17s) (105000 66%) 3.8450\n",
      "134m 9s (- 65m 0s) (106000 67%) 3.8031\n",
      "135m 25s (- 63m 44s) (107000 67%) 3.8335\n",
      "136m 40s (- 62m 28s) (108000 68%) 3.8206\n",
      "137m 54s (- 61m 11s) (109000 69%) 3.7904\n",
      "139m 9s (- 59m 55s) (110000 69%) 3.8001\n",
      "140m 23s (- 58m 38s) (111000 70%) 3.8140\n",
      "141m 40s (- 57m 22s) (112000 71%) 3.7982\n",
      "142m 56s (- 56m 7s) (113000 71%) 3.7790\n",
      "144m 11s (- 54m 50s) (114000 72%) 3.8115\n",
      "145m 26s (- 53m 34s) (115000 73%) 3.8092\n",
      "146m 42s (- 52m 18s) (116000 73%) 3.8050\n",
      "147m 57s (- 51m 2s) (117000 74%) 3.7946\n",
      "149m 12s (- 49m 46s) (118000 74%) 3.7914\n",
      "150m 28s (- 48m 30s) (119000 75%) 3.8233\n",
      "151m 44s (- 47m 14s) (120000 76%) 3.7935\n",
      "153m 0s (- 45m 59s) (121000 76%) 3.7937\n",
      "154m 16s (- 44m 43s) (122000 77%) 3.7674\n",
      "155m 33s (- 43m 27s) (123000 78%) 3.8124\n",
      "156m 48s (- 42m 11s) (124000 78%) 3.7697\n",
      "158m 4s (- 40m 55s) (125000 79%) 3.7678\n",
      "159m 18s (- 39m 39s) (126000 80%) 3.7546\n",
      "160m 33s (- 38m 23s) (127000 80%) 3.8002\n",
      "161m 49s (- 37m 7s) (128000 81%) 3.7532\n",
      "163m 4s (- 35m 51s) (129000 81%) 3.7739\n",
      "164m 20s (- 34m 35s) (130000 82%) 3.8037\n",
      "165m 35s (- 33m 19s) (131000 83%) 3.7371\n",
      "166m 51s (- 32m 3s) (132000 83%) 3.7701\n",
      "168m 7s (- 30m 47s) (133000 84%) 3.7756\n",
      "169m 22s (- 29m 31s) (134000 85%) 3.7759\n",
      "170m 38s (- 28m 16s) (135000 85%) 3.7390\n",
      "171m 53s (- 27m 0s) (136000 86%) 3.7304\n",
      "173m 8s (- 25m 44s) (137000 87%) 3.7528\n",
      "174m 24s (- 24m 28s) (138000 87%) 3.7449\n",
      "175m 40s (- 23m 12s) (139000 88%) 3.7786\n",
      "176m 57s (- 21m 56s) (140000 88%) 3.7464\n",
      "178m 11s (- 20m 40s) (141000 89%) 3.6889\n",
      "179m 27s (- 19m 25s) (142000 90%) 3.7095\n",
      "180m 43s (- 18m 9s) (143000 90%) 3.7475\n",
      "181m 57s (- 16m 53s) (144000 91%) 3.7286\n",
      "183m 12s (- 15m 37s) (145000 92%) 3.7455\n",
      "184m 27s (- 14m 21s) (146000 92%) 3.7053\n",
      "185m 42s (- 13m 5s) (147000 93%) 3.7292\n",
      "186m 57s (- 11m 49s) (148000 94%) 3.7263\n",
      "188m 13s (- 10m 33s) (149000 94%) 3.7374\n",
      "189m 28s (- 9m 18s) (150000 95%) 3.7405\n",
      "190m 44s (- 8m 2s) (151000 95%) 3.7741\n",
      "192m 0s (- 6m 46s) (152000 96%) 3.7357\n",
      "193m 14s (- 5m 30s) (153000 97%) 3.7310\n",
      "194m 30s (- 4m 14s) (154000 97%) 3.7304\n",
      "195m 47s (- 2m 59s) (155000 98%) 3.7187\n",
      "197m 2s (- 1m 43s) (156000 99%) 3.7358\n",
      "198m 19s (- 0m 27s) (157000 99%) 3.7108\n",
      "199m 45s (- 7659m 2s) (1000 2%) 0.6787\n",
      "200m 43s (- 3747m 32s) (2000 5%) 0.6510\n",
      "201m 40s (- 2443m 3s) (3000 7%) 0.6258\n",
      "202m 38s (- 1790m 20s) (4000 10%) 0.6273\n",
      "203m 35s (- 1398m 19s) (5000 12%) 0.6166\n",
      "204m 33s (- 1136m 39s) (6000 15%) 0.6112\n",
      "205m 30s (- 949m 29s) (7000 17%) 0.6215\n",
      "206m 28s (- 808m 52s) (8000 20%) 0.6221\n",
      "207m 25s (- 699m 16s) (9000 22%) 0.6061\n",
      "208m 23s (- 611m 25s) (10000 25%) 0.6312\n",
      "209m 20s (- 539m 21s) (11000 27%) 0.6319\n",
      "210m 18s (- 479m 9s) (12000 30%) 0.6090\n",
      "211m 15s (- 428m 3s) (13000 33%) 0.6201\n",
      "212m 12s (- 384m 7s) (14000 35%) 0.6063\n",
      "213m 10s (- 345m 55s) (15000 38%) 0.6314\n",
      "214m 7s (- 312m 22s) (16000 40%) 0.6036\n",
      "215m 5s (- 282m 39s) (17000 43%) 0.5916\n",
      "216m 2s (- 256m 8s) (18000 45%) 0.6204\n",
      "217m 0s (- 232m 19s) (19000 48%) 0.6006\n",
      "217m 57s (- 210m 46s) (20000 50%) 0.6019\n",
      "218m 55s (- 191m 12s) (21000 53%) 0.5999\n",
      "219m 52s (- 173m 18s) (22000 55%) 0.5764\n",
      "220m 51s (- 156m 54s) (23000 58%) 0.5932\n",
      "221m 48s (- 141m 47s) (24000 61%) 0.6005\n",
      "222m 46s (- 127m 47s) (25000 63%) 0.6131\n",
      "223m 44s (- 114m 48s) (26000 66%) 0.6153\n",
      "224m 41s (- 102m 42s) (27000 68%) 0.5989\n",
      "225m 39s (- 91m 23s) (28000 71%) 0.6340\n",
      "226m 36s (- 80m 48s) (29000 73%) 0.5815\n",
      "227m 34s (- 70m 51s) (30000 76%) 0.6004\n",
      "228m 31s (- 61m 29s) (31000 78%) 0.6156\n",
      "229m 29s (- 52m 38s) (32000 81%) 0.5850\n",
      "230m 27s (- 44m 16s) (33000 83%) 0.6139\n",
      "231m 24s (- 36m 21s) (34000 86%) 0.6068\n",
      "232m 22s (- 28m 49s) (35000 88%) 0.6057\n",
      "233m 20s (- 21m 39s) (36000 91%) 0.5984\n",
      "234m 17s (- 14m 49s) (37000 94%) 0.6120\n",
      "235m 15s (- 8m 18s) (38000 96%) 0.6144\n",
      "236m 12s (- 2m 3s) (39000 99%) 0.5966\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "embedding_dim = 256\n",
    "epochs = 1\n",
    "model = LSTMPredictor(data.n_tokens, embedding_dim, hidden_size).to(device)\n",
    "trainEpochs(model, epochs, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> これからが人生の総仕上げのときだ。\n",
      "こ:\n",
      "['れ', 'こ', 'の', 'う', 'ん']\n",
      "れ:\n",
      "['ま', 'は', 'に', 'で', 'ら']\n",
      "か:\n",
      "['ら', 'に', 'は', '、', 'り']\n",
      "ら:\n",
      "['本', 'は', 'の', '、', '１']\n",
      "が:\n",
      "['本', '、', '「', 'ん', '１']\n",
      "人:\n",
      "['気', '々', '権', '間', '事']\n",
      "生:\n",
      "['に', '活', 'は', 'を', 'の']\n",
      "の:\n",
      "['本', '方', 'こ', '、', '子']\n",
      "総:\n",
      "['理', '選', '統', '額', '事']\n",
      "仕:\n",
      "['事', '上', 'は', '子', '組']\n",
      "上:\n",
      "['げ', 'は', 'が', 'に', '化']\n",
      "げ:\n",
      "['は', 'の', 'を', 'だ', '者']\n",
      "の:\n",
      "['本', '、', '収', '一', '方']\n",
      "と:\n",
      "['こ', 'み', 'は', '、', '思']\n",
      "き:\n",
      "['、', 'は', 'に', 'ど', '言']\n",
      "だ:\n",
      "['、', 'っ', '。', 'ろ', '社']\n",
      "。:\n",
      "['#', '本', 'そ', '私', '＝']\n",
      "> 各自治体には最大限の努力をお願いしたい。\n",
      "各:\n",
      "['社', '国', '地', '種', '省']\n",
      "自:\n",
      "['分', '治', '社', 'は', '民']\n",
      "治:\n",
      "['体', '省', '区', '相', '療']\n",
      "体:\n",
      "['は', 'に', 'の', 'も', 'で']\n",
      "に:\n",
      "['収', 'は', '本', 'よ', 'も']\n",
      "は:\n",
      "['、', '本', 'ど', '「', '社']\n",
      "最:\n",
      "['本', '高', '後', '終', '低']\n",
      "大:\n",
      "['の', 'は', '手', '規', 'に']\n",
      "限:\n",
      "['界', '定', 'に', '度', '問']\n",
      "の:\n",
      "['収', '本', '高', '問', '改']\n",
      "努:\n",
      "['力', 'ー', '収', '車', 'ベ']\n",
      "力:\n",
      "['に', '者', '収', '不', 'は']\n",
      "を:\n",
      "['収', '本', '求', '受', '呼']\n",
      "お:\n",
      "['寄', 'ろ', 'り', '願', 'す']\n",
      "願:\n",
      "['う', 'え', 'い', 'く', 'ま']\n",
      "い:\n",
      "['す', '、', 'ま', 'さ', 'し']\n",
      "し:\n",
      "['ま', 'て', 'た', '、', 'く']\n",
      "た:\n",
      "['。', '本', 'こ', '、', 'い']\n",
      "い:\n",
      "['。', '本', 'ま', '状', 'と']\n",
      "。:\n",
      "['#', '本', 'そ', 'こ', '私']\n",
      "> 弱みとして、価格いろいろ言われている。\n",
      "弱:\n",
      "['者', 'み', 'さ', 'い', '点']\n",
      "み:\n",
      "['は', 'ず', 'が', 'の', 'な']\n",
      "と:\n",
      "['、', 'み', 'は', 'し', 'な']\n",
      "し:\n",
      "['て', '、', 'た', 'ま', 'は']\n",
      "て:\n",
      "['本', 'は', '、', '収', 'い']\n",
      "、:\n",
      "['本', '収', 'こ', 'ど', '白']\n",
      "価:\n",
      "['格', '値', 'は', '収', '本']\n",
      "格:\n",
      "['は', '安', '差', '収', '段']\n",
      "い:\n",
      "['本', 'っ', 'ま', 'は', 'ろ']\n",
      "ろ:\n",
      "['は', 'い', '、', 'う', 'ま']\n",
      "い:\n",
      "['ろ', '。', '収', 'っ', '、']\n",
      "ろ:\n",
      "['は', '、', 'な', 'に', 'い']\n",
      "言:\n",
      "['葉', 'わ', 'う', 'い', 'っ']\n",
      "わ:\n",
      "['れ', 'ざ', 'ず', 'せ', 'り']\n",
      "れ:\n",
      "['ま', '、', 'は', 'て', 'ば']\n",
      "て:\n",
      "['い', '本', '収', '、', 'は']\n",
      "い:\n",
      "['ま', 'る', 'た', '本', 'れ']\n",
      "る:\n",
      "['。', '本', 'の', '、', 'こ']\n",
      "。:\n",
      "['#', '本', '私', '勝', 'そ']\n",
      "> 金大中総書記との「対話」の中で触れる程度だろう。\n",
      "金:\n",
      "['融', '本', '属', '沢', '利']\n",
      "大:\n",
      "['統', 'は', '生', '中', '阪']\n",
      "中:\n",
      "['学', 'の', '高', 'は', '央']\n",
      "総:\n",
      "['統', '裁', '務', '合', '本']\n",
      "書:\n",
      "['社', '記', '店', 'は', '館']\n",
      "記:\n",
      "['局', '者', '録', 'は', 'に']\n",
      "と:\n",
      "['同', '本', '、', 'は', '収']\n",
      "の:\n",
      "['本', '関', '交', '収', '連']\n",
      "「:\n",
      "['本', '収', 'フ', '大', 'パ']\n",
      "対:\n",
      "['面', '象', '照', '策', '応']\n",
      "話:\n",
      "['は', '」', 'に', '家', 'の']\n",
      "」:\n",
      "['は', '「', 'に', 'と', 'の']\n",
      "の:\n",
      "['本', '主', '収', '方', '中']\n",
      "中:\n",
      "['に', '心', 'で', 'は', '身']\n",
      "で:\n",
      "['、', 'は', '本', '収', '「']\n",
      "触:\n",
      "['れ', 'っ', 'る', 'む', '載']\n",
      "れ:\n",
      "['ま', 'ば', 'れ', '、', 'る']\n",
      "る:\n",
      "['。', '本', 'こ', '可', '「']\n",
      "程:\n",
      "['度', '球', '齢', '界', '原']\n",
      "度:\n",
      "['は', '、', 'の', '改', 'で']\n",
      "だ:\n",
      "['ろ', '。', 'っ', 'け', 'と']\n",
      "ろ:\n",
      "['う', '。', '、', '収', 'っ']\n",
      "う:\n",
      "['。', 'か', '、', 'ー', '？']\n",
      "。:\n",
      "['#', '本', 'そ', '面', '分']\n",
      "> 「アメリカンワイン」、１４種の地酒などアルコール類も豊富にある。\n",
      "「:\n",
      "['本', '日', '収', '自', 'こ']\n",
      "ア:\n",
      "['ジ', 'マ', 'メ', 'ー', 'ン']\n",
      "メ:\n",
      "['リ', 'デ', 'ー', 'キ', 'ダ']\n",
      "リ:\n",
      "['カ', 'ー', 'オ', 'ス', 'ア']\n",
      "カ:\n",
      "['国', '人', '」', 'は', 'ベ']\n",
      "ン:\n",
      "['は', '」', '・', 'タ', 'ス']\n",
      "ワ:\n",
      "['ー', 'イ', 'ン', '社', 'シ']\n",
      "イ:\n",
      "['」', 'デ', 'タ', 'ツ', 'ト']\n",
      "ン:\n",
      "['」', 'タ', 'ス', 'グ', 'デ']\n",
      "」:\n",
      "['は', '「', 'の', 'に', 'と']\n",
      "、:\n",
      "['本', '収', '「', 'デ', '名']\n",
      "１:\n",
      "['９', '０', '２', '４', '本']\n",
      "４:\n",
      "['歳', '０', '世', '分', '本']\n",
      "種:\n",
      "['類', '目', 'の', '、', '本']\n",
      "の:\n",
      "['本', '収', '３', '２', '１']\n",
      "地:\n",
      "['球', '位', '域', '元', '下']\n",
      "酒:\n",
      "['屋', 'は', '。', 'デ', '場']\n",
      "な:\n",
      "['ど', '本', 'デ', 'さ', '場']\n",
      "ど:\n",
      "['本', '。', '、', 'の', 'で']\n",
      "ア:\n",
      "['マ', 'メ', 'ジ', 'デ', 'ー']\n",
      "ル:\n",
      "['デ', '本', 'バ', 'コ', 'ツ']\n",
      "コ:\n",
      "['ー', 'ン', 'ツ', '録', 'ス']\n",
      "ー:\n",
      "['ス', 'タ', 'デ', 'ヒ', 'シ']\n",
      "ル:\n",
      "['に', 'ス', 'は', 'デ', '収']\n",
      "類:\n",
      "['は', 'に', '送', '面', '。']\n",
      "も:\n",
      "['、', '収', '本', 'あ', '同']\n",
      "豊:\n",
      "['本', '富', '島', '田', 'か']\n",
      "富:\n",
      "['に', 'な', '本', 'で', 'だ']\n",
      "に:\n",
      "['収', '本', '違', '決', 'な']\n",
      "あ:\n",
      "['る', 'り', 'っ', 'ふ', 'げ']\n",
      "る:\n",
      "['。', '本', 'こ', '#', 'べ']\n",
      "。:\n",
      "['#', '本', '勝', '収', '私']\n",
      "> 前まわしを取って頭をつけて前へ出るのが持ち味。\n",
      "前:\n",
      "['年', '回', '社', '本', '者']\n",
      "ま:\n",
      "['す', 'で', '時', 'と', 'ず']\n",
      "わ:\n",
      "['り', 'ず', 'っ', 'る', 'ら']\n",
      "し:\n",
      "['て', 'た', 'は', '、', 'く']\n",
      "を:\n",
      "['収', '受', '、', '見', '本']\n",
      "取:\n",
      "['り', '得', 'る', 'ら', 'っ']\n",
      "っ:\n",
      "['て', 'た', 'せ', '手', 'ず']\n",
      "て:\n",
      "['本', '、', '収', 'い', 'お']\n",
      "頭:\n",
      "['痛', '取', '脳', '立', 'に']\n",
      "を:\n",
      "['収', '下', '出', '、', 'か']\n",
      "つ:\n",
      "['く', 'け', 'い', 'づ', 'き']\n",
      "け:\n",
      "['て', '、', 'た', 'ま', 'る']\n",
      "て:\n",
      "['本', '、', '収', 'は', 'き']\n",
      "前:\n",
      "['年', '本', '社', 'に', '身']\n",
      "へ:\n",
      "['出', '。', '、', 'の', '向']\n",
      "出:\n",
      "['場', '録', '席', '資', 'そ']\n",
      "る:\n",
      "['。', 'こ', '、', '本', 'か']\n",
      "の:\n",
      "['は', 'が', '本', 'で', 'か']\n",
      "が:\n",
      "['本', '、', '収', '一', '好']\n",
      "持:\n",
      "['ち', 'つ', 'っ', '続', '社']\n",
      "ち:\n",
      "['味', '、', '込', '回', '物']\n",
      "味:\n",
      "['は', '深', '方', 'だ', '、']\n",
      "。:\n",
      "['#', '本', 'そ', 'こ', '無']\n",
      "> 生命科学は大きく前進し試験管内での臓器や組織の創生が次々と報告されている。\n",
      "生:\n",
      "['活', '徒', '涯', '産', '命']\n",
      "命:\n",
      "['は', '保', '力', '家', '者']\n",
      "科:\n",
      "['学', '医', 'は', '社', '技']\n",
      "学:\n",
      "['者', '技', '研', 'は', '部']\n",
      "は:\n",
      "['、', '本', '収', '社', '「']\n",
      "大:\n",
      "['学', '阪', '変', '統', '社']\n",
      "き:\n",
      "['な', 'い', 'く', '、', 'に']\n",
      "く:\n",
      "['、', '変', '分', 'う', '打']\n",
      "前:\n",
      "['年', 'に', '提', '社', '本']\n",
      "進:\n",
      "['す', 'し', '、', 'に', '展']\n",
      "し:\n",
      "['、', 'た', 'て', 'ま', 'そ']\n",
      "試:\n",
      "['み', '合', '験', 'さ', 'す']\n",
      "験:\n",
      "['に', '、', '的', 'の', 'さ']\n",
      "管:\n",
      "['理', '社', '財', '制', '区']\n",
      "内:\n",
      "['に', '外', '容', 'の', 'デ']\n",
      "で:\n",
      "['、', '収', 'は', 'す', 'あ']\n",
      "の:\n",
      "['本', 'ぞ', '、', '利', '見']\n",
      "臓:\n",
      "['器', '病', '面', '移', '動']\n",
      "器:\n",
      "['移', 'や', 'に', '用', '産']\n",
      "や:\n",
      "['、', '本', 'デ', '関', '資']\n",
      "組:\n",
      "['織', '合', 'み', 'む', '”']\n",
      "織:\n",
      "['に', 'は', '化', 'デ', '状']\n",
      "の:\n",
      "['本', '収', '責', '問', '方']\n",
      "創:\n",
      "['業', '価', '造', '作', '刊']\n",
      "生:\n",
      "['に', 'は', '者', '時', '活']\n",
      "が:\n",
      "['本', '、', '収', 'あ', '必']\n",
      "次:\n",
      "['々', '第', '期', '世', '本']\n",
      "々:\n",
      "['に', 'と', '、', 'で', '。']\n",
      "と:\n",
      "['、', '言', 'い', 'み', '呼']\n",
      "報:\n",
      "['道', '告', 'じ', '酬', 'わ']\n",
      "告:\n",
      "['さ', '書', 'す', 'し', 'は']\n",
      "さ:\n",
      "['れ', 'せ', 'に', 'ず', 'な']\n",
      "れ:\n",
      "['ま', 'て', 'そ', '方', '、']\n",
      "て:\n",
      "['い', '本', '収', 'き', '、']\n",
      "い:\n",
      "['ま', 'る', 'た', 'く', '本']\n",
      "る:\n",
      "['。', '本', 'の', '可', 'こ']\n",
      "。:\n",
      "['#', '本', '私', 'そ', '日']\n",
      "> 日付を設定しなければ撮影は可能。\n",
      "日:\n",
      "['本', '露', '米', '産', '銀']\n",
      "付:\n",
      "['は', 'の', '近', '銀', '初']\n",
      "を:\n",
      "['収', '本', '受', '開', '務']\n",
      "設:\n",
      "['立', '置', '録', '定', '計']\n",
      "定:\n",
      "['さ', 'し', 'す', 'せ', '後']\n",
      "し:\n",
      "['、', 'た', 'ま', 'て', '社']\n",
      "な:\n",
      "['け', 'ど', 'く', 'が', 'か']\n",
      "け:\n",
      "['れ', 'ど', 'て', 'ば', 'に']\n",
      "れ:\n",
      "['ば', 'ま', 'ど', '本', 'ん']\n",
      "ば:\n",
      "['、', '本', 'な', '勝', 'ば']\n",
      "撮:\n",
      "['影', '道', '談', 'る', '治']\n",
      "影:\n",
      "['さ', '響', 'す', 'を', '者']\n",
      "は:\n",
      "['、', '本', 'な', 'ず', '収']\n",
      "可:\n",
      "['能', '決', '愛', '動', '欠']\n",
      "能:\n",
      "['に', '性', 'だ', 'な', '。']\n",
      "。:\n",
      "['#', '本', 'そ', '子', 'こ']\n",
      "> 逆光線で水蒸気などが凍結する霧氷を、美しく表現しました。\n",
      "逆:\n",
      "['に', '転', 'は', '本', '面']\n",
      "光:\n",
      "['は', 'の', 'ー', 'に', 'へ']\n",
      "線:\n",
      "['は', 'さ', 'の', 'に', 'が']\n",
      "で:\n",
      "['は', '本', '、', 'の', '新']\n",
      "水:\n",
      "['面', 'を', 'は', '準', '俣']\n",
      "蒸:\n",
      "['気', 'は', '目', 'や', '社']\n",
      "気:\n",
      "['味', 'が', 'は', '本', '温']\n",
      "な:\n",
      "['ど', '本', 'が', 'く', 'さ']\n",
      "ど:\n",
      "['本', '、', 'が', 'の', 'で']\n",
      "が:\n",
      "['本', '、', '収', '出', '「']\n",
      "凍:\n",
      "['結', 'ら', '手', 'り', '収']\n",
      "結:\n",
      "['さ', 'に', 'は', 'な', 'す']\n",
      "す:\n",
      "['。', 'る', 'れ', 'べ', '収']\n",
      "る:\n",
      "['。', 'こ', '、', '本', 'か']\n",
      "霧:\n",
      "['う', '取', '球', '手', '星']\n",
      "氷:\n",
      "['点', '山', '制', '本', 'チ']\n",
      "を:\n",
      "['収', '受', '得', '本', '目']\n",
      "、:\n",
      "['本', '収', '出', 'じ', 'そ']\n",
      "美:\n",
      "['術', 'さ', 'し', '容', '人']\n",
      "し:\n",
      "['く', 'い', 'さ', 'ま', 'て']\n",
      "く:\n",
      "['、', '。', '打', '面', '作']\n",
      "表:\n",
      "['面', '明', '現', 'れ', '彰']\n",
      "現:\n",
      "['さ', 'に', 'は', 'す', 'で']\n",
      "し:\n",
      "['、', 'て', 'た', 'ま', 'そ']\n",
      "ま:\n",
      "['す', 'せ', 'し', '、', '。']\n",
      "し:\n",
      "['た', 'ょ', 'て', '、', 'ま']\n",
      "た:\n",
      "['。', '本', '、', 'こ', 'ね']\n",
      "。:\n",
      "['#', '本', '私', 'そ', 'こ']\n",
      "> また「管理組合への不信」は、組合運営など。\n",
      "ま:\n",
      "['す', 'た', 'ず', 'だ', 'あ']\n",
      "た:\n",
      "['、', 'は', '本', '「', '一']\n",
      "「:\n",
      "['本', '収', '自', '日', 'エ']\n",
      "管:\n",
      "['理', '財', '区', '制', '社']\n",
      "理:\n",
      "['的', '職', 'は', 'さ', '性']\n",
      "組:\n",
      "['」', '織', 'は', 'み', '合']\n",
      "合:\n",
      "['員', '」', '、', 'は', '研']\n",
      "へ:\n",
      "['」', 'の', '収', '行', 'は']\n",
      "の:\n",
      "['本', '収', '関', '影', '道']\n",
      "不:\n",
      "['足', '安', '幸', '在', '要']\n",
      "信:\n",
      "['感', '」', '頼', 'に', '訴']\n",
      "」:\n",
      "['は', 'に', 'と', '「', 'を']\n",
      "は:\n",
      "['、', '本', '「', '次', '一']\n",
      "、:\n",
      "['本', '#', '社', '日', '和']\n",
      "組:\n",
      "['織', 'み', '合', '教', 'む']\n",
      "合:\n",
      "['員', '収', '的', 'に', '、']\n",
      "運:\n",
      "['動', '営', '用', '法', '賃']\n",
      "営:\n",
      "['に', '委', '協', 'は', '者']\n",
      "な:\n",
      "['ど', '本', 'ん', 'ら', 'べ']\n",
      "ど:\n",
      "['本', '収', '、', 'に', '。']\n",
      "。:\n",
      "['#', '本', '無', '日', '会']\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(model, 10)\n",
    "\n",
    "outputs = evaluate(model, \"だが「市場の論理」万能のグローバル化はどうか。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./weights/token_level_\"+str(epochs)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
